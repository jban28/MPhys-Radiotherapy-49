{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trying3dAugSem2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jban28/MPhys-Radiotherapy-49/blob/main/Trying3dAugSem2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E8F_po0K_Wu"
      },
      "source": [
        "## Pre-requisites\n",
        "This block makes the necessary installations and imports for the rest of the code blocks to run, connects to the GPU if one is available, and specifies the location of the folder containing the data. That data folder should contain a sub-folder containing all nifti files, along with a metadata csv file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5AFQEgZc7XUV",
        "outputId": "5ffba197-9ac1-478b-e9dc-ac11b724260d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Egh9uSI77b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b8de95-018f-41df-99ba-0e7b66e9d67f"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "!pip install kornia\n",
        "!pip install utils\n",
        "!pip install torchio\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "import torchio as tio\n",
        "import kornia.augmentation as K\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch.nn import LeakyReLU\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "from scipy.ndimage import zoom, rotate\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#from torch.utils.data import windowLevelNormalize\n",
        "\n",
        "\n",
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "# Specify project folder location\n",
        "#project_folder = \"/content/drive/My Drive/Degree/MPhys/Data/\"\n",
        "project_folder = \"/content/drive/My Drive/Data/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 2.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.3-py2.py3-none-any.whl (474 kB)\n",
            "\u001b[K     |████████████████████████████████| 474 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.7)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.6.3\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.18.73-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.10.0+cu111)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from torchio) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from torchio) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchio) (4.62.3)\n",
            "Requirement already satisfied: SimpleITK!=2.0.* in /usr/local/lib/python3.7/dist-packages (from torchio) (2.1.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from torchio) (3.0.2)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->torchio) (1.13.3)\n",
            "Installing collected packages: Deprecated, torchio\n",
            "Successfully installed Deprecated-1.2.13 torchio-0.18.73\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzE7_7waF7_S"
      },
      "source": [
        "## Define arrays of patient and outcome data\n",
        "This block allows you to specify the criteria which defines the patient outcome as True or False. It then loops through all the patients in the metadata.csv file, searches for their corresponding image in the image folder, and then adds patient and outcome to either the training, testing, or validation array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KFIqmcw83Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c77eee-bcfa-42ff-dd00-43f0219f30c9"
      },
      "source": [
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = open(project_folder + \"metadata.csv\")\n",
        "metadata = np.loadtxt(metadata_file, dtype=\"str\", delimiter=\",\")\n",
        "metadata = metadata[1:][:]\n",
        "\n",
        "# Set the values which are used to define the outcome for each patient\n",
        "outcome_type = 1 #int(input(\"Select which outcome you are aiming to predict \\n(1=Locoregional, 2=Distant Metastasis, 3=Death):\"))\n",
        "check_day = 3000 #int(input(\"Select the number of days at which to check for event:\"))\n",
        "which_patients = 1 #int(input(\"Do you want to include patients whose last follow up is before the check day? (no = 0, yes = 1):\"))\n",
        "\n",
        "# Create empty arrays to store patient names and outcomes in\n",
        "patient_with_event = []\n",
        "patient_no_event = []\n",
        "outcomes_train = []\n",
        "outcomes_test = []\n",
        "images = []\n",
        "\n",
        "# Loop through each patient and identify whether they are true or false for the specified outcome from above\n",
        "for patient in metadata:\n",
        "  if (patient[(5+outcome_type)] == \"\") and (int(patient[5]) >= check_day):\n",
        "    # Last follow up after check day, no event\n",
        "    outcome = 0\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 0):\n",
        "    # Last follow up before check day, event unknown\n",
        "    continue\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 1):\n",
        "    outcome = 0\n",
        "  elif int(patient[(5+outcome_type)]) <= check_day:\n",
        "    # Event occurred before or on check day\n",
        "    outcome = 1\n",
        "  else:\n",
        "    # Event occurred after check day\n",
        "    outcome = 0\n",
        "  # No Image file found for patient\n",
        "  if not os.path.exists(project_folder + \"crop/Images/\" + patient[0] + \".nii\"):\n",
        "    print(\"No image found for patient \" + patient[0])\n",
        "    continue\n",
        "  \n",
        "  if outcome == 1:\n",
        "    patient_with_event.append([patient[0], outcome])\n",
        "  else:\n",
        "    patient_no_event.append([patient[0], outcome])\n",
        "\n",
        "# # Make arrays the same length\n",
        "# if len(patient_with_event) < len(patient_no_event):\n",
        "#   new_patient_no_event = random.sample(patient_no_event,len(patient_with_event))\n",
        "#   new_patient_with_event = patient_with_event\n",
        "# elif len(patient_with_event) > len(patient_no_event):\n",
        "#   new_patient_with_event = random.sample(patient_with_event, len(patient_no_event))\n",
        "#   new_patient_no_event = patient_no_event\n",
        "# elif len(patient_with_event) == len(patient_no_event):\n",
        "new_patient_no_event = patient_no_event\n",
        "new_patient_with_event = patient_with_event\n",
        "pos_weights = len(new_patient_no_event)/len(new_patient_with_event)\n",
        "# Add patient name, outcome and image to array\n",
        "seventy_percent_event = int(0.7*len(new_patient_with_event))\n",
        "seventy_percent_no_event = int(0.7*len(new_patient_no_event))\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "train_patients_event = random.sample(new_patient_with_event, seventy_percent_event)\n",
        "train_patients_no_event = random.sample(new_patient_no_event, seventy_percent_no_event)\n",
        "\n",
        "def remove(small_array, original_array):\n",
        "  for i in small_array:\n",
        "    original_array.remove(i)\n",
        "    \n",
        "  return original_array\n",
        "\n",
        "new_patients_with_event = remove(train_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(train_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "\n",
        "fifty_percent_event = int(0.5*len(new_patient_with_event))\n",
        "fifty_percent_no_event = int(0.5*len(new_patient_no_event))\n",
        "\n",
        "validate_patients_event = random.sample(new_patient_with_event, fifty_percent_event)\n",
        "validate_patients_no_event = random.sample(new_patient_no_event, fifty_percent_no_event)\n",
        "\n",
        "new_patient_with_event = remove(validate_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(validate_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "test_patients_event = new_patient_with_event\n",
        "test_patients_no_event = new_patient_no_event\n",
        "\n",
        "outcomes_train = train_patients_event + train_patients_no_event\n",
        "outcomes_validate = validate_patients_event + validate_patients_no_event\n",
        "outcomes_test = test_patients_event + test_patients_no_event\n",
        "\n",
        "print(outcomes_train)\n",
        "print(outcomes_validate)\n",
        "print(outcomes_test)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No image found for patient HN-CHUM-005\n",
            "No image found for patient HN-CHUM-016\n",
            "No image found for patient HN-CHUM-040\n",
            "No image found for patient HN-CHUM-051\n",
            "No image found for patient HN-CHUS-033\n",
            "No image found for patient HN-CHUS-086\n",
            "No image found for patient HN-CHUS-089\n",
            "No image found for patient HN-CHUS-093\n",
            "No image found for patient HN-CHUS-096\n",
            "No image found for patient HN-CHUS-099\n",
            "No image found for patient HN-CHUS-100\n",
            "No image found for patient HN-CHUS-101\n",
            "No image found for patient HN-HGJ-003\n",
            "No image found for patient HN-HGJ-008\n",
            "No image found for patient HN-HGJ-010\n",
            "No image found for patient HN-HGJ-028\n",
            "No image found for patient HN-HGJ-034\n",
            "No image found for patient HN-HGJ-038\n",
            "No image found for patient HN-HGJ-041\n",
            "No image found for patient HN-HGJ-046\n",
            "No image found for patient HN-HGJ-047\n",
            "No image found for patient HN-HGJ-048\n",
            "No image found for patient HN-HGJ-054\n",
            "No image found for patient HN-HGJ-055\n",
            "No image found for patient HN-HGJ-056\n",
            "No image found for patient HN-HGJ-063\n",
            "No image found for patient HN-HGJ-064\n",
            "No image found for patient HN-HGJ-065\n",
            "No image found for patient HN-HGJ-066\n",
            "No image found for patient HN-HGJ-069\n",
            "No image found for patient HN-HGJ-071\n",
            "No image found for patient HN-HGJ-074\n",
            "No image found for patient HN-HGJ-079\n",
            "No image found for patient HN-HGJ-082\n",
            "No image found for patient HN-HGJ-083\n",
            "No image found for patient HN-HGJ-084\n",
            "No image found for patient HN-HGJ-087\n",
            "No image found for patient HN-HGJ-088\n",
            "No image found for patient HN-HGJ-089\n",
            "No image found for patient HN-HGJ-090\n",
            "No image found for patient HN-HGJ-091\n",
            "No image found for patient HN-HGJ-092\n",
            "No image found for patient HN-HMR-003\n",
            "No image found for patient HN-HMR-004\n",
            "No image found for patient HN-HMR-005\n",
            "No image found for patient HN-HMR-007\n",
            "No image found for patient HN-HMR-009\n",
            "No image found for patient HN-HMR-021\n",
            "No image found for patient HN-HMR-024\n",
            "No image found for patient HN-HMR-027\n",
            "No image found for patient HN-HMR-028\n",
            "No image found for patient HN-HMR-029\n",
            "No image found for patient HN-HMR-032\n",
            "No image found for patient HN-HMR-039\n",
            "NO event\n",
            "120\n",
            "WITH event\n",
            "19\n",
            "NO event\n",
            "36\n",
            "WITH event\n",
            "6\n",
            "NO event\n",
            "18\n",
            "WITH event\n",
            "3\n",
            "[['HN-CHUM-061', 1], ['HN-CHUM-002', 1], ['HN-CHUM-053', 1], ['HN-HMR-031', 1], ['HN-HGJ-018', 1], ['HN-HMR-015', 1], ['HN-CHUM-063', 1], ['HN-CHUM-028', 1], ['HN-HGJ-002', 1], ['HN-HMR-035', 1], ['HN-CHUM-020', 1], ['HN-HMR-038', 1], ['HN-HGJ-078', 1], ['HN-CHUM-009', 0], ['HN-HGJ-012', 0], ['HN-HGJ-005', 0], ['HN-CHUM-018', 0], ['HN-CHUM-003', 0], ['HN-HMR-019', 0], ['HN-CHUM-007', 0], ['HN-HGJ-025', 0], ['HN-HGJ-070', 0], ['HN-CHUS-002', 0], ['HN-CHUM-012', 0], ['HN-HMR-033', 0], ['HN-HMR-040', 0], ['HN-HMR-025', 0], ['HN-CHUM-062', 0], ['HN-HMR-041', 0], ['HN-HGJ-062', 0], ['HN-HGJ-077', 0], ['HN-CHUM-021', 0], ['HN-HGJ-022', 0], ['HN-HGJ-024', 0], ['HN-CHUM-050', 0], ['HN-CHUM-015', 0], ['HN-HMR-018', 0], ['HN-CHUM-001', 0], ['HN-HGJ-013', 0], ['HN-CHUS-005', 0], ['HN-HGJ-072', 0], ['HN-CHUM-023', 0], ['HN-HMR-037', 0], ['HN-HGJ-049', 0], ['HN-CHUM-019', 0], ['HN-CHUM-025', 0], ['HN-HGJ-052', 0], ['HN-HGJ-060', 0], ['HN-CHUM-031', 0], ['HN-CHUM-042', 0], ['HN-HGJ-026', 0], ['HN-HMR-016', 0], ['HN-HMR-002', 0], ['HN-HMR-030', 0], ['HN-CHUM-039', 0], ['HN-CHUM-035', 0], ['HN-CHUM-052', 0], ['HN-HGJ-043', 0], ['HN-HMR-017', 0], ['HN-HGJ-076', 0], ['HN-HGJ-030', 0], ['HN-CHUM-056', 0], ['HN-HGJ-051', 0], ['HN-HGJ-037', 0], ['HN-HMR-010', 0], ['HN-HGJ-058', 0], ['HN-HMR-013', 0], ['HN-HMR-036', 0], ['HN-CHUM-026', 0], ['HN-CHUM-033', 0], ['HN-HGJ-075', 0], ['HN-HGJ-035', 0], ['HN-CHUM-034', 0], ['HN-CHUM-043', 0], ['HN-HGJ-061', 0], ['HN-HMR-011', 0], ['HN-HGJ-007', 0], ['HN-HGJ-067', 0], ['HN-HGJ-042', 0], ['HN-CHUM-022', 0], ['HN-HMR-026', 0], ['HN-HGJ-032', 0], ['HN-HMR-012', 0], ['HN-HMR-008', 0], ['HN-HGJ-044', 0], ['HN-CHUM-024', 0], ['HN-HMR-014', 0], ['HN-HGJ-027', 0], ['HN-HMR-020', 0], ['HN-CHUM-041', 0], ['HN-CHUM-006', 0], ['HN-CHUM-014', 0], ['HN-CHUS-064', 0], ['HN-CHUM-037', 0], ['HN-HGJ-015', 0], ['HN-HGJ-086', 0], ['HN-CHUM-049', 0]]\n",
            "[['HN-HMR-022', 1], ['HN-HGJ-001', 1], ['HN-HGJ-045', 1], ['HN-HGJ-004', 0], ['HN-HGJ-085', 0], ['HN-CHUM-017', 0], ['HN-CHUM-011', 0], ['HN-HGJ-020', 0], ['HN-CHUS-009', 0], ['HN-HGJ-019', 0], ['HN-HGJ-029', 0], ['HN-CHUM-008', 0], ['HN-CHUM-036', 0], ['HN-HGJ-050', 0], ['HN-HGJ-080', 0], ['HN-CHUM-057', 0], ['HN-HGJ-016', 0], ['HN-HMR-006', 0], ['HN-CHUM-027', 0], ['HN-CHUM-029', 0], ['HN-HGJ-014', 0]]\n",
            "[['HN-HGJ-031', 1], ['HN-HGJ-059', 1], ['HN-HMR-001', 1], ['HN-CHUM-004', 0], ['HN-CHUM-010', 0], ['HN-CHUM-013', 0], ['HN-CHUM-030', 0], ['HN-CHUM-032', 0], ['HN-CHUM-038', 0], ['HN-CHUM-055', 0], ['HN-CHUM-065', 0], ['HN-HGJ-006', 0], ['HN-HGJ-009', 0], ['HN-HGJ-011', 0], ['HN-HGJ-036', 0], ['HN-HGJ-040', 0], ['HN-HGJ-053', 0], ['HN-HGJ-057', 0], ['HN-HGJ-073', 0], ['HN-HMR-023', 0], ['HN-HMR-034', 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfGjowelNEoF"
      },
      "source": [
        "## Define dataset class\n",
        "This block defines the class on which to build dataset objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjrRiSmq4mBF"
      },
      "source": [
        "# class Normalize(Dataset):\n",
        "#     def __init__(self):\n",
        "#       pass\n",
        "#     def __call__(self, vol):\n",
        "#         vol = (vol-vol.mean())/vol.std()\n",
        "#         return(vol) \n",
        "\n",
        "# class MyAugmentationPipeline(Dataset):\n",
        "# #class MyAugmentationPipeline(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(MyAugmentationPipeline, self).__init__()\n",
        "#         #self.mixup = K.RandomMixUp(p=1.)\n",
        "#         self.aff = K.RandomAffine3D(degrees=[5.,5.,5.], scale=(0.9,1.1), keepdim = True, p=0.5)\n",
        "#         self.Hflip = K.RandomHorizontalFlip3D(p=0.3)\n",
        "#         # self.jitter = K.ColorJitter(0.2, 0.3, 0.2, 0.3, p=0.5)\n",
        "#         # self.crp = K.RandomCrop((200, 200))\n",
        "#     #def forward(self, input, label):\n",
        "#     def __call__(self, input):\n",
        "#         #input, label = self.mixup(input, label)\n",
        "#         input = self.aff(self.Hflip)\n",
        "#         #input = self.crp(self.jitter(self.aff(input)))\n",
        "#         #return input, label\n",
        "#         return input\n",
        "# aug = MyAugmentationPipeline()\n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #Normalize()\n",
        "    ])\n",
        "\n",
        "#window and levelling and this does normalise as well\n",
        "def windowLevelNormalize(image, level, window):\n",
        "    minval = level - window/2\n",
        "    maxval = level + window/2\n",
        "    wld = np.clip(image, minval, maxval)\n",
        "    wld -= minval\n",
        "    wld *= (1 / window)\n",
        "    return wld\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, annotations, img_dir, transform= data_transform, target_transform=None, rotate_augment=False, scale_augment=False, flip_augment=False, shift_augment=True):\n",
        "        self.img_labels = annotations\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.flips = flip_augment\n",
        "        self.rotations = rotate_augment\n",
        "        self.scaling = scale_augment\n",
        "        self.shifts = shift_augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels[idx][0]+\".nii\")\n",
        "        image_sitk = sitk.ReadImage(img_path)\n",
        "        image = sitk.GetArrayFromImage(image_sitk)\n",
        "        label = self.img_labels[idx][1]\n",
        "        print(image.shape)\n",
        "        \n",
        "        if self.shifts and random.random()<0.5:\n",
        "            mx_x, mx_yz = 10, 10\n",
        "            # find shift values\n",
        "            cc_shift, ap_shift, lr_shift = random.randint(-mx_x,mx_x), random.randint(-mx_yz,mx_yz), random.randint(-mx_yz,mx_yz)\n",
        "            # pad for shifting into\n",
        "            image = np.pad(image, pad_width=((mx_x,mx_x),(mx_yz,mx_yz),(mx_yz,mx_yz)), mode='constant', constant_values=-1024)\n",
        "            # crop to complete shift\n",
        "            image = image[mx_x+cc_shift:246+mx_x+cc_shift, mx_yz+ap_shift:246+mx_yz+ap_shift, mx_yz+lr_shift:246+mx_yz+lr_shift]\n",
        "            print(image.shape)\n",
        "            print('shift')\n",
        "\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        \n",
        "        if self.rotations and random.random()<0.5:\n",
        "            # taking implementation from my 3DSegmentationNetwork which can be applied -> rotations in the axial plane only I should think? -10->10 degrees?\n",
        "            roll_angle = np.clip(np.random.normal(loc=0,scale=3), -10, 10) # make -10,10\n",
        "            image = self.rotation(image, roll_angle, rotation_plane=(1,2)) # (1,2) originally\n",
        "            print('rotation')\n",
        "            \n",
        "        if self.scaling and random.random()<0.5:\n",
        "            # same here -> zoom between 80-120%\n",
        "            scale_factor = np.clip(np.random.normal(loc=1.0,scale=0.5), 0.8, 1.2) # original scale = 0.05\n",
        "            image = self.scale(image, scale_factor)\n",
        "            print('scale')\n",
        "            \n",
        "        if self.flips and random.random()<0.5:\n",
        "            image = self.flip(image)\n",
        "            print('horizontal flip')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # window and levelling\n",
        "        image = windowLevelNormalize(image, level=40, window=50)\n",
        " \n",
        "        return image, label\n",
        "    def scale(self, image, scale_factor):\n",
        "        # scale the image or mask using scipy zoom function\n",
        "        order, cval = (3, 0) # changed from -1024 to 0\n",
        "        height, width, depth = image.shape\n",
        "        zheight = int(np.round(scale_factor*height))\n",
        "        zwidth = int(np.round(scale_factor*width))\n",
        "        zdepth = int(np.round(scale_factor*depth))\n",
        "        # zoomed out\n",
        "        if scale_factor < 1.0:\n",
        "            new_image = np.full_like(image, cval)\n",
        "            ud_buffer = (height-zheight) // 2\n",
        "            ap_buffer = (width-zwidth) // 2\n",
        "            lr_buffer = (depth-zdepth) // 2\n",
        "            new_image[ud_buffer:ud_buffer+zheight, ap_buffer:ap_buffer+zwidth, lr_buffer:lr_buffer+zdepth] = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            return new_image\n",
        "        elif scale_factor > 1.0:\n",
        "            new_image = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            ud_extra = (new_image.shape[0] - height) // 2\n",
        "            ap_extra = (new_image.shape[1] - width) // 2\n",
        "            lr_extra = (new_image.shape[2] - depth) // 2\n",
        "            new_image = new_image[ud_extra:ud_extra+height, ap_extra:ap_extra+width, lr_extra:lr_extra+depth]\n",
        "            return new_image\n",
        "        return image\n",
        "      \n",
        "    def rotation(self, image, rotation_angle, rotation_plane):\n",
        "        # rotate the image using scipy rotate function\n",
        "        order, cval = (3, -1024) # changed from -1024 to 0\n",
        "        return rotate(input=image, angle=rotation_angle, axes=rotation_plane, reshape=False, order=order, mode='constant', cval=cval)\n",
        "\n",
        "    def flip(self, image):\n",
        "        #hflip = np.fliplr(image)\n",
        "        #image = (reversed(image[1:]))\n",
        "        image = np.flipud(image).copy()\n",
        "        return image\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiSjndmcNfSA"
      },
      "source": [
        "## Build Datasets\n",
        "This block uses the class and arrays defined previously to build datasets for training, testing and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDoF-cH6xw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb71033c-a87c-4418-efff-d6c6e19ae698"
      },
      "source": [
        "\n",
        "training_data = ImageDataset(outcomes_train, project_folder + \"crop/Images/\")\n",
        "validation_data = ImageDataset(outcomes_validate, project_folder + \"crop/Images/\")\n",
        "test_data = ImageDataset(outcomes_test, project_folder + \"crop/Images/\")\n",
        "print(len(training_data))\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7jDjfvKOCWc"
      },
      "source": [
        "## View binary masks in 3d\n",
        "This block allows you to view a binary mask from the image in 3d by extracting the image from a given dataset. This helps to confirm that the data has not been affected by reading in to pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uideXDzjvdS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "7ea7fb17-90fb-4adc-8b9b-ea4626f49e4d"
      },
      "source": [
        "# Set which dataset to look at, and the index of the patient to view\n",
        "dataset = training_data\n",
        "index = 9\n",
        "print('flipud')\n",
        "print(outcomes_train[index])\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "#print(dataset[0])\n",
        "\n",
        "#array = dataset[index][0].numpy()\n",
        "array = dataset[index][0]\n",
        "print(type(array))\n",
        "print('array shape')\n",
        "print(array.shape)\n",
        "x,y,z = np.where(array > 0.) # what >=\n",
        "ax.scatter(x, y, z, c=z, alpha=1)\n",
        "\n",
        "ax.set_xlim(0,246)\n",
        "ax.set_ylim(0,246)\n",
        "ax.set_zlim(0,246)\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flipud\n",
            "['HN-HMR-035', 1]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "<class 'torch.Tensor'>\n",
            "array shape\n",
            "torch.Size([246, 246, 246])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 246.0)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Chh969QU-u"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEBaWTtLN_A_"
      },
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=2, shuffle=True)\n",
        "validate_dataloader = DataLoader(validation_data, batch_size=2, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=2, shuffle=True)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4hpRnHALqS"
      },
      "source": [
        "# Define CNN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSj3U3DL5NGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153e2a1e-1acc-4722-d279-54b6f7631b9a"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    out1 = 4\n",
        "    out2 = 4\n",
        "    out3 = 2\n",
        "    self.cnn_layers = nn.Sequential(\n",
        "      # Layer 1\n",
        "      nn.Conv3d(1,out1,4,1,1),\n",
        "      nn.BatchNorm3d(out1),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 2\n",
        "      nn.Conv3d(out1, out2, 4, 1, 1),\n",
        "      nn.BatchNorm3d(out2),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 3\n",
        "      nn.Conv3d(out2, out3, 4, 1, 1),\n",
        "      nn.BatchNorm3d(out3),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    self.linear_layers = nn.Sequential(\n",
        "      nn.Linear(48778, 2)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.cnn_layers(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.linear_layers(x)\n",
        "    return x\n",
        "\n",
        "model = CNN().to(device)\n",
        "print(model)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv3d(1, 4, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv3d(4, 4, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (5): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv3d(4, 2, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (9): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (11): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=48778, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imIsJYkHAVEe"
      },
      "source": [
        "# Define Train and Test Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RhWjamUGtE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f00f2e-8af9-493d-c751-7c65afc79096"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "        X = X.float()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        #y = reshape(y, (y.shape[0],1))\n",
        "        hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "        for index in range(len(y)):\n",
        "          if y[index] == 0:\n",
        "            hot_y[index,0] = 1\n",
        "            hot_y[index,1] = 0\n",
        "          elif y[index] == 1:\n",
        "            hot_y[index,0] = 0\n",
        "            hot_y[index,1] = 1\n",
        "      \n",
        "        print(hot_y)\n",
        "        pred = model(X)\n",
        "        torch.squeeze(pred)\n",
        "        loss = loss_fn(pred, hot_y.float())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print results after each batch        \n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss\n",
        "\n",
        "def validate_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    validate_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "            \n",
        "            pred = model(X)\n",
        "            # print(f'pred: {pred}')\n",
        "            # print(f'hot_y: {hot_y}')\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            # print(f'predictions: {predictions}')\n",
        "            # print(f'targets: {targets}')\n",
        "            print(f'Correct this batch = {(predictions == targets).sum().item()}')\n",
        "\n",
        "            torch.squeeze(pred)\n",
        "            validate_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            # correct += (pred.argmax(1) == hot_y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    validate_loss /= num_batches\n",
        "    correct /= size\n",
        "    accuracy = 100*correct\n",
        "    print(f\"Validate Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validate_loss:>8f} \\n\")\n",
        "    return validate_loss, accuracy\n",
        "\n",
        "learning_rate = 0.001\n",
        "# defining the model\n",
        "model = CNN()\n",
        "# defining the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# defining the loss function\n",
        "pos_weights = torch.tensor(pos_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weights)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.to(device)\n",
        "loss_fn.to(device)\n",
        "\n",
        "summary(model=model, input_size=(1, 246, 246, 246), batch_size=2)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [2, 4, 245, 245, 245]             260\n",
            "       BatchNorm3d-2      [2, 4, 245, 245, 245]               8\n",
            "         LeakyReLU-3      [2, 4, 245, 245, 245]               0\n",
            "         MaxPool3d-4      [2, 4, 122, 122, 122]               0\n",
            "            Conv3d-5      [2, 4, 121, 121, 121]           1,028\n",
            "       BatchNorm3d-6      [2, 4, 121, 121, 121]               8\n",
            "         LeakyReLU-7      [2, 4, 121, 121, 121]               0\n",
            "         MaxPool3d-8         [2, 4, 60, 60, 60]               0\n",
            "            Conv3d-9         [2, 2, 59, 59, 59]             514\n",
            "      BatchNorm3d-10         [2, 2, 59, 59, 59]               4\n",
            "        LeakyReLU-11         [2, 2, 59, 59, 59]               0\n",
            "        MaxPool3d-12         [2, 2, 29, 29, 29]               0\n",
            "           Linear-13                     [2, 2]          97,558\n",
            "================================================================\n",
            "Total params: 99,380\n",
            "Trainable params: 99,380\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 113.58\n",
            "Forward/backward pass size (MB): 3160.72\n",
            "Params size (MB): 0.38\n",
            "Estimated Total Size (MB): 3274.67\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqQYmcaAe-Q"
      },
      "source": [
        "# Run Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23uXlNlG9ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6fb0e0-587c-46a0-c248-f5b4c06ca075"
      },
      "source": [
        "epochs = 1\n",
        "train_losses = [[],[]]\n",
        "validate_losses = [[],[]]\n",
        "validate_accuracies = [[],[]]\n",
        "\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    validate_loss = validate_loop(validate_dataloader, model, loss_fn)\n",
        "\n",
        "    train_losses[0].append(t)\n",
        "    train_losses[1].append(train_loss)\n",
        "    validate_losses[0].append(t)\n",
        "    validate_losses[1].append(validate_loss[0])\n",
        "    validate_accuracies[0].append(t)\n",
        "    validate_accuracies[1].append(validate_loss[1])\n",
        "\n",
        "\n",
        "    #writer.add_scalar(\"Loss/train\", )\n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 6.243097  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 278.270233  [    2/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.000000  [    4/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 65.352402  [    6/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 104.732445  [    8/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 17.257589  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.539033  [   12/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.051045  [   14/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.001747  [   16/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.000002  [   18/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.000129  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.006038  [   22/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.007372  [   24/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 23.643679  [   26/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 3.914879  [   28/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 3.693634  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 6.419004  [   32/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.350916  [   34/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.003147  [   36/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.884894  [   38/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.012743  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.001086  [   42/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.801465  [   44/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.000040  [   46/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 43.759449  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 10.585371  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 14.116566  [   52/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.978359  [   54/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.794303  [   56/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.563157  [   58/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.309001  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 4.855753  [   62/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.060516  [   64/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.242218  [   66/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.003519  [   68/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.262934  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 32.738205  [   72/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.032384  [   74/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 6.354458  [   76/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.414414  [   78/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.545898  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 6.729062  [   82/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.201086  [   84/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.954107  [   86/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 3.645209  [   88/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.841026  [   90/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 5.300007  [   92/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.342002  [   94/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.]], device='cuda:0')\n",
            "loss: 3.019785  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 1\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.934324 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "NUCtjrHb6JAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "                \n",
        "            pred = model(X)\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            torch.squeeze(pred)\n",
        "            #test_loss += loss_fn(pred, y.float()).item()\n",
        "            test_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n",
        "\n",
        "test_loop(test_dataloader, model)"
      ],
      "metadata": {
        "id": "MEuNq5Z-6IV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZBw098GbFou"
      },
      "source": [
        "# Plot Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmncBB6bEip"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(train_losses[0], train_losses[1], label=\"Train Loss\")\n",
        "ax.plot(validate_losses[0], validate_losses[1], label=\"Validate Loss\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Accuracies"
      ],
      "metadata": {
        "id": "fFAdAFAECQ-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(validate_accuracies[0], validate_accuracies[1], label=\"Validate Accuracies\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy / %')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "2Q8g4JowCPkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}