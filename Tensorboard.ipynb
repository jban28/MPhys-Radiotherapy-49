{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jban28/MPhys-Radiotherapy-49/blob/main/Tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E8F_po0K_Wu"
      },
      "source": [
        "## Pre-requisites\n",
        "This block makes the necessary installations and imports for the rest of the code blocks to run, connects to the GPU if one is available, and specifies the location of the folder containing the data. That data folder should contain a sub-folder containing all nifti files, along with a metadata csv file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5AFQEgZc7XUV",
        "outputId": "37d2f269-a3fb-4b5c-e6a4-b1cc009b0f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Egh9uSI77b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67333a4-b06f-4269-830e-6a1a9d8cccd8"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "!pip install kornia\n",
        "!pip install utils\n",
        "!pip install torchio\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "import torchio as tio\n",
        "import kornia.augmentation as K\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch.nn import LeakyReLU\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "from scipy.ndimage import zoom, rotate\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#from torch.utils.data import windowLevelNormalize\n",
        "\n",
        "\n",
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "# Specify project folder location\n",
        "#project_folder = \"/content/drive/My Drive/Degree/MPhys/Data/\"\n",
        "project_folder = \"/content/drive/My Drive/Data/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 19 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.3-py2.py3-none-any.whl (474 kB)\n",
            "\u001b[K     |████████████████████████████████| 474 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.7)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.6.3\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.18.73-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.10.0+cu111)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from torchio) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.21.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from torchio) (0.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchio) (4.62.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: SimpleITK!=2.0.* in /usr/local/lib/python3.7/dist-packages (from torchio) (2.1.1)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->torchio) (1.13.3)\n",
            "Installing collected packages: Deprecated, torchio\n",
            "Successfully installed Deprecated-1.2.13 torchio-0.18.73\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzE7_7waF7_S"
      },
      "source": [
        "## Define arrays of patient and outcome data\n",
        "This block allows you to specify the criteria which defines the patient outcome as True or False. It then loops through all the patients in the metadata.csv file, searches for their corresponding image in the image folder, and then adds patient and outcome to either the training, testing, or validation array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KFIqmcw83Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db0f5d2-137b-463e-c415-c27173df5fe6"
      },
      "source": [
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = open(project_folder + \"metadata.csv\")\n",
        "metadata = np.loadtxt(metadata_file, dtype=\"str\", delimiter=\",\")\n",
        "metadata = metadata[1:][:]\n",
        "\n",
        "# Set the values which are used to define the outcome for each patient\n",
        "outcome_type = 1 #int(input(\"Select which outcome you are aiming to predict \\n(1=Locoregional, 2=Distant Metastasis, 3=Death):\"))\n",
        "check_day = 3000 #int(input(\"Select the number of days at which to check for event:\"))\n",
        "which_patients = 1 #int(input(\"Do you want to include patients whose last follow up is before the check day? (no = 0, yes = 1):\"))\n",
        "\n",
        "# Create empty arrays to store patient names and outcomes in\n",
        "patient_with_event = []\n",
        "patient_no_event = []\n",
        "outcomes_train = []\n",
        "outcomes_test = []\n",
        "images = []\n",
        "\n",
        "# Loop through each patient and identify whether they are true or false for the specified outcome from above\n",
        "for patient in metadata:\n",
        "  if (patient[(5+outcome_type)] == \"\") and (int(patient[5]) >= check_day):\n",
        "    # Last follow up after check day, no event\n",
        "    outcome = 0\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 0):\n",
        "    # Last follow up before check day, event unknown\n",
        "    continue\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 1):\n",
        "    outcome = 0\n",
        "  elif int(patient[(5+outcome_type)]) <= check_day:\n",
        "    # Event occurred before or on check day\n",
        "    outcome = 1\n",
        "  else:\n",
        "    # Event occurred after check day\n",
        "    outcome = 0\n",
        "  # No Image file found for patient\n",
        "  if not os.path.exists(project_folder + \"crop/Images/\" + patient[0] + \".nii\"):\n",
        "    print(\"No image found for patient \" + patient[0])\n",
        "    continue\n",
        "  \n",
        "  if outcome == 1:\n",
        "    patient_with_event.append([patient[0], outcome])\n",
        "  else:\n",
        "    patient_no_event.append([patient[0], outcome])\n",
        "\n",
        "# # Make arrays the same length\n",
        "# if len(patient_with_event) < len(patient_no_event):\n",
        "#   new_patient_no_event = random.sample(patient_no_event,len(patient_with_event))\n",
        "#   new_patient_with_event = patient_with_event\n",
        "# elif len(patient_with_event) > len(patient_no_event):\n",
        "#   new_patient_with_event = random.sample(patient_with_event, len(patient_no_event))\n",
        "#   new_patient_no_event = patient_no_event\n",
        "# elif len(patient_with_event) == len(patient_no_event):\n",
        "new_patient_no_event = patient_no_event\n",
        "new_patient_with_event = patient_with_event\n",
        "pos_weights = len(new_patient_no_event)/len(new_patient_with_event)\n",
        "# Add patient name, outcome and image to array\n",
        "seventy_percent_event = int(0.7*len(new_patient_with_event))\n",
        "seventy_percent_no_event = int(0.7*len(new_patient_no_event))\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "train_patients_event = random.sample(new_patient_with_event, seventy_percent_event)\n",
        "train_patients_no_event = random.sample(new_patient_no_event, seventy_percent_no_event)\n",
        "\n",
        "def remove(small_array, original_array):\n",
        "  for i in small_array:\n",
        "    original_array.remove(i)\n",
        "    \n",
        "  return original_array\n",
        "\n",
        "new_patients_with_event = remove(train_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(train_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "\n",
        "fifty_percent_event = int(0.5*len(new_patient_with_event))\n",
        "fifty_percent_no_event = int(0.5*len(new_patient_no_event))\n",
        "\n",
        "validate_patients_event = random.sample(new_patient_with_event, fifty_percent_event)\n",
        "validate_patients_no_event = random.sample(new_patient_no_event, fifty_percent_no_event)\n",
        "\n",
        "new_patient_with_event = remove(validate_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(validate_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "test_patients_event = new_patient_with_event\n",
        "test_patients_no_event = new_patient_no_event\n",
        "\n",
        "outcomes_train = train_patients_event + train_patients_no_event\n",
        "outcomes_validate = validate_patients_event + validate_patients_no_event\n",
        "outcomes_test = test_patients_event + test_patients_no_event\n",
        "\n",
        "print(outcomes_train)\n",
        "print(outcomes_validate)\n",
        "print(outcomes_test)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No image found for patient HN-CHUM-005\n",
            "No image found for patient HN-CHUM-016\n",
            "No image found for patient HN-CHUM-040\n",
            "No image found for patient HN-CHUM-051\n",
            "No image found for patient HN-CHUS-033\n",
            "No image found for patient HN-CHUS-086\n",
            "No image found for patient HN-CHUS-089\n",
            "No image found for patient HN-CHUS-093\n",
            "No image found for patient HN-CHUS-096\n",
            "No image found for patient HN-CHUS-099\n",
            "No image found for patient HN-CHUS-100\n",
            "No image found for patient HN-CHUS-101\n",
            "No image found for patient HN-HGJ-003\n",
            "No image found for patient HN-HGJ-008\n",
            "No image found for patient HN-HGJ-010\n",
            "No image found for patient HN-HGJ-028\n",
            "No image found for patient HN-HGJ-034\n",
            "No image found for patient HN-HGJ-038\n",
            "No image found for patient HN-HGJ-041\n",
            "No image found for patient HN-HGJ-046\n",
            "No image found for patient HN-HGJ-047\n",
            "No image found for patient HN-HGJ-048\n",
            "No image found for patient HN-HGJ-054\n",
            "No image found for patient HN-HGJ-055\n",
            "No image found for patient HN-HGJ-056\n",
            "No image found for patient HN-HGJ-063\n",
            "No image found for patient HN-HGJ-064\n",
            "No image found for patient HN-HGJ-065\n",
            "No image found for patient HN-HGJ-066\n",
            "No image found for patient HN-HGJ-069\n",
            "No image found for patient HN-HGJ-071\n",
            "No image found for patient HN-HGJ-074\n",
            "No image found for patient HN-HGJ-079\n",
            "No image found for patient HN-HGJ-082\n",
            "No image found for patient HN-HGJ-083\n",
            "No image found for patient HN-HGJ-084\n",
            "No image found for patient HN-HGJ-087\n",
            "No image found for patient HN-HGJ-088\n",
            "No image found for patient HN-HGJ-089\n",
            "No image found for patient HN-HGJ-090\n",
            "No image found for patient HN-HGJ-091\n",
            "No image found for patient HN-HGJ-092\n",
            "No image found for patient HN-HMR-003\n",
            "No image found for patient HN-HMR-004\n",
            "No image found for patient HN-HMR-005\n",
            "No image found for patient HN-HMR-007\n",
            "No image found for patient HN-HMR-009\n",
            "No image found for patient HN-HMR-021\n",
            "No image found for patient HN-HMR-024\n",
            "No image found for patient HN-HMR-027\n",
            "No image found for patient HN-HMR-028\n",
            "No image found for patient HN-HMR-029\n",
            "No image found for patient HN-HMR-032\n",
            "No image found for patient HN-HMR-039\n",
            "NO event\n",
            "120\n",
            "WITH event\n",
            "19\n",
            "NO event\n",
            "36\n",
            "WITH event\n",
            "6\n",
            "NO event\n",
            "18\n",
            "WITH event\n",
            "3\n",
            "[['HN-HGJ-001', 1], ['HN-CHUM-020', 1], ['HN-HGJ-045', 1], ['HN-HMR-035', 1], ['HN-HGJ-018', 1], ['HN-CHUM-061', 1], ['HN-HMR-001', 1], ['HN-HMR-031', 1], ['HN-CHUM-053', 1], ['HN-HMR-022', 1], ['HN-HMR-015', 1], ['HN-HMR-038', 1], ['HN-CHUM-002', 1], ['HN-HGJ-036', 0], ['HN-HMR-034', 0], ['HN-HGJ-075', 0], ['HN-CHUM-007', 0], ['HN-HMR-036', 0], ['HN-HGJ-037', 0], ['HN-HGJ-027', 0], ['HN-CHUM-039', 0], ['HN-HGJ-025', 0], ['HN-HMR-025', 0], ['HN-CHUM-006', 0], ['HN-HGJ-007', 0], ['HN-CHUM-012', 0], ['HN-CHUM-010', 0], ['HN-HGJ-020', 0], ['HN-HMR-011', 0], ['HN-CHUM-009', 0], ['HN-HGJ-070', 0], ['HN-HMR-019', 0], ['HN-HGJ-053', 0], ['HN-CHUM-033', 0], ['HN-CHUM-018', 0], ['HN-HGJ-086', 0], ['HN-CHUS-009', 0], ['HN-CHUM-043', 0], ['HN-CHUM-015', 0], ['HN-HGJ-026', 0], ['HN-CHUM-055', 0], ['HN-HGJ-040', 0], ['HN-HMR-006', 0], ['HN-CHUS-005', 0], ['HN-CHUM-034', 0], ['HN-HMR-023', 0], ['HN-HGJ-051', 0], ['HN-HGJ-024', 0], ['HN-HMR-020', 0], ['HN-CHUM-001', 0], ['HN-HGJ-005', 0], ['HN-HGJ-049', 0], ['HN-CHUM-019', 0], ['HN-CHUM-011', 0], ['HN-CHUM-050', 0], ['HN-CHUM-057', 0], ['HN-HGJ-004', 0], ['HN-CHUM-022', 0], ['HN-HGJ-014', 0], ['HN-CHUM-065', 0], ['HN-CHUM-023', 0], ['HN-HGJ-060', 0], ['HN-HMR-018', 0], ['HN-HGJ-043', 0], ['HN-HGJ-042', 0], ['HN-CHUM-017', 0], ['HN-CHUM-035', 0], ['HN-CHUM-008', 0], ['HN-HGJ-030', 0], ['HN-HMR-037', 0], ['HN-CHUM-026', 0], ['HN-HGJ-052', 0], ['HN-HGJ-085', 0], ['HN-HGJ-012', 0], ['HN-CHUM-013', 0], ['HN-HGJ-080', 0], ['HN-CHUM-062', 0], ['HN-HMR-013', 0], ['HN-CHUM-027', 0], ['HN-CHUM-021', 0], ['HN-CHUM-038', 0], ['HN-HGJ-019', 0], ['HN-CHUM-036', 0], ['HN-HGJ-050', 0], ['HN-CHUM-003', 0], ['HN-HGJ-076', 0], ['HN-HGJ-009', 0], ['HN-HGJ-013', 0], ['HN-HGJ-073', 0], ['HN-HGJ-057', 0], ['HN-HMR-033', 0], ['HN-CHUM-042', 0], ['HN-HMR-002', 0], ['HN-CHUM-029', 0], ['HN-HMR-012', 0], ['HN-HMR-014', 0], ['HN-CHUM-041', 0]]\n",
            "[['HN-CHUM-063', 1], ['HN-HGJ-059', 1], ['HN-CHUM-028', 1], ['HN-CHUM-030', 0], ['HN-HMR-016', 0], ['HN-HGJ-022', 0], ['HN-CHUM-032', 0], ['HN-HMR-010', 0], ['HN-CHUM-031', 0], ['HN-HGJ-062', 0], ['HN-CHUS-064', 0], ['HN-HGJ-077', 0], ['HN-HGJ-067', 0], ['HN-HGJ-015', 0], ['HN-HMR-041', 0], ['HN-HMR-026', 0], ['HN-CHUM-049', 0], ['HN-HGJ-006', 0], ['HN-HMR-017', 0], ['HN-HMR-030', 0], ['HN-HGJ-035', 0]]\n",
            "[['HN-HGJ-002', 1], ['HN-HGJ-031', 1], ['HN-HGJ-078', 1], ['HN-CHUM-004', 0], ['HN-CHUM-014', 0], ['HN-CHUM-024', 0], ['HN-CHUM-025', 0], ['HN-CHUM-037', 0], ['HN-CHUM-052', 0], ['HN-CHUM-056', 0], ['HN-CHUS-002', 0], ['HN-HGJ-011', 0], ['HN-HGJ-016', 0], ['HN-HGJ-029', 0], ['HN-HGJ-032', 0], ['HN-HGJ-044', 0], ['HN-HGJ-058', 0], ['HN-HGJ-061', 0], ['HN-HGJ-072', 0], ['HN-HMR-008', 0], ['HN-HMR-040', 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfGjowelNEoF"
      },
      "source": [
        "## Define dataset class\n",
        "This block defines the class on which to build dataset objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjrRiSmq4mBF"
      },
      "source": [
        "# class Normalize(Dataset):\n",
        "#     def __init__(self):\n",
        "#       pass\n",
        "#     def __call__(self, vol):\n",
        "#         vol = (vol-vol.mean())/vol.std()\n",
        "#         return(vol) \n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #Normalize()\n",
        "    ])\n",
        "\n",
        "#window and levelling and this does normalise as well\n",
        "def windowLevelNormalize(image, level, window):\n",
        "    minval = level - window/2\n",
        "    maxval = level + window/2\n",
        "    wld = np.clip(image, minval, maxval)\n",
        "    wld -= minval\n",
        "    wld *= (1 / window)\n",
        "    return wld\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, annotations, img_dir, transform= data_transform, target_transform=None, rotate_augment=False, scale_augment=False, flip_augment=False, shift_augment=True):\n",
        "        self.img_labels = annotations\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.flips = flip_augment\n",
        "        self.rotations = rotate_augment\n",
        "        self.scaling = scale_augment\n",
        "        self.shifts = shift_augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels[idx][0]+\".nii\")\n",
        "        image_sitk = sitk.ReadImage(img_path)\n",
        "        image = sitk.GetArrayFromImage(image_sitk)\n",
        "        label = self.img_labels[idx][1]\n",
        "        print(image.shape)\n",
        "        \n",
        "        if self.shifts and random.random()<0.5:\n",
        "            mx_x, mx_yz = 10, 10\n",
        "            # find shift values\n",
        "            cc_shift, ap_shift, lr_shift = random.randint(-mx_x,mx_x), random.randint(-mx_yz,mx_yz), random.randint(-mx_yz,mx_yz)\n",
        "            # pad for shifting into\n",
        "            image = np.pad(image, pad_width=((mx_x,mx_x),(mx_yz,mx_yz),(mx_yz,mx_yz)), mode='constant', constant_values=-1024)\n",
        "            # crop to complete shift\n",
        "            image = image[mx_x+cc_shift:246+mx_x+cc_shift, mx_yz+ap_shift:246+mx_yz+ap_shift, mx_yz+lr_shift:246+mx_yz+lr_shift]\n",
        "            print(image.shape)\n",
        "            print('shift')\n",
        "\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        \n",
        "        if self.rotations and random.random()<0.5:\n",
        "            # taking implementation from my 3DSegmentationNetwork which can be applied -> rotations in the axial plane only I should think? -10->10 degrees?\n",
        "            roll_angle = np.clip(np.random.normal(loc=0,scale=3), -10, 10) # make -10,10\n",
        "            image = self.rotation(image, roll_angle, rotation_plane=(1,2)) # (1,2) originally\n",
        "            print('rotation')\n",
        "            \n",
        "        if self.scaling and random.random()<0.5:\n",
        "            # same here -> zoom between 80-120%\n",
        "            scale_factor = np.clip(np.random.normal(loc=1.0,scale=0.5), 0.8, 1.2) # original scale = 0.05\n",
        "            image = self.scale(image, scale_factor)\n",
        "            print('scale')\n",
        "            \n",
        "        if self.flips and random.random()<0.5:\n",
        "            image = self.flip(image)\n",
        "            print('horizontal flip')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # window and levelling\n",
        "        image = windowLevelNormalize(image, level=40, window=50)\n",
        " \n",
        "        return image, label\n",
        "    def scale(self, image, scale_factor):\n",
        "        # scale the image or mask using scipy zoom function\n",
        "        order, cval = (3, 0) # changed from -1024 to 0\n",
        "        height, width, depth = image.shape\n",
        "        zheight = int(np.round(scale_factor*height))\n",
        "        zwidth = int(np.round(scale_factor*width))\n",
        "        zdepth = int(np.round(scale_factor*depth))\n",
        "        # zoomed out\n",
        "        if scale_factor < 1.0:\n",
        "            new_image = np.full_like(image, cval)\n",
        "            ud_buffer = (height-zheight) // 2\n",
        "            ap_buffer = (width-zwidth) // 2\n",
        "            lr_buffer = (depth-zdepth) // 2\n",
        "            new_image[ud_buffer:ud_buffer+zheight, ap_buffer:ap_buffer+zwidth, lr_buffer:lr_buffer+zdepth] = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            return new_image\n",
        "        elif scale_factor > 1.0:\n",
        "            new_image = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            ud_extra = (new_image.shape[0] - height) // 2\n",
        "            ap_extra = (new_image.shape[1] - width) // 2\n",
        "            lr_extra = (new_image.shape[2] - depth) // 2\n",
        "            new_image = new_image[ud_extra:ud_extra+height, ap_extra:ap_extra+width, lr_extra:lr_extra+depth]\n",
        "            return new_image\n",
        "        return image\n",
        "      \n",
        "    def rotation(self, image, rotation_angle, rotation_plane):\n",
        "        # rotate the image using scipy rotate function\n",
        "        order, cval = (3, -1024) # changed from -1024 to 0\n",
        "        return rotate(input=image, angle=rotation_angle, axes=rotation_plane, reshape=False, order=order, mode='constant', cval=cval)\n",
        "\n",
        "    def flip(self, image):\n",
        "        #hflip = np.fliplr(image)\n",
        "        #image = (reversed(image[1:]))\n",
        "        image = np.flipud(image).copy()\n",
        "        return image\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiSjndmcNfSA"
      },
      "source": [
        "## Build Datasets\n",
        "This block uses the class and arrays defined previously to build datasets for training, testing and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDoF-cH6xw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1a21dd-1b71-4ac9-e7ea-43aaf2df848b"
      },
      "source": [
        "\n",
        "training_data = ImageDataset(outcomes_train, project_folder + \"crop/Images/\")\n",
        "validation_data = ImageDataset(outcomes_validate, project_folder + \"crop/Images/\")\n",
        "test_data = ImageDataset(outcomes_test, project_folder + \"crop/Images/\")\n",
        "print(len(training_data))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7jDjfvKOCWc"
      },
      "source": [
        "## View binary masks in 3d\n",
        "This block allows you to view a binary mask from the image in 3d by extracting the image from a given dataset. This helps to confirm that the data has not been affected by reading in to pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uideXDzjvdS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "6a1caab0-1a5b-470c-b18d-9ee1966a7dcf"
      },
      "source": [
        "# Set which dataset to look at, and the index of the patient to view\n",
        "dataset = training_data\n",
        "index = 9\n",
        "print('flipud')\n",
        "print(outcomes_train[index])\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "#print(dataset[0])\n",
        "\n",
        "#array = dataset[index][0].numpy()\n",
        "array = dataset[index][0]\n",
        "print(type(array))\n",
        "print('array shape')\n",
        "print(array.shape)\n",
        "x,y,z = np.where(array > 0.) # what >=\n",
        "ax.scatter(x, y, z, c=z, alpha=1)\n",
        "\n",
        "ax.set_xlim(0,246)\n",
        "ax.set_ylim(0,246)\n",
        "ax.set_zlim(0,246)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flipud\n",
            "['HN-HMR-022', 1]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "<class 'torch.Tensor'>\n",
            "array shape\n",
            "torch.Size([246, 246, 246])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 246.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Chh969QU-u"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEBaWTtLN_A_"
      },
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=2, shuffle=True)\n",
        "validate_dataloader = DataLoader(validation_data, batch_size=2, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=2, shuffle=True)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4hpRnHALqS"
      },
      "source": [
        "# Define CNN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSj3U3DL5NGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7577c6-9ade-41d2-bc56-dec9cb625195"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    out1 = 4\n",
        "    out2 = 4\n",
        "    out3 = 2\n",
        "    self.cnn_layers = nn.Sequential(\n",
        "      # Layer 1\n",
        "      nn.Conv3d(1,out1,4,1,1),\n",
        "      nn.BatchNorm3d(out1),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 2\n",
        "      nn.Conv3d(out1, out2, 4, 1, 1),\n",
        "      nn.BatchNorm3d(out2),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 3\n",
        "      nn.Conv3d(out2, out3, 4, 1, 1),\n",
        "      nn.BatchNorm3d(out3),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    self.linear_layers = nn.Sequential(\n",
        "      nn.Linear(48778, 2)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.cnn_layers(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.linear_layers(x)\n",
        "    return x\n",
        "\n",
        "model = CNN().to(device)\n",
        "print(model)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv3d(1, 4, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv3d(4, 4, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (5): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv3d(4, 2, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (9): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (11): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=48778, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imIsJYkHAVEe"
      },
      "source": [
        "# Define Train and Test Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RhWjamUGtE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049e1d9d-74d6-4ab4-b92c-26150fa66256"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "        X = X.float()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        #y = reshape(y, (y.shape[0],1))\n",
        "        hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "        for index in range(len(y)):\n",
        "          if y[index] == 0:\n",
        "            hot_y[index,0] = 1\n",
        "            hot_y[index,1] = 0\n",
        "          elif y[index] == 1:\n",
        "            hot_y[index,0] = 0\n",
        "            hot_y[index,1] = 1\n",
        "      \n",
        "        print(hot_y)\n",
        "        pred = model(X)\n",
        "        torch.squeeze(pred)\n",
        "        loss = loss_fn(pred, hot_y.float())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print results after each batch        \n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss\n",
        "\n",
        "def validate_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    validate_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "            \n",
        "            pred = model(X)\n",
        "            # print(f'pred: {pred}')\n",
        "            # print(f'hot_y: {hot_y}')\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            # print(f'predictions: {predictions}')\n",
        "            # print(f'targets: {targets}')\n",
        "            print(f'Correct this batch = {(predictions == targets).sum().item()}')\n",
        "\n",
        "            torch.squeeze(pred)\n",
        "            validate_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            # correct += (pred.argmax(1) == hot_y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    validate_loss /= num_batches\n",
        "    correct /= size\n",
        "    accuracy = 100*correct\n",
        "    print(f\"Validate Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validate_loss:>8f} \\n\")\n",
        "    return validate_loss, accuracy\n",
        "\n",
        "learning_rate = 0.001\n",
        "# defining the model\n",
        "model = CNN()\n",
        "# defining the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# defining the loss function\n",
        "pos_weights = torch.tensor(pos_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weights)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.to(device)\n",
        "loss_fn.to(device)\n",
        "\n",
        "summary(model=model, input_size=(1, 246, 246, 246), batch_size=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [2, 4, 245, 245, 245]             260\n",
            "       BatchNorm3d-2      [2, 4, 245, 245, 245]               8\n",
            "         LeakyReLU-3      [2, 4, 245, 245, 245]               0\n",
            "         MaxPool3d-4      [2, 4, 122, 122, 122]               0\n",
            "            Conv3d-5      [2, 4, 121, 121, 121]           1,028\n",
            "       BatchNorm3d-6      [2, 4, 121, 121, 121]               8\n",
            "         LeakyReLU-7      [2, 4, 121, 121, 121]               0\n",
            "         MaxPool3d-8         [2, 4, 60, 60, 60]               0\n",
            "            Conv3d-9         [2, 2, 59, 59, 59]             514\n",
            "      BatchNorm3d-10         [2, 2, 59, 59, 59]               4\n",
            "        LeakyReLU-11         [2, 2, 59, 59, 59]               0\n",
            "        MaxPool3d-12         [2, 2, 29, 29, 29]               0\n",
            "           Linear-13                     [2, 2]          97,558\n",
            "================================================================\n",
            "Total params: 99,380\n",
            "Trainable params: 99,380\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 113.58\n",
            "Forward/backward pass size (MB): 3160.72\n",
            "Params size (MB): 0.38\n",
            "Estimated Total Size (MB): 3274.67\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w-_C54rIh_Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir = content/logsdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfKkG2-Gh_p1",
        "outputId": "c77d3bbc-1b94-427c-d491-36f0b4394aa1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
            "                   [--host ADDR] [--bind_all] [--port PORT]\n",
            "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
            "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
            "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
            "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
            "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
            "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
            "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
            "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
            "                   [--reload_multifile BOOL]\n",
            "                   [--reload_multifile_inactive_secs SECONDS]\n",
            "                   [--generic_data TYPE]\n",
            "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
            "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
            "                   [--whatif-data-dir PATH]\n",
            "                   {serve,dev} ...\n",
            "tensorboard: error: invalid choice: 'content/logsdir' (choose from 'serve', 'dev')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqQYmcaAe-Q"
      },
      "source": [
        "# Run Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23uXlNlG9ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7a9e63-221d-4866-c7a9-bc2d5c1a5ffa"
      },
      "source": [
        "epochs = 2\n",
        "train_losses = [[],[]]\n",
        "validate_losses = [[],[]]\n",
        "validate_accuracies = [[],[]]\n",
        "\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    validate_loss = validate_loop(validate_dataloader, model, loss_fn)\n",
        "\n",
        "    train_losses[0].append(t)\n",
        "    train_losses[1].append(train_loss)\n",
        "    validate_losses[0].append(t)\n",
        "    validate_losses[1].append(validate_loss[0])\n",
        "    validate_accuracies[0].append(t)\n",
        "    validate_accuracies[1].append(validate_loss[1])\n",
        "\n",
        "    writer.add_scalar('Loss/train', train_loss, t)\n",
        "    #writer.add_scalar(\"Loss/train\", )\n",
        "\n",
        "writer.close()\n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 6.062706  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 110.009888  [    2/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 3.091027  [    4/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 5.329275  [    6/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.830175  [    8/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 5.657502  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.719163  [   12/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.132007  [   14/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.484379  [   16/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.663329  [   18/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 7.210060  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.951065  [   22/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.011586  [   24/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.592813  [   26/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.357227  [   28/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.313007  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.230832  [   32/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 8.889031  [   34/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.741766  [   36/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.737539  [   38/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.892412  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.281009  [   42/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 9.808914  [   44/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.469893  [   46/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 9.755090  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 4.521649  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 4.535598  [   52/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 3.338458  [   54/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 5.129471  [   56/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 3.248744  [   58/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.302126  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.803706  [   62/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 7.266628  [   64/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.241890  [   66/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.077025  [   68/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.101706  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.724203  [   72/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.736556  [   74/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.381660  [   76/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 9.223904  [   78/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.963082  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.965086  [   82/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.691262  [   84/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.581833  [   86/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.314658  [   88/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.333375  [   90/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.216880  [   92/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 11.583342  [   94/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.]], device='cuda:0')\n",
            "loss: 1.015837  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.749936 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.843772  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.758428  [    2/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.444763  [    4/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.418094  [    6/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 11.947597  [    8/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 5.184645  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.244604  [   12/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.903852  [   14/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.300292  [   16/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 9.389120  [   18/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.223164  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.252107  [   22/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.020477  [   24/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 7.677984  [   26/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.888268  [   28/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.987068  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.849887  [   32/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.632381  [   34/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 9.666529  [   36/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.606470  [   38/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.545598  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 8.420999  [   42/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 6.581370  [   44/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.851146  [   46/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.574353  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.333181  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 6.594234  [   52/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.253796  [   54/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.324210  [   56/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.078171  [   58/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.741104  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.454409  [   62/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 9.571516  [   64/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.172012  [   66/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.114669  [   68/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 7.342661  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.477593  [   72/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 5.771012  [   74/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.134834  [   76/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.428941  [   78/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.860882  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.953251  [   82/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 8.687510  [   84/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.047062  [   86/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 5.959142  [   88/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.108335  [   90/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.215094  [   92/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.962678  [   94/   97]\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.]], device='cuda:0')\n",
            "loss: 0.643116  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "shift\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "Correct this batch = 0\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 3.511928 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "NUCtjrHb6JAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "                \n",
        "            pred = model(X)\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            torch.squeeze(pred)\n",
        "            #test_loss += loss_fn(pred, y.float()).item()\n",
        "            test_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n",
        "\n",
        "test_loop(test_dataloader, model)"
      ],
      "metadata": {
        "id": "MEuNq5Z-6IV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZBw098GbFou"
      },
      "source": [
        "# Plot Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmncBB6bEip"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(train_losses[0], train_losses[1], label=\"Train Loss\")\n",
        "ax.plot(validate_losses[0], validate_losses[1], label=\"Validate Loss\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Accuracies"
      ],
      "metadata": {
        "id": "fFAdAFAECQ-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(validate_accuracies[0], validate_accuracies[1], label=\"Validate Accuracies\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy / %')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "2Q8g4JowCPkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}