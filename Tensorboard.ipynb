{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jban28/MPhys-Radiotherapy-49/blob/main/Tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E8F_po0K_Wu"
      },
      "source": [
        "## Pre-requisites\n",
        "This block makes the necessary installations and imports for the rest of the code blocks to run, connects to the GPU if one is available, and specifies the location of the folder containing the data. That data folder should contain a sub-folder containing all nifti files, along with a metadata csv file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5AFQEgZc7XUV",
        "outputId": "1af52f5a-71e4-4209-85b0-1a995d84d186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Egh9uSI77b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3eb0201-650f-4770-ea55-44c192db0973"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "!pip install kornia\n",
        "!pip install utils\n",
        "!pip install torchio\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "import torchio as tio\n",
        "import kornia.augmentation as K\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch.nn import LeakyReLU\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "from scipy.ndimage import zoom, rotate\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#from torch.utils.data import windowLevelNormalize\n",
        "\n",
        "\n",
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "# Specify project folder location\n",
        "#project_folder = \"/content/drive/My Drive/Degree/MPhys/Data/\"\n",
        "project_folder = \"/content/drive/My Drive/Data/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (0.6.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.7)\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchio in /usr/local/lib/python3.7/dist-packages (0.18.73)\n",
            "Requirement already satisfied: SimpleITK!=2.0.* in /usr/local/lib/python3.7/dist-packages (from torchio) (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.21.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from torchio) (7.1.2)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from torchio) (0.5.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchio) (4.62.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.7/dist-packages (from torchio) (1.2.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->torchio) (1.13.3)\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzE7_7waF7_S"
      },
      "source": [
        "## Define arrays of patient and outcome data\n",
        "This block allows you to specify the criteria which defines the patient outcome as True or False. It then loops through all the patients in the metadata.csv file, searches for their corresponding image in the image folder, and then adds patient and outcome to either the training, testing, or validation array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KFIqmcw83Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac47db8-004d-45d8-d55f-43144a3096bd"
      },
      "source": [
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = open(project_folder + \"metadata.csv\")\n",
        "metadata = np.loadtxt(metadata_file, dtype=\"str\", delimiter=\",\")\n",
        "metadata = metadata[1:][:]\n",
        "\n",
        "# Set the values which are used to define the outcome for each patient\n",
        "outcome_type = 1 #int(input(\"Select which outcome you are aiming to predict \\n(1=Locoregional, 2=Distant Metastasis, 3=Death):\"))\n",
        "check_day = 3000 #int(input(\"Select the number of days at which to check for event:\"))\n",
        "which_patients = 1 #int(input(\"Do you want to include patients whose last follow up is before the check day? (no = 0, yes = 1):\"))\n",
        "\n",
        "# Create empty arrays to store patient names and outcomes in\n",
        "patient_with_event = []\n",
        "patient_no_event = []\n",
        "outcomes_train = []\n",
        "outcomes_test = []\n",
        "images = []\n",
        "\n",
        "# Loop through each patient and identify whether they are true or false for the specified outcome from above\n",
        "for patient in metadata:\n",
        "  if (patient[(5+outcome_type)] == \"\") and (int(patient[5]) >= check_day):\n",
        "    # Last follow up after check day, no event\n",
        "    outcome = 0\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 0):\n",
        "    # Last follow up before check day, event unknown\n",
        "    continue\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 1):\n",
        "    outcome = 0\n",
        "  elif int(patient[(5+outcome_type)]) <= check_day:\n",
        "    # Event occurred before or on check day\n",
        "    outcome = 1\n",
        "  else:\n",
        "    # Event occurred after check day\n",
        "    outcome = 0\n",
        "  # No Image file found for patient\n",
        "  if not os.path.exists(project_folder + \"crop/Images/\" + patient[0] + \".nii\"):\n",
        "    print(\"No image found for patient \" + patient[0])\n",
        "    continue\n",
        "  \n",
        "  if outcome == 1:\n",
        "    patient_with_event.append([patient[0], outcome])\n",
        "  else:\n",
        "    patient_no_event.append([patient[0], outcome])\n",
        "\n",
        "# # Make arrays the same length\n",
        "# if len(patient_with_event) < len(patient_no_event):\n",
        "#   new_patient_no_event = random.sample(patient_no_event,len(patient_with_event))\n",
        "#   new_patient_with_event = patient_with_event\n",
        "# elif len(patient_with_event) > len(patient_no_event):\n",
        "#   new_patient_with_event = random.sample(patient_with_event, len(patient_no_event))\n",
        "#   new_patient_no_event = patient_no_event\n",
        "# elif len(patient_with_event) == len(patient_no_event):\n",
        "new_patient_no_event = patient_no_event\n",
        "new_patient_with_event = patient_with_event\n",
        "pos_weights = len(new_patient_no_event)/len(new_patient_with_event)\n",
        "# Add patient name, outcome and image to array\n",
        "seventy_percent_event = int(0.7*len(new_patient_with_event))\n",
        "seventy_percent_no_event = int(0.7*len(new_patient_no_event))\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "train_patients_event = random.sample(new_patient_with_event, seventy_percent_event)\n",
        "train_patients_no_event = random.sample(new_patient_no_event, seventy_percent_no_event)\n",
        "\n",
        "def remove(small_array, original_array):\n",
        "  for i in small_array:\n",
        "    original_array.remove(i)\n",
        "    \n",
        "  return original_array\n",
        "\n",
        "new_patients_with_event = remove(train_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(train_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "\n",
        "fifty_percent_event = int(0.5*len(new_patient_with_event))\n",
        "fifty_percent_no_event = int(0.5*len(new_patient_no_event))\n",
        "\n",
        "validate_patients_event = random.sample(new_patient_with_event, fifty_percent_event)\n",
        "validate_patients_no_event = random.sample(new_patient_no_event, fifty_percent_no_event)\n",
        "\n",
        "new_patient_with_event = remove(validate_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(validate_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "test_patients_event = new_patient_with_event\n",
        "test_patients_no_event = new_patient_no_event\n",
        "\n",
        "outcomes_train = train_patients_event + train_patients_no_event\n",
        "outcomes_validate = validate_patients_event + validate_patients_no_event\n",
        "outcomes_test = test_patients_event + test_patients_no_event\n",
        "\n",
        "print(outcomes_train)\n",
        "print(outcomes_validate)\n",
        "print(outcomes_test)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No image found for patient HN-CHUM-005\n",
            "No image found for patient HN-CHUM-016\n",
            "No image found for patient HN-CHUM-040\n",
            "No image found for patient HN-CHUM-051\n",
            "No image found for patient HN-CHUS-033\n",
            "No image found for patient HN-CHUS-086\n",
            "No image found for patient HN-CHUS-089\n",
            "No image found for patient HN-CHUS-093\n",
            "No image found for patient HN-CHUS-096\n",
            "No image found for patient HN-CHUS-099\n",
            "No image found for patient HN-CHUS-100\n",
            "No image found for patient HN-CHUS-101\n",
            "No image found for patient HN-HGJ-003\n",
            "No image found for patient HN-HGJ-008\n",
            "No image found for patient HN-HGJ-010\n",
            "No image found for patient HN-HGJ-028\n",
            "No image found for patient HN-HGJ-034\n",
            "No image found for patient HN-HGJ-038\n",
            "No image found for patient HN-HGJ-041\n",
            "No image found for patient HN-HGJ-046\n",
            "No image found for patient HN-HGJ-047\n",
            "No image found for patient HN-HGJ-048\n",
            "No image found for patient HN-HGJ-054\n",
            "No image found for patient HN-HGJ-055\n",
            "No image found for patient HN-HGJ-056\n",
            "No image found for patient HN-HGJ-063\n",
            "No image found for patient HN-HGJ-064\n",
            "No image found for patient HN-HGJ-065\n",
            "No image found for patient HN-HGJ-066\n",
            "No image found for patient HN-HGJ-069\n",
            "No image found for patient HN-HGJ-071\n",
            "No image found for patient HN-HGJ-074\n",
            "No image found for patient HN-HGJ-079\n",
            "No image found for patient HN-HGJ-082\n",
            "No image found for patient HN-HGJ-083\n",
            "No image found for patient HN-HGJ-084\n",
            "No image found for patient HN-HGJ-087\n",
            "No image found for patient HN-HGJ-088\n",
            "No image found for patient HN-HGJ-089\n",
            "No image found for patient HN-HGJ-090\n",
            "No image found for patient HN-HGJ-091\n",
            "No image found for patient HN-HGJ-092\n",
            "No image found for patient HN-HMR-003\n",
            "No image found for patient HN-HMR-004\n",
            "No image found for patient HN-HMR-005\n",
            "No image found for patient HN-HMR-007\n",
            "No image found for patient HN-HMR-009\n",
            "No image found for patient HN-HMR-021\n",
            "No image found for patient HN-HMR-024\n",
            "No image found for patient HN-HMR-027\n",
            "No image found for patient HN-HMR-028\n",
            "No image found for patient HN-HMR-029\n",
            "No image found for patient HN-HMR-032\n",
            "No image found for patient HN-HMR-039\n",
            "NO event\n",
            "120\n",
            "WITH event\n",
            "19\n",
            "NO event\n",
            "36\n",
            "WITH event\n",
            "6\n",
            "NO event\n",
            "18\n",
            "WITH event\n",
            "3\n",
            "[['HN-CHUM-020', 1], ['HN-HMR-001', 1], ['HN-HGJ-059', 1], ['HN-CHUM-063', 1], ['HN-HGJ-018', 1], ['HN-HMR-031', 1], ['HN-HGJ-045', 1], ['HN-HGJ-002', 1], ['HN-CHUM-002', 1], ['HN-HMR-035', 1], ['HN-HGJ-031', 1], ['HN-HMR-022', 1], ['HN-HMR-038', 1], ['HN-CHUM-030', 0], ['HN-HGJ-053', 0], ['HN-CHUM-003', 0], ['HN-CHUM-050', 0], ['HN-HGJ-057', 0], ['HN-HGJ-072', 0], ['HN-CHUM-014', 0], ['HN-CHUM-039', 0], ['HN-HGJ-042', 0], ['HN-CHUM-035', 0], ['HN-CHUM-018', 0], ['HN-HMR-016', 0], ['HN-CHUM-022', 0], ['HN-HGJ-036', 0], ['HN-HMR-040', 0], ['HN-HGJ-011', 0], ['HN-CHUM-031', 0], ['HN-CHUM-032', 0], ['HN-HGJ-014', 0], ['HN-CHUS-009', 0], ['HN-CHUM-025', 0], ['HN-HGJ-061', 0], ['HN-HGJ-073', 0], ['HN-HGJ-019', 0], ['HN-CHUS-002', 0], ['HN-CHUM-037', 0], ['HN-CHUM-012', 0], ['HN-CHUM-013', 0], ['HN-HGJ-012', 0], ['HN-HMR-025', 0], ['HN-HGJ-052', 0], ['HN-HMR-012', 0], ['HN-CHUM-029', 0], ['HN-HMR-010', 0], ['HN-HGJ-020', 0], ['HN-HMR-034', 0], ['HN-HGJ-051', 0], ['HN-HMR-013', 0], ['HN-HGJ-026', 0], ['HN-CHUM-065', 0], ['HN-CHUM-026', 0], ['HN-CHUM-021', 0], ['HN-CHUM-017', 0], ['HN-HGJ-070', 0], ['HN-HMR-033', 0], ['HN-HMR-030', 0], ['HN-HGJ-013', 0], ['HN-CHUS-064', 0], ['HN-HMR-014', 0], ['HN-CHUM-006', 0], ['HN-HGJ-058', 0], ['HN-HGJ-060', 0], ['HN-HGJ-080', 0], ['HN-CHUM-043', 0], ['HN-CHUM-015', 0], ['HN-CHUM-056', 0], ['HN-HGJ-043', 0], ['HN-HGJ-024', 0], ['HN-CHUM-038', 0], ['HN-HMR-020', 0], ['HN-CHUM-034', 0], ['HN-HGJ-032', 0], ['HN-HGJ-086', 0], ['HN-CHUM-009', 0], ['HN-CHUM-041', 0], ['HN-HGJ-029', 0], ['HN-CHUM-057', 0], ['HN-HGJ-022', 0], ['HN-CHUM-036', 0], ['HN-CHUS-005', 0], ['HN-CHUM-027', 0], ['HN-CHUM-024', 0], ['HN-CHUM-010', 0], ['HN-HMR-006', 0], ['HN-CHUM-055', 0], ['HN-HMR-026', 0], ['HN-CHUM-049', 0], ['HN-CHUM-011', 0], ['HN-CHUM-062', 0], ['HN-HMR-017', 0], ['HN-CHUM-008', 0], ['HN-HGJ-050', 0], ['HN-CHUM-004', 0], ['HN-HGJ-009', 0]]\n",
            "[['HN-CHUM-053', 1], ['HN-CHUM-028', 1], ['HN-HGJ-078', 1], ['HN-CHUM-023', 0], ['HN-HGJ-004', 0], ['HN-HGJ-076', 0], ['HN-HGJ-040', 0], ['HN-HMR-037', 0], ['HN-HMR-036', 0], ['HN-HMR-002', 0], ['HN-HGJ-030', 0], ['HN-CHUM-042', 0], ['HN-HMR-008', 0], ['HN-CHUM-033', 0], ['HN-HMR-041', 0], ['HN-HGJ-027', 0], ['HN-HGJ-067', 0], ['HN-HGJ-035', 0], ['HN-HGJ-085', 0], ['HN-HGJ-075', 0], ['HN-HGJ-015', 0]]\n",
            "[['HN-CHUM-061', 1], ['HN-HGJ-001', 1], ['HN-HMR-015', 1], ['HN-CHUM-001', 0], ['HN-CHUM-007', 0], ['HN-CHUM-019', 0], ['HN-CHUM-052', 0], ['HN-HGJ-005', 0], ['HN-HGJ-006', 0], ['HN-HGJ-007', 0], ['HN-HGJ-016', 0], ['HN-HGJ-025', 0], ['HN-HGJ-037', 0], ['HN-HGJ-044', 0], ['HN-HGJ-049', 0], ['HN-HGJ-062', 0], ['HN-HGJ-077', 0], ['HN-HMR-011', 0], ['HN-HMR-018', 0], ['HN-HMR-019', 0], ['HN-HMR-023', 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfGjowelNEoF"
      },
      "source": [
        "## Define dataset class\n",
        "This block defines the class on which to build dataset objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjrRiSmq4mBF"
      },
      "source": [
        "# class Normalize(Dataset):\n",
        "#     def __init__(self):\n",
        "#       pass\n",
        "#     def __call__(self, vol):\n",
        "#         vol = (vol-vol.mean())/vol.std()\n",
        "#         return(vol) \n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #Normalize()\n",
        "    ])\n",
        "\n",
        "#window and levelling and this does normalise as well\n",
        "def windowLevelNormalize(image, level, window):\n",
        "    minval = level - window/2\n",
        "    maxval = level + window/2\n",
        "    wld = np.clip(image, minval, maxval)\n",
        "    wld -= minval\n",
        "    wld *= (1 / window)\n",
        "    return wld\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, annotations, img_dir, transform= data_transform, target_transform=None, rotate_augment=True, scale_augment=True, flip_augment=True, shift_augment=True):\n",
        "        self.img_labels = annotations\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.flips = flip_augment\n",
        "        self.rotations = rotate_augment\n",
        "        self.scaling = scale_augment\n",
        "        self.shifts = shift_augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels[idx][0]+\".nii\")\n",
        "        image_sitk = sitk.ReadImage(img_path)\n",
        "        image = sitk.GetArrayFromImage(image_sitk)\n",
        "        label = self.img_labels[idx][1]\n",
        "        print(image.shape)\n",
        "        \n",
        "        if self.shifts and random.random()<0.5:\n",
        "            mx_x, mx_yz = 10, 10\n",
        "            # find shift values\n",
        "            cc_shift, ap_shift, lr_shift = random.randint(-mx_x,mx_x), random.randint(-mx_yz,mx_yz), random.randint(-mx_yz,mx_yz)\n",
        "            # pad for shifting into\n",
        "            image = np.pad(image, pad_width=((mx_x,mx_x),(mx_yz,mx_yz),(mx_yz,mx_yz)), mode='constant', constant_values=-1024)\n",
        "            # crop to complete shift\n",
        "            image = image[mx_x+cc_shift:246+mx_x+cc_shift, mx_yz+ap_shift:246+mx_yz+ap_shift, mx_yz+lr_shift:246+mx_yz+lr_shift]\n",
        "            #print(image.shape)\n",
        "            #print('shift')\n",
        "\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        \n",
        "        if self.rotations and random.random()<0.5:\n",
        "            # taking implementation from my 3DSegmentationNetwork which can be applied -> rotations in the axial plane only I should think? -10->10 degrees?\n",
        "            roll_angle = np.clip(np.random.normal(loc=0,scale=3), -10, 10) # make -10,10\n",
        "            image = self.rotation(image, roll_angle, rotation_plane=(1,2)) # (1,2) originally\n",
        "            #print('rotation')\n",
        "            \n",
        "        if self.scaling and random.random()<0.5:\n",
        "            # same here -> zoom between 80-120%\n",
        "            scale_factor = np.clip(np.random.normal(loc=1.0,scale=0.5), 0.8, 1.2) # original scale = 0.05\n",
        "            image = self.scale(image, scale_factor)\n",
        "            #print('scale')\n",
        "            \n",
        "        if self.flips and random.random()<0.5:\n",
        "            image = self.flip(image)\n",
        "            #print('horizontal flip')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # window and levelling\n",
        "        image = windowLevelNormalize(image, level=40, window=50)\n",
        " \n",
        "        return image, label\n",
        "    def scale(self, image, scale_factor):\n",
        "        # scale the image or mask using scipy zoom function\n",
        "        order, cval = (3, 0) # changed from -1024 to 0\n",
        "        height, width, depth = image.shape\n",
        "        zheight = int(np.round(scale_factor*height))\n",
        "        zwidth = int(np.round(scale_factor*width))\n",
        "        zdepth = int(np.round(scale_factor*depth))\n",
        "        # zoomed out\n",
        "        if scale_factor < 1.0:\n",
        "            new_image = np.full_like(image, cval)\n",
        "            ud_buffer = (height-zheight) // 2\n",
        "            ap_buffer = (width-zwidth) // 2\n",
        "            lr_buffer = (depth-zdepth) // 2\n",
        "            new_image[ud_buffer:ud_buffer+zheight, ap_buffer:ap_buffer+zwidth, lr_buffer:lr_buffer+zdepth] = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            return new_image\n",
        "        elif scale_factor > 1.0:\n",
        "            new_image = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            ud_extra = (new_image.shape[0] - height) // 2\n",
        "            ap_extra = (new_image.shape[1] - width) // 2\n",
        "            lr_extra = (new_image.shape[2] - depth) // 2\n",
        "            new_image = new_image[ud_extra:ud_extra+height, ap_extra:ap_extra+width, lr_extra:lr_extra+depth]\n",
        "            return new_image\n",
        "        return image\n",
        "      \n",
        "    def rotation(self, image, rotation_angle, rotation_plane):\n",
        "        # rotate the image using scipy rotate function\n",
        "        order, cval = (3, -1024) # changed from -1024 to 0\n",
        "        return rotate(input=image, angle=rotation_angle, axes=rotation_plane, reshape=False, order=order, mode='constant', cval=cval)\n",
        "\n",
        "    def flip(self, image):\n",
        "        #hflip = np.fliplr(image)\n",
        "        #image = (reversed(image[1:]))\n",
        "        image = np.flipud(image).copy()\n",
        "        return image\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiSjndmcNfSA"
      },
      "source": [
        "## Build Datasets\n",
        "This block uses the class and arrays defined previously to build datasets for training, testing and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDoF-cH6xw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a19895-18fb-4f0b-b707-88b8d71f7a49"
      },
      "source": [
        "\n",
        "training_data = ImageDataset(outcomes_train, project_folder + \"crop/Images/\")\n",
        "validation_data = ImageDataset(outcomes_validate, project_folder + \"crop/Images/\", rotate_augment=False, scale_augment=False, flip_augment=False, shift_augment=False)\n",
        "test_data = ImageDataset(outcomes_test, project_folder + \"crop/Images/\", rotate_augment=False, scale_augment=False, flip_augment=False, shift_augment=False)\n",
        "print(len(training_data))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7jDjfvKOCWc"
      },
      "source": [
        "## View binary masks in 3d\n",
        "This block allows you to view a binary mask from the image in 3d by extracting the image from a given dataset. This helps to confirm that the data has not been affected by reading in to pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uideXDzjvdS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "2e5175d8-16e5-4582-878f-b11ae3cae47c"
      },
      "source": [
        "# Set which dataset to look at, and the index of the patient to view\n",
        "dataset = training_data\n",
        "index = 9\n",
        "print('flipud')\n",
        "print(outcomes_train[index])\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "#print(dataset[0])\n",
        "\n",
        "#array = dataset[index][0].numpy()\n",
        "array = dataset[index][0]\n",
        "print(type(array))\n",
        "print('array shape')\n",
        "print(array.shape)\n",
        "x,y,z = np.where(array > 0.) # what >=\n",
        "ax.scatter(x, y, z, c=z, alpha=1)\n",
        "\n",
        "ax.set_xlim(0,246)\n",
        "ax.set_ylim(0,246)\n",
        "ax.set_zlim(0,246)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flipud\n",
            "['HN-HMR-035', 1]\n",
            "(246, 246, 246)\n",
            "<class 'torch.Tensor'>\n",
            "array shape\n",
            "torch.Size([246, 246, 246])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 246.0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Chh969QU-u"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEBaWTtLN_A_"
      },
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=2, shuffle=True)\n",
        "validate_dataloader = DataLoader(validation_data, batch_size=2, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=2, shuffle=True)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4hpRnHALqS"
      },
      "source": [
        "# Define CNN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSj3U3DL5NGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dd7771-63f3-484a-a809-eb55c6f20f4f"
      },
      "source": [
        "# class CNN(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(CNN, self).__init__()\n",
        "#     out1 = 4\n",
        "#     out2 = 4\n",
        "#     out3 = 2\n",
        "#     self.cnn_layers = nn.Sequential(\n",
        "#       # Layer 1\n",
        "#       nn.Conv3d(1,out1,4,1,1),\n",
        "#       nn.BatchNorm3d(out1),\n",
        "#       #nn.ReLU(inplace=True),\n",
        "#       nn.LeakyReLU(inplace=True),\n",
        "#       nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "#       # Layer 2\n",
        "#       nn.Conv3d(out1, out2, 4, 1, 1),\n",
        "#       nn.BatchNorm3d(out2),\n",
        "#       #nn.ReLU(inplace=True),\n",
        "#       nn.LeakyReLU(inplace=True),\n",
        "#       nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "#       # Layer 3\n",
        "#       nn.Conv3d(out2, out3, 4, 1, 1),\n",
        "#       nn.BatchNorm3d(out3),\n",
        "#       #nn.ReLU(inplace=True),\n",
        "#       nn.LeakyReLU(inplace=True),\n",
        "#       nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "#     )\n",
        "    # self.linear_layers = nn.Sequential(\n",
        "    #   nn.Linear(48778, 2)\n",
        "    # )\n",
        "#   def forward(self, x):\n",
        "#     x = self.cnn_layers(x)\n",
        "#     x = x.view(x.size(0), -1)\n",
        "#     x = self.linear_layers(x)\n",
        "#     return x\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    out1 = 4\n",
        "    out2 = 4\n",
        "    out3 = 2\n",
        "    self.cnn_layers = nn.Sequential(\n",
        "      # Layer 1\n",
        "      nn.Conv3d(1,out1,4,1,1),\n",
        "      nn.BatchNorm3d(out1),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 2\n",
        "      nn.Conv3d(out1, out2, 4, 1, 1),\n",
        "      nn.BatchNorm3d(out2),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 3\n",
        "      nn.Conv3d(out2, out3, 4, 1, 1),\n",
        "      nn.BatchNorm3d(out3),\n",
        "      #nn.ReLU(inplace=True),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      nn.AvgPool3d(3)\n",
        "    )\n",
        "    self.linear_layers = nn.Sequential(\n",
        "      nn.Linear(1458, 2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cnn_layers(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.linear_layers(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "print(model)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv3d(1, 4, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv3d(4, 4, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (5): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv3d(4, 2, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (9): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (11): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): AvgPool3d(kernel_size=3, stride=3, padding=0)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=1458, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imIsJYkHAVEe"
      },
      "source": [
        "# Define Train and Test Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RhWjamUGtE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573ae567-64c1-4fc6-d7f1-bb4b58f7418d"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "        X = X.float()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        #y = reshape(y, (y.shape[0],1))\n",
        "        hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "        for index in range(len(y)):\n",
        "          if y[index] == 0:\n",
        "            hot_y[index,0] = 1\n",
        "            hot_y[index,1] = 0\n",
        "          elif y[index] == 1:\n",
        "            hot_y[index,0] = 0\n",
        "            hot_y[index,1] = 1\n",
        "      \n",
        "        print(hot_y)\n",
        "        pred = model(X)\n",
        "        torch.squeeze(pred)\n",
        "        loss = loss_fn(pred, hot_y.float())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print results after each batch        \n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss\n",
        "\n",
        "def validate_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    validate_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "            \n",
        "            pred = model(X)\n",
        "            # print(f'pred: {pred}')\n",
        "            # print(f'hot_y: {hot_y}')\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            # print(f'predictions: {predictions}')\n",
        "            # print(f'targets: {targets}')\n",
        "            print(f'Correct this batch = {(predictions == targets).sum().item()}')\n",
        "\n",
        "            torch.squeeze(pred)\n",
        "            validate_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            # correct += (pred.argmax(1) == hot_y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    validate_loss /= num_batches\n",
        "    correct /= size\n",
        "    accuracy = 100*correct\n",
        "    print(f\"Validate Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validate_loss:>8f} \\n\")\n",
        "    return validate_loss, accuracy\n",
        "\n",
        "learning_rate = 0.001\n",
        "# defining the model\n",
        "model = CNN()\n",
        "# defining the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# defining the loss function\n",
        "pos_weights = torch.tensor(pos_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "# loss_fn = nn.BCEWithLogitsLoss(pos_weights)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.to(device)\n",
        "loss_fn.to(device)\n",
        "\n",
        "summary(model=model, input_size=(1, 246, 246, 246), batch_size=2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [2, 4, 245, 245, 245]             260\n",
            "       BatchNorm3d-2      [2, 4, 245, 245, 245]               8\n",
            "         LeakyReLU-3      [2, 4, 245, 245, 245]               0\n",
            "         MaxPool3d-4      [2, 4, 122, 122, 122]               0\n",
            "            Conv3d-5      [2, 4, 121, 121, 121]           1,028\n",
            "       BatchNorm3d-6      [2, 4, 121, 121, 121]               8\n",
            "         LeakyReLU-7      [2, 4, 121, 121, 121]               0\n",
            "         MaxPool3d-8         [2, 4, 60, 60, 60]               0\n",
            "            Conv3d-9         [2, 2, 59, 59, 59]             514\n",
            "      BatchNorm3d-10         [2, 2, 59, 59, 59]               4\n",
            "        LeakyReLU-11         [2, 2, 59, 59, 59]               0\n",
            "        MaxPool3d-12         [2, 2, 29, 29, 29]               0\n",
            "        AvgPool3d-13            [2, 2, 9, 9, 9]               0\n",
            "           Linear-14                     [2, 2]           2,918\n",
            "================================================================\n",
            "Total params: 4,740\n",
            "Trainable params: 4,740\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 113.58\n",
            "Forward/backward pass size (MB): 3160.74\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 3274.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w-_C54rIh_Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir = content/drive/MyDrive/logsdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfKkG2-Gh_p1",
        "outputId": "9adbdcea-a2be-4bec-eb21-bccedb7d76f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
            "                   [--host ADDR] [--bind_all] [--port PORT]\n",
            "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
            "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
            "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
            "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
            "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
            "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
            "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
            "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
            "                   [--reload_multifile BOOL]\n",
            "                   [--reload_multifile_inactive_secs SECONDS]\n",
            "                   [--generic_data TYPE]\n",
            "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
            "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
            "                   [--whatif-data-dir PATH]\n",
            "                   {serve,dev} ...\n",
            "tensorboard: error: invalid choice: 'content/drive/MyDrive/logsdir' (choose from 'serve', 'dev')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqQYmcaAe-Q"
      },
      "source": [
        "# Run Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23uXlNlG9ZR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d88a8f0e-bf67-4c20-e000-68f9dc1fd0ae"
      },
      "source": [
        "epochs = 3\n",
        "train_losses = [[],[]]\n",
        "validate_losses = [[],[]]\n",
        "validate_accuracies = [[],[]]\n",
        "\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    validate_loss = validate_loop(validate_dataloader, model, loss_fn)\n",
        "\n",
        "    train_losses[0].append(t)\n",
        "    train_losses[1].append(train_loss)\n",
        "    validate_losses[0].append(t)\n",
        "    validate_losses[1].append(validate_loss[0])\n",
        "    validate_accuracies[0].append(t)\n",
        "    validate_accuracies[1].append(validate_loss[1])\n",
        "\n",
        "    writer.add_scalar('Loss', train_loss, t)\n",
        "    writer.add_scalar('Loss', validate_loss[0], t)\n",
        "\n",
        "writer.close()\n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 6.681827  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 8.414531  [    2/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.827257  [    4/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 11.298639  [    6/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 6.936287  [    8/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.834420  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.087676  [   12/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.862922  [   14/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.334411  [   16/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.304133  [   18/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.337782  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.429860  [   22/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 7.176299  [   24/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.505160  [   26/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.535071  [   28/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.354273  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.368499  [   32/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.274111  [   34/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 10.399292  [   36/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.647148  [   38/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.148406  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 10.617076  [   42/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.526345  [   44/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 8.312980  [   46/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 4.464665  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.934129  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.569421  [   52/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.586401  [   54/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.097900  [   56/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 9.865561  [   58/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.752934  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.940491  [   62/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 6.684341  [   64/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.252669  [   66/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.975974  [   68/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.684493  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.776816  [   72/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 12.052849  [   74/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 4.159513  [   76/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.648535  [   78/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 7.456324  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.203050  [   82/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 7.834970  [   84/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.281934  [   86/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.215743  [   88/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.167090  [   90/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 4.739240  [   92/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 8.127962  [   94/   97]\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.]], device='cuda:0')\n",
            "loss: 3.086732  [   48/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 2\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 3.088834 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 1.201723  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.924872  [    2/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.619150  [    4/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.680092  [    6/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.376279  [    8/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.652189  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 0.198791  [   12/   97]\n",
            "(246, 246, 246)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-5049e040c994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalidate_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-75ea98fdd376>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m246\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m246\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m246\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-9712bcd2016d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m#print('horizontal flip')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# window and levelling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m# backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "NUCtjrHb6JAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "                \n",
        "            pred = model(X)\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            torch.squeeze(pred)\n",
        "            #test_loss += loss_fn(pred, y.float()).item()\n",
        "            test_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n",
        "\n",
        "test_loop(test_dataloader, model)"
      ],
      "metadata": {
        "id": "MEuNq5Z-6IV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZBw098GbFou"
      },
      "source": [
        "# Plot Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmncBB6bEip"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(train_losses[0], train_losses[1], label=\"Train Loss\")\n",
        "ax.plot(validate_losses[0], validate_losses[1], label=\"Validate Loss\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Accuracies"
      ],
      "metadata": {
        "id": "fFAdAFAECQ-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(validate_accuracies[0], validate_accuracies[1], label=\"Validate Accuracies\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy / %')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "2Q8g4JowCPkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}