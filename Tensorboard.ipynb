{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jban28/MPhys-Radiotherapy-49/blob/main/Tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E8F_po0K_Wu"
      },
      "source": [
        "## Pre-requisites\n",
        "This block makes the necessary installations and imports for the rest of the code blocks to run, connects to the GPU if one is available, and specifies the location of the folder containing the data. That data folder should contain a sub-folder containing all nifti files, along with a metadata csv file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5AFQEgZc7XUV",
        "outputId": "037f82ae-88ec-4895-b060-38f19111f220",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Egh9uSI77b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220b43f9-ac47-4706-f4c5-50e4b0882dda"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "!pip install kornia\n",
        "!pip install utils\n",
        "!pip install torchio\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "import torchio as tio\n",
        "import kornia.augmentation as K\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch.nn import LeakyReLU\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "from scipy.ndimage import zoom, rotate\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#from torch.utils.data import windowLevelNormalize\n",
        "\n",
        "\n",
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "# Specify project folder location\n",
        "#project_folder = \"/content/drive/My Drive/Degree/MPhys/Data/\"\n",
        "project_folder = \"/content/drive/My Drive/Data/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (0.6.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.7)\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchio in /usr/local/lib/python3.7/dist-packages (0.18.73)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from torchio) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchio) (4.62.3)\n",
            "Requirement already satisfied: SimpleITK!=2.0.* in /usr/local/lib/python3.7/dist-packages (from torchio) (2.1.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from torchio) (7.1.2)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.7/dist-packages (from torchio) (1.2.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->torchio) (1.13.3)\n",
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzE7_7waF7_S"
      },
      "source": [
        "## Define arrays of patient and outcome data\n",
        "This block allows you to specify the criteria which defines the patient outcome as True or False. It then loops through all the patients in the metadata.csv file, searches for their corresponding image in the image folder, and then adds patient and outcome to either the training, testing, or validation array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KFIqmcw83Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cea1f57-f6e6-4bdc-febc-96717f2767d5"
      },
      "source": [
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = open(project_folder + \"metadata.csv\")\n",
        "metadata = np.loadtxt(metadata_file, dtype=\"str\", delimiter=\",\")\n",
        "metadata = metadata[1:][:]\n",
        "\n",
        "# Set the values which are used to define the outcome for each patient\n",
        "outcome_type = 1 #int(input(\"Select which outcome you are aiming to predict \\n(1=Locoregional, 2=Distant Metastasis, 3=Death):\"))\n",
        "check_day = 3000 #int(input(\"Select the number of days at which to check for event:\"))\n",
        "which_patients = 1 #int(input(\"Do you want to include patients whose last follow up is before the check day? (no = 0, yes = 1):\"))\n",
        "\n",
        "# Create empty arrays to store patient names and outcomes in\n",
        "patient_with_event = []\n",
        "patient_no_event = []\n",
        "outcomes_train = []\n",
        "outcomes_test = []\n",
        "images = []\n",
        "\n",
        "# Loop through each patient and identify whether they are true or false for the specified outcome from above\n",
        "for patient in metadata:\n",
        "  if (patient[(5+outcome_type)] == \"\") and (int(patient[5]) >= check_day):\n",
        "    # Last follow up after check day, no event\n",
        "    outcome = 0\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 0):\n",
        "    # Last follow up before check day, event unknown\n",
        "    continue\n",
        "  elif (patient[(5+outcome_type)] == \"\") and (int(patient[5]) < check_day) and (which_patients == 1):\n",
        "    outcome = 0\n",
        "  elif int(patient[(5+outcome_type)]) <= check_day:\n",
        "    # Event occurred before or on check day\n",
        "    outcome = 1\n",
        "  else:\n",
        "    # Event occurred after check day\n",
        "    outcome = 0\n",
        "  # No Image file found for patient\n",
        "  if not os.path.exists(project_folder + \"crop/Images/\" + patient[0] + \".nii\"):\n",
        "    print(\"No image found for patient \" + patient[0])\n",
        "    continue\n",
        "  \n",
        "  if outcome == 1:\n",
        "    patient_with_event.append([patient[0], outcome])\n",
        "  else:\n",
        "    patient_no_event.append([patient[0], outcome])\n",
        "\n",
        "# # Make arrays the same length\n",
        "# if len(patient_with_event) < len(patient_no_event):\n",
        "#   new_patient_no_event = random.sample(patient_no_event,len(patient_with_event))\n",
        "#   new_patient_with_event = patient_with_event\n",
        "# elif len(patient_with_event) > len(patient_no_event):\n",
        "#   new_patient_with_event = random.sample(patient_with_event, len(patient_no_event))\n",
        "#   new_patient_no_event = patient_no_event\n",
        "# elif len(patient_with_event) == len(patient_no_event):\n",
        "new_patient_no_event = patient_no_event\n",
        "new_patient_with_event = patient_with_event\n",
        "pos_weights = len(new_patient_no_event)/len(new_patient_with_event)\n",
        "# Add patient name, outcome and image to array\n",
        "seventy_percent_event = int(0.7*len(new_patient_with_event))\n",
        "seventy_percent_no_event = int(0.7*len(new_patient_no_event))\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "train_patients_event = random.sample(new_patient_with_event, seventy_percent_event)\n",
        "train_patients_no_event = random.sample(new_patient_no_event, seventy_percent_no_event)\n",
        "\n",
        "def remove(small_array, original_array):\n",
        "  for i in small_array:\n",
        "    original_array.remove(i)\n",
        "    \n",
        "  return original_array\n",
        "\n",
        "new_patients_with_event = remove(train_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(train_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "\n",
        "fifty_percent_event = int(0.5*len(new_patient_with_event))\n",
        "fifty_percent_no_event = int(0.5*len(new_patient_no_event))\n",
        "\n",
        "validate_patients_event = random.sample(new_patient_with_event, fifty_percent_event)\n",
        "validate_patients_no_event = random.sample(new_patient_no_event, fifty_percent_no_event)\n",
        "\n",
        "new_patient_with_event = remove(validate_patients_event, new_patient_with_event)\n",
        "new_patient_no_event = remove(validate_patients_no_event, new_patient_no_event)\n",
        "\n",
        "print('NO event')\n",
        "print(len(new_patient_no_event))\n",
        "print('WITH event')\n",
        "print(len(new_patient_with_event))\n",
        "\n",
        "test_patients_event = new_patient_with_event\n",
        "test_patients_no_event = new_patient_no_event\n",
        "\n",
        "outcomes_train = train_patients_event + train_patients_no_event\n",
        "outcomes_validate = validate_patients_event + validate_patients_no_event\n",
        "outcomes_test = test_patients_event + test_patients_no_event\n",
        "\n",
        "print(outcomes_train)\n",
        "print(outcomes_validate)\n",
        "print(outcomes_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No image found for patient HN-CHUM-005\n",
            "No image found for patient HN-CHUM-016\n",
            "No image found for patient HN-CHUM-040\n",
            "No image found for patient HN-CHUM-051\n",
            "No image found for patient HN-CHUS-033\n",
            "No image found for patient HN-CHUS-086\n",
            "No image found for patient HN-CHUS-089\n",
            "No image found for patient HN-CHUS-093\n",
            "No image found for patient HN-CHUS-096\n",
            "No image found for patient HN-CHUS-099\n",
            "No image found for patient HN-CHUS-100\n",
            "No image found for patient HN-CHUS-101\n",
            "No image found for patient HN-HGJ-003\n",
            "No image found for patient HN-HGJ-008\n",
            "No image found for patient HN-HGJ-010\n",
            "No image found for patient HN-HGJ-028\n",
            "No image found for patient HN-HGJ-034\n",
            "No image found for patient HN-HGJ-038\n",
            "No image found for patient HN-HGJ-041\n",
            "No image found for patient HN-HGJ-046\n",
            "No image found for patient HN-HGJ-047\n",
            "No image found for patient HN-HGJ-048\n",
            "No image found for patient HN-HGJ-054\n",
            "No image found for patient HN-HGJ-055\n",
            "No image found for patient HN-HGJ-056\n",
            "No image found for patient HN-HGJ-063\n",
            "No image found for patient HN-HGJ-064\n",
            "No image found for patient HN-HGJ-065\n",
            "No image found for patient HN-HGJ-066\n",
            "No image found for patient HN-HGJ-069\n",
            "No image found for patient HN-HGJ-071\n",
            "No image found for patient HN-HGJ-074\n",
            "No image found for patient HN-HGJ-079\n",
            "No image found for patient HN-HGJ-082\n",
            "No image found for patient HN-HGJ-083\n",
            "No image found for patient HN-HGJ-084\n",
            "No image found for patient HN-HGJ-087\n",
            "No image found for patient HN-HGJ-088\n",
            "No image found for patient HN-HGJ-089\n",
            "No image found for patient HN-HGJ-090\n",
            "No image found for patient HN-HGJ-091\n",
            "No image found for patient HN-HGJ-092\n",
            "No image found for patient HN-HMR-003\n",
            "No image found for patient HN-HMR-004\n",
            "No image found for patient HN-HMR-005\n",
            "No image found for patient HN-HMR-007\n",
            "No image found for patient HN-HMR-009\n",
            "No image found for patient HN-HMR-021\n",
            "No image found for patient HN-HMR-024\n",
            "No image found for patient HN-HMR-027\n",
            "No image found for patient HN-HMR-028\n",
            "No image found for patient HN-HMR-029\n",
            "No image found for patient HN-HMR-032\n",
            "No image found for patient HN-HMR-039\n",
            "NO event\n",
            "120\n",
            "WITH event\n",
            "19\n",
            "NO event\n",
            "36\n",
            "WITH event\n",
            "6\n",
            "NO event\n",
            "18\n",
            "WITH event\n",
            "3\n",
            "[['HN-HMR-035', 1], ['HN-HGJ-031', 1], ['HN-HGJ-002', 1], ['HN-CHUM-061', 1], ['HN-HMR-031', 1], ['HN-CHUM-063', 1], ['HN-CHUM-002', 1], ['HN-HMR-038', 1], ['HN-HGJ-045', 1], ['HN-CHUM-028', 1], ['HN-HMR-022', 1], ['HN-HMR-015', 1], ['HN-CHUM-053', 1], ['HN-HMR-016', 0], ['HN-CHUM-003', 0], ['HN-HMR-018', 0], ['HN-HGJ-005', 0], ['HN-CHUM-019', 0], ['HN-HGJ-029', 0], ['HN-HGJ-076', 0], ['HN-HGJ-024', 0], ['HN-HGJ-075', 0], ['HN-HMR-020', 0], ['HN-HGJ-014', 0], ['HN-HGJ-043', 0], ['HN-CHUM-041', 0], ['HN-HGJ-013', 0], ['HN-CHUM-036', 0], ['HN-HGJ-020', 0], ['HN-CHUM-010', 0], ['HN-HMR-019', 0], ['HN-HGJ-026', 0], ['HN-CHUS-064', 0], ['HN-HGJ-070', 0], ['HN-HGJ-040', 0], ['HN-HGJ-053', 0], ['HN-HGJ-011', 0], ['HN-CHUM-024', 0], ['HN-HMR-034', 0], ['HN-HGJ-022', 0], ['HN-HGJ-015', 0], ['HN-CHUM-052', 0], ['HN-CHUM-023', 0], ['HN-HGJ-007', 0], ['HN-HGJ-025', 0], ['HN-CHUM-056', 0], ['HN-HGJ-077', 0], ['HN-CHUM-018', 0], ['HN-CHUM-013', 0], ['HN-HGJ-072', 0], ['HN-CHUM-032', 0], ['HN-CHUM-062', 0], ['HN-CHUS-005', 0], ['HN-CHUS-002', 0], ['HN-HGJ-052', 0], ['HN-CHUM-065', 0], ['HN-HGJ-051', 0], ['HN-HGJ-037', 0], ['HN-CHUM-026', 0], ['HN-HGJ-004', 0], ['HN-CHUM-034', 0], ['HN-CHUM-030', 0], ['HN-CHUM-057', 0], ['HN-HGJ-042', 0], ['HN-CHUM-015', 0], ['HN-HMR-006', 0], ['HN-CHUM-025', 0], ['HN-HMR-023', 0], ['HN-HMR-002', 0], ['HN-HGJ-036', 0], ['HN-HGJ-050', 0], ['HN-HGJ-032', 0], ['HN-CHUM-042', 0], ['HN-CHUM-037', 0], ['HN-CHUM-007', 0], ['HN-CHUM-029', 0], ['HN-HGJ-073', 0], ['HN-HMR-036', 0], ['HN-CHUM-050', 0], ['HN-HMR-011', 0], ['HN-HGJ-019', 0], ['HN-HMR-012', 0], ['HN-HGJ-009', 0], ['HN-HMR-010', 0], ['HN-HGJ-049', 0], ['HN-CHUM-001', 0], ['HN-CHUM-004', 0], ['HN-HMR-026', 0], ['HN-HGJ-044', 0], ['HN-HMR-033', 0], ['HN-CHUM-006', 0], ['HN-HMR-025', 0], ['HN-HGJ-085', 0], ['HN-HGJ-027', 0], ['HN-CHUM-043', 0], ['HN-CHUS-009', 0], ['HN-CHUM-009', 0]]\n",
            "[['HN-HGJ-018', 1], ['HN-HGJ-059', 1], ['HN-HMR-001', 1], ['HN-HGJ-006', 0], ['HN-HGJ-035', 0], ['HN-CHUM-021', 0], ['HN-CHUM-027', 0], ['HN-HGJ-086', 0], ['HN-HMR-008', 0], ['HN-HMR-041', 0], ['HN-HMR-014', 0], ['HN-HMR-013', 0], ['HN-CHUM-022', 0], ['HN-CHUM-017', 0], ['HN-HMR-030', 0], ['HN-CHUM-031', 0], ['HN-HGJ-062', 0], ['HN-CHUM-038', 0], ['HN-CHUM-012', 0], ['HN-HGJ-030', 0], ['HN-HGJ-061', 0]]\n",
            "[['HN-CHUM-020', 1], ['HN-HGJ-001', 1], ['HN-HGJ-078', 1], ['HN-CHUM-008', 0], ['HN-CHUM-011', 0], ['HN-CHUM-014', 0], ['HN-CHUM-033', 0], ['HN-CHUM-035', 0], ['HN-CHUM-039', 0], ['HN-CHUM-049', 0], ['HN-CHUM-055', 0], ['HN-HGJ-012', 0], ['HN-HGJ-016', 0], ['HN-HGJ-057', 0], ['HN-HGJ-058', 0], ['HN-HGJ-060', 0], ['HN-HGJ-067', 0], ['HN-HGJ-080', 0], ['HN-HMR-017', 0], ['HN-HMR-037', 0], ['HN-HMR-040', 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfGjowelNEoF"
      },
      "source": [
        "## Define dataset class\n",
        "This block defines the class on which to build dataset objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjrRiSmq4mBF"
      },
      "source": [
        "# class Normalize(Dataset):\n",
        "#     def __init__(self):\n",
        "#       pass\n",
        "#     def __call__(self, vol):\n",
        "#         vol = (vol-vol.mean())/vol.std()\n",
        "#         return(vol) \n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #Normalize()\n",
        "    ])\n",
        "\n",
        "#window and levelling and this does normalise as well\n",
        "def windowLevelNormalize(image, level, window):\n",
        "    minval = level - window/2\n",
        "    maxval = level + window/2\n",
        "    wld = np.clip(image, minval, maxval)\n",
        "    wld -= minval\n",
        "    wld *= (1 / window)\n",
        "    return wld\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, annotations, img_dir, transform= data_transform, target_transform=None, rotate_augment=False, scale_augment=False, flip_augment=False, shift_augment=False):\n",
        "        self.img_labels = annotations\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.flips = flip_augment\n",
        "        self.rotations = rotate_augment\n",
        "        self.scaling = scale_augment\n",
        "        self.shifts = shift_augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels[idx][0]+\".nii\")\n",
        "        image_sitk = sitk.ReadImage(img_path)\n",
        "        image = sitk.GetArrayFromImage(image_sitk)\n",
        "        label = self.img_labels[idx][1]\n",
        "        print(image.shape)\n",
        "        \n",
        "        if self.shifts and random.random()<0.5:\n",
        "            mx_x, mx_yz = 10, 10\n",
        "            # find shift values\n",
        "            cc_shift, ap_shift, lr_shift = random.randint(-mx_x,mx_x), random.randint(-mx_yz,mx_yz), random.randint(-mx_yz,mx_yz)\n",
        "            # pad for shifting into\n",
        "            image = np.pad(image, pad_width=((mx_x,mx_x),(mx_yz,mx_yz),(mx_yz,mx_yz)), mode='constant', constant_values=-1024)\n",
        "            # crop to complete shift\n",
        "            image = image[mx_x+cc_shift:246+mx_x+cc_shift, mx_yz+ap_shift:246+mx_yz+ap_shift, mx_yz+lr_shift:246+mx_yz+lr_shift]\n",
        "            #print(image.shape)\n",
        "            #print('shift')\n",
        "\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        \n",
        "        if self.rotations and random.random()<0.5:\n",
        "            # taking implementation from my 3DSegmentationNetwork which can be applied -> rotations in the axial plane only I should think? -10->10 degrees?\n",
        "            roll_angle = np.clip(np.random.normal(loc=0,scale=3), -10, 10) # make -10,10\n",
        "            image = self.rotation(image, roll_angle, rotation_plane=(1,2)) # (1,2) originally\n",
        "            #print('rotation')\n",
        "            \n",
        "        if self.scaling and random.random()<0.5:\n",
        "            # same here -> zoom between 80-120%\n",
        "            scale_factor = np.clip(np.random.normal(loc=1.0,scale=0.5), 0.8, 1.2) # original scale = 0.05\n",
        "            image = self.scale(image, scale_factor)\n",
        "            #print('scale')\n",
        "            \n",
        "        if self.flips and random.random()<0.5:\n",
        "            image = self.flip(image)\n",
        "            #print('horizontal flip')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # window and levelling\n",
        "        image = windowLevelNormalize(image, level=40, window=80)\n",
        " \n",
        "        return image, label\n",
        "    def scale(self, image, scale_factor):\n",
        "        # scale the image or mask using scipy zoom function\n",
        "        order, cval = (3, 0) # changed from -1024 to 0\n",
        "        height, width, depth = image.shape\n",
        "        zheight = int(np.round(scale_factor*height))\n",
        "        zwidth = int(np.round(scale_factor*width))\n",
        "        zdepth = int(np.round(scale_factor*depth))\n",
        "        # zoomed out\n",
        "        if scale_factor < 1.0:\n",
        "            new_image = np.full_like(image, cval)\n",
        "            ud_buffer = (height-zheight) // 2\n",
        "            ap_buffer = (width-zwidth) // 2\n",
        "            lr_buffer = (depth-zdepth) // 2\n",
        "            new_image[ud_buffer:ud_buffer+zheight, ap_buffer:ap_buffer+zwidth, lr_buffer:lr_buffer+zdepth] = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            return new_image\n",
        "        elif scale_factor > 1.0:\n",
        "            new_image = zoom(input=image, zoom=scale_factor, order=order, mode='constant', cval=cval)[0:zheight, 0:zwidth, 0:zdepth]\n",
        "            ud_extra = (new_image.shape[0] - height) // 2\n",
        "            ap_extra = (new_image.shape[1] - width) // 2\n",
        "            lr_extra = (new_image.shape[2] - depth) // 2\n",
        "            new_image = new_image[ud_extra:ud_extra+height, ap_extra:ap_extra+width, lr_extra:lr_extra+depth]\n",
        "            return new_image\n",
        "        return image\n",
        "      \n",
        "    def rotation(self, image, rotation_angle, rotation_plane):\n",
        "        # rotate the image using scipy rotate function\n",
        "        order, cval = (3, -1024) # changed from -1024 to 0\n",
        "        return rotate(input=image, angle=rotation_angle, axes=rotation_plane, reshape=False, order=order, mode='constant', cval=cval)\n",
        "\n",
        "    def flip(self, image):\n",
        "        #hflip = np.fliplr(image)\n",
        "        #image = (reversed(image[1:]))\n",
        "        image = np.flipud(image).copy()\n",
        "        return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiSjndmcNfSA"
      },
      "source": [
        "## Build Datasets\n",
        "This block uses the class and arrays defined previously to build datasets for training, testing and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDoF-cH6xw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96217c8-7951-4c0a-d968-d998d876a646"
      },
      "source": [
        "\n",
        "training_data = ImageDataset(outcomes_train, project_folder + \"crop/Images/\")\n",
        "validation_data = ImageDataset(outcomes_validate, project_folder + \"crop/Images/\", rotate_augment=False, scale_augment=False, flip_augment=False, shift_augment=False)\n",
        "test_data = ImageDataset(outcomes_test, project_folder + \"crop/Images/\", rotate_augment=False, scale_augment=False, flip_augment=False, shift_augment=False)\n",
        "print(len(training_data))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7jDjfvKOCWc"
      },
      "source": [
        "## View binary masks in 3d\n",
        "This block allows you to view a binary mask from the image in 3d by extracting the image from a given dataset. This helps to confirm that the data has not been affected by reading in to pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uideXDzjvdS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "ea6b6531-8289-4bdb-8e8e-192cb41f7bb9"
      },
      "source": [
        "  # Set which dataset to look at, and the index of the patient to view\n",
        "dataset = training_data\n",
        "index = 9\n",
        "print('flipud')\n",
        "print(outcomes_train[index])\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "#print(dataset[0])\n",
        "\n",
        "#array = dataset[index][0].numpy()\n",
        "array = dataset[index][0]\n",
        "print(type(array))\n",
        "print('array shape')\n",
        "print(array.shape)\n",
        "x,y,z = np.where(array > 0.) # what >=\n",
        "ax.scatter(x, y, z, c=z, alpha=1)\n",
        "\n",
        "ax.set_xlim(0,246)\n",
        "ax.set_ylim(0,246)\n",
        "ax.set_zlim(0,246)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flipud\n",
            "['HN-CHUM-028', 1]\n",
            "(246, 246, 246)\n",
            "<class 'torch.Tensor'>\n",
            "array shape\n",
            "torch.Size([246, 246, 246])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 246.0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9aXAc53k1erp7dmCwbwQBYgcJkiIpUiKpVOLP12vKSeQtlmQnJS+ylajiexnL9g0dxVu+70pUKs7nSuR7bdmKKTs3crEqZcufL23HsS3bsimKlklqoQQMBhhgZgAMgMHsW2/v/QG9zZ7BzGCWng3oU8WiNCB63unpPv28z/Oc8zCEEOjQoUOHjuqArfUCdOjQoWM3QSddHTp06KgidNLVoUOHjipCJ10dOnToqCJ00tWhQ4eOKsKwzc/11gYdOnToKB5Mrh/oka4OHTp0VBE66erQoUNHFaGTrg4dOnRUETrp6tChQ0cVoZOuDh06dFQROunq0KFDRxWhk64OHTp0VBE66erQoUNHFaGTrg4dOnRUETrp6tChQ0cVoZOuDh06dFQROunq0KFDRxWhk64OHTp0VBHbuYzp0JEThBDIsoxUKgVRFGEwGMCyLDiOA8uyYFkWDJPTbEmHjl0JZpvBlLq1o44tIIRAkiSIopj23wDg8XhgsVjQ1dUFAAoJ0z86GevYJch5geuRro6CkUm2DMOAZVnIsqz8N8MwIISA4zgQQkAIgSAI4Hk+jWh1MtaxW6GTro5tQQiBKIqQJCmNbLOBki7972wkSn8uiiIEQUj7mU7GOnY6dNLVkROUbGnqIB/ZUqhJN9+/Uf+tfj/gJhlTgqf/luM4JW9MyVknYx2NBp10dWyBLMtpedpcESuF+meFkO52x8lFxpmpDUJI3shYJ2Qd9QiddHUokGVZSSMA25NtNjAMA1mWNV1XoWQ8MzODffv2wWKxKFG5wWDQyVhHXUEn3V0OdbGLkmU5xFROpFvKe6n/FkVRIVcASjtb5u/Q6FidqtDJWEe1oJPuLgXtsRVFUROyzTx2LZErMgZufm5JksDzfNrP1GkKGh3rZKxDa+iku8tASWd1dRVmsxk2m01TYql3gsrXUUHJWF3AA5A1Z6x3VOgoFTrp7hJk9tiur6+jra0NTU1Nmr4P7dttNJRCxnp7m45SoJPuDkcuQQPLshVLA9Q6vaAl8pGxWvgRDAYhCAJ6enp0MtaRFzrp7lBsJ2ioFOnuFmLJJGNBEJRCHqALP3Tkhk66OwyFChq0TANo1afbyKAPtkKFH2pQ8tWFH7sDOunuEBQraKhU7nW3k24u6MIPHRQ66TY4ShU0VELEQI+7W0l3O4l0NhRKxpm/ows/Ghc66TYgtBA0sCy7ZZurBXYz6WpJeNuRcabwIxAIwGw2w26368KPOodOug0ELQUNlSyk6aRbOeQi43A4DLvdjqamJl34UefQSbcBQMnW5/OhqakJZrO57BtGz+lqi2qRbi7IsqyQaSay9RrTv3XhR/Whk24dI7PHdmlpSTF0KRd6Tldb1APp5vM41oUf9QOddOsQuQQNHMdpRpRaR7rqba9OutVHPtLNhUKFHzoZawuddOsI2wka6pF0JUnC4uIigsEgmpqawHHcFgPy3YBaf95SSDcXSpn4wTAMkskkWltbdTLeBjrp1gGKETTQ1rByUW4hTRRFuN1uLC0toa+vDwMDA0gmkwgEAohEIrhy5QpYloXNZkNzczOamprS8tE7DTuJdHMhX0eFIAiYnp7GkSNH0n6mFn7oZLwJnXRriGIFDVpGuqXmdEVRxOLiIpaXl9Hf349Tp04p7Wetra2w2+0QRRGHDx+GJEmIx+OIxWIIBoPweDxIpVLgOG4LGZtMpoa+EXcD6eYCwzCQJElJOVAUIvxQt7btlo4KnXRrgFIFDVpHusWQriAIWFxcxMrKCgYGBnD69GnlBsuMmOn/cxwHu90Ou92e9nNRFBUy9vv9WFxcBM/zMBgMCgmrybgRsJtJF4BCumrowo/s0Em3StBK0FDtnC7P81hYWMDq6ioGBwdxxx135L25C/k8BoMBLS0taGlpSXtdFEXEYjFEo1Gsra3B5XJBEAQYDIa0qLipqQlGo3H7D1lF7HbSlWUZBkNhdFKs8IP+250y8UMn3QpDS0EDLVJpge1yujzPw+VyYW1tDUNDQ9uSbaHHzQeDwYDW1la0tramvS4IAqLRKGKxGHw+H2KxGERRhMlkSiPiWvr47nbSVTuslYpcZAwUPvGDBjWZD/R6gk66FQKNagVBSHsi14ugIdexUqkUXC4X/H4/hoaGMD4+XvTNpHXLmNFoRHt7O9rb29PeQ03Gy8vLCIVCuH79OqxWq0LEzc3NsNlsW7a+lUAtSbfWpJ8tvaAlCuk1BoAf//jHuH79Oh5++OGKraVc6KSrMdQ9tj6fD+FwGBMTE5rcEBzHaZbTzSykJZNJzM/PIxAIYHh4GJOTkyWtuVp9ugzDwGQyoaOjAx0dHQA2I+KxsTFwHKeQscfjQSwWgyzLsFgsW8hYq+hQluVdT7qFphe0RCYZh0KhLTuleoNOuhohm6DBaDRqejNWItJNJBKYn59HKBTCyMgIDhw4UNZ6ay2OYBgGZrMZZrMZnZ2dyuuEECSTScRiMcRiMWxsbCAej0OWZSUypnljq9VaUnTfaLlFLVHpSLdQhEIhtLW11XoZeaGTbpnIJ2jQMjKlx9OKdFOpFGKxGK5du4bR0VFMTU1pQhq1Jt1cYBgGVqsVVqsVXV1dyuuEECQSCYWM19bWEI/HASArGec6R7Um3VoTviRJdVHcDIVCGBoaqvUy8kIn3RJRiKBBa9LVomUsFothbm4OsVgMHMfh9OnTmlsS1iPp5gLDMLDZbLDZbOju7lZep7uAWCyGSCSClZUVJJNJANjSY2yxWGpOurWGJEmwWq21XoYe6e5EFCNoqKdINxqNYm5uDolEAmNjY+js7MSlS5c0J4pak66WqRxKqj09PcrrsiwjHo8jGo0iFAphaWkJyWQSyWQShBC0trbWRH1X6wddvaQXwuGwTro7BaUIGgwGw5bm73JQSqQbiUTgdDrB8zzGxsbQ0dFRUSKoNelWGizLorm5Gc3NzWmvX79+HXv27IEgCAgEAmnqu2yCDy2/g3o43/VEunohrYFRrqChEumFQiPdcDgMp9MJURQVsq0GdvMW2263w2w2p71G1XfRaDSv+q65ubnknGipo4K0RL2QbigUSmstrEfopJsFWgkatLZPLITEQ6EQnE4nCCEYHR2t+wtQS9Q64st2feRS3wmCkFa8o+o7o9GYRsRNTU3btmLVWhgB1Bfp6umFBgJt+5IkSWn1KkfQoHXUl4/Eg8EgnE4nGIbB2NhY3W+xdhqKbQ00Go1oa2vbQhA8zytkvLKyklV9R3uMKRnrpJu+jnroosgHnXRxk2yXl5dht9thsVjqUtOdjXQ3NjbgdDphMBgwMTFR1/LHnQytuhdMJhNMJtMW9Z2ajJeWlhCLxSBJEsxmMywWC3ieRyQSqZr6LhP1QLq13ukUil1NupmChvX1dRiNxrpofckGelMTQhSyNZlMOHDgwBYnLx3VRSVbxtSCD3VunhCCVCqFjY0NhEIhuN1uRfBB1Xc0RaGl+i4b6iHapqRbb8FSJnYl6ebqsdW620D9flpcCHTdzz//PKxWKw4ePLilil6rtdX7hV5p1KJPl2EYWCwWtLS0oLm5GQcPHlTWQtV30WgU6+vriuDDYrGk9RiXor7Lt55aIplMwmaz1XQNhWBXkW42slVfKJUgXdpCVc4FSQjB2toa5ubmIAgCTpw4gaamprLXRh3Ban2z7ATU8jxmRpmFqO+i0ShWV1eRSCQAbAo+1N0U+dR32VAPW/tgMNgQ6bVdQbqFChoMBoOmLV70mLQQUiwIIVhdXcX8/Dyam5tx5MgRXLt2TRPCBW6a3pQb6QiCgOXlZWVLq6O6KPQ7LEZ9l0gklHFLajKm9Y56RCN0LgA7nHSLFTQYDIYtXp3lopReXUIIfD4f5ufn0draiqNHj1Ykz1xuS5soilhYWMDy8jK6u7sRiUTgcrkQi8Vw9epVZRtL/651oaXSqJdIt1gUq75T/3v6px7QCA5jwA4k3XIEDQaDQcl9aYViSJcQguXlZbhcLrS3t+PWW2+FxWLJ+u+0uMFLJV31nDQ6TUIURWVNV65cwaFDhxR7Ra/Xq9grZprI2Gy2uo2cGgWVKmLlUt9JkqR0UgQCAaWA98ILL2QVfFTr+w0Gg3qkW01oIWjgOE7znG4hpCvLMpaXl7GwsICOjg6cOHFii7Ip83haeJcWS7rqCcDqOWk0n6d+GGR63dKfZ+YU4/H4lqnBzc3NDT+ospqoducAx3Fpgg+e53Hjxg0cPnxYIWO/34+FhQVl3JJW6rt80NMLVYKWgoZKFNLyka4sy1haWsLCwgK6u7tx2223bZv71VLlVqhPgiRJcLvd8Hg8W4ZS0uMUcqxcOUU6NTgajSqRE5XKZqYoamGUXe+odbsW7dHNN25Jrb6bn5+HKIolqe/yoRHMboAGJt1spuHlChqqRbqyLMPj8cDtdqOnpwe33357wYU2LT11tyNwSrZerxf9/f04ffp0RUgv19TgzHE8akGAmowr3YNa76gX0s2FQtV30WgUkiQp6jt1a1sh9YBQKIQ9e/aU/XkqjYYjXUq2Xq9X+WK0uuAq0b2gJl1JkuDxeODxeNDX14eTJ08Wvc2qxhh29UNhz549OHXqVE0izFyz0VKpFKLRqGIiQ/PwPM/D4/Ggra2t7ivtWqLeSTcXClHfeb1exOPxLQ9bWg9Qv6+eXqgQJEmCIAgIh8NgWVZTJValIl06Wdfr9ZZNYpUcTinLMrxeLxYXF9HX11fWOivVt0oFARaLJa0HVZZlXLt2DRaLJa3STq0V1ZFxvWvzi0Ux488rAS0lwNup72g9QD1uyWKx4KmnnoLb7cbGxgZ4ni9o5+h2u3HvvffC5/OBYRjcf//9OHPmDDY2NnD33XfD5XJheHgYFy5cQHt7OwghOHPmDC5evAibzYbz58/j+PHjRX/GhiNdOu/eZDJpNo5cfWwtI11RFBEIBBAMBjE8PKxJxKilXSQVR6hzy729vSVF4GpoIQgpFlRR2NXVldbxIYqicqOq84nqLWw1JwZXAo0a6RYD9cM2c/ZdPB7HkSNHcPXqVTz11FP48pe/jN7eXvzgBz/Ie0yDwYAvfelLOH78OCKRCE6cOIG3vvWtOH/+PN785jfj7NmzOHfuHM6dO4dHH30UP/zhD+FwOOBwOHD58mU88MADuHz5ctGfpeFIl6JS6jEtIAgCFhcXsbKyArvdjsHBQYyMjGhybK3tIldXV/Hqq6+ip6enbLKlqCcj82zFHbqFpflitWeB1WpNi4qLVWbVAruBdHOBYRg0NTXh/e9/Py5cuIBvfOMb6OvrK+j627Nnj5IDttvtmJqagtfrxdNPP41nnnkGAPDBD34Qb3zjG/Hoo4/i6aefxr333guGYXD69GkEg0EsLy8XnUduWNI1Go3KzKp6gSAIcLlcWF1dxeDgIE6fPg2/349QKKTZe2gR6dJ+4KWlJbS3txdVyCsE9US62ZBvYnAikVDyxT6fT1FmZVbZ66mlbTeTrhrqnG6x343L5cLVq1dx6tQp+Hw+hUj7+vrg8/kAAF6vF4ODg8rvDAwMKCnDYtBwpEtPZqXMaUoBzdmura1h3759uOOOOyo2EbicSJcQgpWVFczPz6OjowN79+5Fa2urpoQL1D/p5oK6pU2tzFKLATL7T2l6gnbS1CK3Wg+kq/U1VAoEQcjZ354P0WgU733ve/HlL395i3dDJSxeG450KYxGo+Y5XeAmqRVyEadSKbhcLvj9/i1kS1EPwymprHhubg7t7e2K+GJ+fl4zclQTbaOSbi5kigEoaJU9Go1CEARcv34dkiSl2SrSFMVOtlWsh0i31OtNEAS8973vxZ/92Z/hPe95DwCgt7dXSRssLy8rD+C9e/fC7XYrv+vxeLB3796i37PhSLfSkW4hBjXJZBLz8/MIBAIYHh7GxMREzou+lmPYqWHO3NwcWltbcfz48bQiEzW80Ro7jXRzgbY8tbW1YWVlBSdOnNhiq7i2tpbm5KXOF2s1LVgn3Zso1hntvvvuw9TUFB588EHl9TvvvBNPPvkkzp49iyeffBLvfOc7ldcfe+wx3HPPPbh8+TJaW1tL6gtuONIFNk9spSJdKgXORrrJZBJzc3MIhUIYHh7GgQMHtv2SaxHpUitIp9OJlpaWnB4OWhflKOol11ktqDs1ctkqZprHeL1eZVpwpuqu2GKmTrqb92axqYVf//rX+Pa3v41bbrkFx44dAwA8/PDDOHv2LO666y488cQTGBoawoULFwAA73jHO3Dx4kWMj4/DZrPhm9/8ZklrbUjSBSof6aqRSCQwNzeHcDiMkZERTE1N1XQicK6HDZ1+4XQ60dzcjGPHjuV1J9O6RY6iUhF0vaKQ9rhc5jGiKCpdFD6fT5mJZjabt6iychGrTrqlOYz9/u//fs4d2U9/+tMtrzEMg6985SslrU+NhiXdSkVTatKNx+OYm5tDNBrF6OgoDh48WPT7am2iky06JYTA7/fD6XTCZrPhyJEjBTno5yPwcrDbIl2g9M9sMBi2SGTVLW1UCBCLxUAIUfxtKYFbLBaddNE4ajSgQUm3kjlDg8GAaDQKj8eDRCKB0dFRHDp0qOSbSkuvBHo8dXTq9/sxOzsLq9WKw4cPF+VtSsURlcBuyOlSaC0EydXSlmk2vry8jGQyiUQigdnZWdjt9jSXtmqhHkg3HA43hJcu0KCkq4aWF3wkEsHq6ipkWcbBgwfR0dFR9rErNYZ9Y2MDs7OzMJvNRZNt5rG0xm4ppFFUS32Xy2z8ypUr6O/vRzweT2tpMxqNVTGSrwfSDQaDOulWEpkdDOWqqCKRCGZnZyGKIjo6OtDU1JQWYdQT4vE4VlZWkEwmyx5MqXcvaIN6mDPX2tqa1cWrECP5clvaJEmqucubnl6oEmgHQ6mkGwqF4HQ6IcsyxsbG0N7ejqWlJaRSKY1XWj6CwSBmZ2dBCEFLS4tSbS0HWkW61D1NlmU0Nzcr0zt2C+qBdLO9f6FG8rSlLdMYqBjVXa0/f6NMjQAalHTL7dUNBoNwOp0AgLGxsbQvy2AwIBaLabNQDRAKhTA7OwuGYTA5OQmWZZW1l4tyc7rUApK6knEch7W1NQQCAYTDYaUvVW0qU+ubsxKg5vmNgEKN5D0eD1KplDL1gX6H2YzG6+Gzh8NhjI+P13oZBaEhSZei2F7dQCAAp9MJjuMwPj6eNQdUKSOdYivM4XBYiWzVa00kEhX3090OhBAsLS3B5XKht7cXp0+fBrB549LUQm9vLywWi1KBX1tbU0bzqG/inWC1WA+RbrnIZyRPo2K10bja25aOyKplikFPL1QJhRAkIQQbGxuYm5uD0WjE/v3783rwVnJ6RCEXJc0vS5KE8fHxLReSlt0QxeZ01XLizs7ONKOczAkeALL63lIfg0yrRXVfaqNNg9gJpJsL2aY+ZBrJC4KAF154AQAUlzZKyNUykm+UUT1Ag5Iu/RLzRbq0d3Vubg5msxlTU1MFFZ0qSbr5IrpIJAKn0wlBEDA+Pp7mpq9GNSZHZIKeS9qWlCknzkS+Qlo2H4PMvlT1NIjMqLgejFWyYaeSbjaovW3b29vh9/tx4sQJpaUtc2Q7NZJXf5da724aZfw60KCkS2EwGLaQLlVlzc3NwWq14tChQ0W1U1VqZE8uIo9Go3A6neB5HmNjY2lFj2zQenLEdjndQCAAh8MBi8VSsOii2O6FfH2pNCpWt0KZTKYtueJaRsW1jHRrXbBUt4upW9p6e3uVf0ON5DMHU5Y6Cy0bQqFQzkCl3tCQpKuOdGlERM1d5ufn0dzcjFtuuaUggshEJSLdbEQei8XgdDqRTCYxNjZWcIualoKGfAQeDofhcDjAsiympqaKGoukVcsYHceU+d48zyMSiSAWi2FxcVEpfPI8D6/Xi7a2tqqOca816dYyyi6kRzefkTx9qGa2tBVrJK+TbpVgNBrB87ziEdvS0oKjR4/m9RvYDpUQDKhVZPF4HE6nE/F4HOPj45oIMEpFts8ai8XgcDggiiImJiZK2rJVuk/XZDKhs7NzS1R87do1mEymtDHuVCBQybE8tSS+WhewShVG5JuFRlMU1I+CGsmru2EyjeRTqVRZ93010bCkSwhBIBDAysoKWJbN6aRVD+A4DvF4HEtLS4hGoxgbG0NXV1fN84DqQloikYDT6UQsFsP4+HjR4hD1Z6mFOILOSOvu7k67DtS5YjqWJ5uHQTk2izrpavcQU7e0Zb4PbWnz+/1YXFwEz/Nwu9340Y9+BFmWcenSJdxyyy0F7co+8pGP4Ac/+AF6enrw8ssvAwC+8IUv4Otf/7rSSvfwww/jHe94BwDgkUcewRNPPAGO4/DP//zPePvb317yZ2xY0r18+TKam5vR0tKCqampWi8nJxKJBNbX1yGKIg4cOFCWj4PWYFkWoiji1VdfRTAYxNjYGLq7uzWRPtc610iRTSCQWfChNovqSRDFyGZr2ae700g3F3K1tE1OTsJqteLatWv41re+hZdffhnvfve78clPfjLv8T70oQ/h4x//OO6999601z/xiU/gU5/6VNprN27cwHe+8x288sorWFpawlve8hbMzMyU/LkbknQZhsHJkychy7LSqqI1yo1e1N67drsd7e3taXr5WkMQBMzPzyMajWJkZKQgb+BCUcuHSiHvnavgIwiCEhWrc4yZ29rMNig90q2d70JbWxve8pa34B//8R/x1a9+teDfe8Mb3gCXy1XQv3366adxzz33wGw2Y2RkBOPj43j++edxxx13lLTmhiRdYPPJxzBMRfxgaS9sKRcTnSoRDAYV710qkdUSpd7ooihicXERy8vLGBoaQlNTU0nu9/nQqH66RqMR7e3taQUZOuI7FoshHA6ntUGp56PVKrLf7aQLbBbRMkcplYrHHnsM3/rWt3DbbbfhS1/6Etrb2+H1ehUBEHBzIGWpaFjSrcTAOAra4lXMxZRKpTA/P4+NjQ2Mjo6mRY4cx2nq50C378V8flmW4Xa7lblOp0+fBsdxWFxc1GxdmevbCaAjvjOdvdRKLep3GwgE0sQB1O+2klGwTrraqdEeeOABfPaznwXDMPjsZz+LT37yk/jXf/1XDVaYjoYl3UqCto0VMv6D53nMz8/D7/djeHgY+/fv33KTae3nQCPxQm42WZaxtLSEhYUF9PX14dSpUzWZWLvToFZqWSwWRCIRDA8PK7litd+teiQP9bzV6juoB9KttWBFK2GEOtX0sY99DH/8x38MQLuBlBQNe/epZ1JpfeEV0qurHrteq+GU+W7cfJLdSmMnRbqFQD0FOdsIdyoOyPQvsFgsaVFxIf2omagH0q11pKuVwxidAAwA3/3ud3H48GEAmwMpP/CBD+DBBx/E0tISHA4HTp48WfL7NCzpUhQyvbfUY2aDIAhwuVxYXV3F0NBQ1rHrmajEcMpcx6OKvNnZ2awTgKuB3Ui6+cgylzggmUwqhTt1P2pmB0U+yaxOuqUJI97//vfjmWeewfr6OgYGBvDFL34RzzzzDK5duwaGYTA8PIyvfe1rAIBDhw7hrrvuwsGDB2EwGPCVr3ylrM/c8KRL/Re0Jt1MUhMEAQsLC/D5fNi3b19BZEtRiUg3W6FqY2MDDocDNpsNR48eLUmRVyoy+3QbsZBWKkohPvXU4EyLRTqOZ3V1FdFoVEl1ZbPJ1El3Uz1ZbCHtqaee2vLafffdl/PfP/TQQ3jooYeKXls2NCzpluupmw/qY4qiiIWFBaysrGBwcLAosqWo9Bj2UCgEh8MBjuNw6NChsqZJaAE90i0duQyB1K5ea2trSCQSYBhGEYUEAoGa2GTWA+mGQiHs27evpmsoBg1LuhTFeuoWAo7jwPM85ubmsLy8jIGBAaXaX+rxKpHTjUajcDgckCSpZMluJVAPpEuIDIbZ9KkIiotwRH6BsLQBv7AIQY6jwzSEoy13ot9c/ITnre9V2T5dtatXpk3mwsICEonEFptMtXdBJQ2B6oF0g8Egjhw5UtM1FIOGJd1KRbqSJGFjYwN+vx+jo6NlkS2F1qQrSRKcTqdCtts5k+VDKe1n2aAe0VNJ0iWEICmtgZAoosI0/KkfgWM4tJnegiCXxO8i/wsk9D0QhkCQWIjgsCFaESRN4BhAlFlIjBGhxDoc8aswMBZ8dOCrMHPlpWJqIY7gOA4mkwkWiwX9/f0Aqm+TWWxrZSXQSF66QAOTLoVWka4kSXC73fB6vWhtbUV/fz+Gh4fLXyC0I91UKgWn06kk/8fHx8u+2Wl+uJwbx+/3w+FwQBAEcBwHjuPAsiza2to0bY+Kiy7Mhd6PHs4PQgCRAFYAEuGwGvsxmro5JGQDQFgQAEbIWBC7IAJgGQmEAJBZEAaQADCMDBkJPOa+D+/r+QL22faXtK5aK9LU57faNpn1EOk20tQIYIeQLh2sVwroUEW3243+/n6cOnVK6bHUCuXekOpe4NHRUeVG0eJGp8WYUm6cSCSiaNAPHToEo9EIQgg8Hg+CwWBaexQVDdjt9qINZjZ4B14NnUUf60Qr4hAkgGUADgDHAAQSLJwEEAEEQICYsS5Y4ZE2t+IGAAwAmQEYjoCXNl8wMEAoZUYCZpxfOoe7ez+O/fYTRZ+HWpNuISRZrE1m5ny7XDaZhJCaT/hoJFtHoIFJt9z0Ah2q6Ha70dfXh9OnTysRQyWKc6VAXcQbGhpSeoFdLpemRubFHisej2N2dhapVAqTk5NobW2FLMvgeV6ZEiBJEkZHRwGk2/WpDWbUtot2uz1rlOWPPYF28ct4g5nFOkkgIQIyAAGvX7wEoIkMBgBhgE6WRysrgEmxcEkdkAGwYJAUjZAYAzgWiAsGeIQ2MCwgywxEwuKJpW/gfb0p3N72e0Wdj0Yg3VzIZZOpHlKZzyYTqP3UjHA4rJNuNVFsekGWZXi9XiwuLqK3txcnT57cUvHVOgdbLNSpjoGBgS0dE1qP7Ck0/8rzPJxOJ4LBIMbHx7fYU6oFK/axAYIAACAASURBVOpj5hINqHOPCwsLr+ceZcRNDH4cv44Tnb/AO3p/BwYMvFLq9WO9ftGq7nNB3ox6WRZgCBCQDVgTm2DgJHQhBo/QAQMRIBADGAZYTGxGwDIYBJJWRAQr4qIRDID/O/kf+OYuIt1sUPcKq5HNJjMWi+GVV15R1HbVNI+niMfjDeOlCzQw6RYb6arlsD09PVnJlqJWka56jXv27Mkp2aWWjFqgkEhXHXEX4khWaCFNbbtIiIyZ8P+JjdQzMAJ4JyQMcDEE5ddTA+Qmz8oMQGkmJW++HwsCFoBXtiIpG2GEjNdSfTAyBKxMsCq0wWwQsZJoA8MAG0kz4pIVKdmAQMKKaMoEQhj4ws34mvNn+IuxNxVy+jbXU8Ne2Wq+dzabzOeffx7Dw8OIRqMIBoNpo9tLscksFvQ6q3WKoxg0LOkCmzfbdpGuLMtYXl6Gy+VCd3d3QXLYao9hJ4Qo0y+6urryPhCAmy1tWq4rG9S7gr17927bo6yeBlxs98J89J+wwT8DAZuEuoeLQ2AYQCYwAhBej3BZslkECxIOQckKKyPCAAndnIBpvhU8MYJhCBb4LphZGSuJZvjEdqwkmzFsW0dSMkCQOKRgBS8D61EbwgkL6LONAPjG3DW0cq24Z7iw/O5Oi3QLBf3chdpkEkK2GAKVYx6vRq1THMWgoUkXyJ1eIIQoZFus94CWc8goso1hJ4RgbW0NTqcTbW1tOHHiREEmO1qOYc8W6dJ5c06nE93d3ds+BCjU6YVisZL8LiTCApAhESAgW2BjBAiEhZWVIMuAxBAYQOATbRDBgZcBiTWBlWW4xG7YmSTcQgcikgUcQ+DjrVgX7VhLNiElG+GIdKPZJCIkWGE2yIgJRoTiFnAsXf/N9XzJ8QuddLdB5vWsRjE2mTQqVre0FRoV10PLWrFoeNLNJEh11NjR0VEwkVUamWPYqWS3qakJx44dKyonVcmcLl1Xc3NzUb4N5Y7rSckyUpIRLAg4VoZbaIKZ4WGCBAYSWjhxk2gJC0KAddEGARxYMIjBAhZAUDZjXbAhLlvRakhgJbUpFomJJgTiZsR4C/rtIYgwwGzg4Q83gcgAYRjcLMeVht1IupntatuhEJvM5eVlxGKxtI6XfDaZpUiAa42GJl31za121Wpvb6+J0Us+UI9eKtk1GAwlS3a1HsMuy7LS/sWyLA4fPlzU2PpMlEK6UbkfYTkGIyNBFFkAHCKwwggJMhgEZR5NLA8OBB6pHRJhsHkGWHAgmE12gZdNaDdGERGtSIgcXgt2IykaIcoc4gkOssxhLtGGpmYJwbVmJDZaAKsIWCVwhpsPMUIAWSqcRGupvqsl6WoVZaptMinUHS/ZbDKbm5uRSqUaThgBNDjpAptfjiAIeO655zR31dJy2yjLMm7cuAGO4zA5OVnW01nL7gpZluF0OiHLMiYnJzW5gEsh3bbU/45l9n9CBgsDI4F5XcbLywawjAyBNSAlmcC/3nUbk6xgQRCTTFgXWgAwIGAQFi1YjVuwGBsEwwKx1OYOghBAkhiQpAWRBECSZoABSJwFiTMQugiMpk0alyQGQsiA9fV12O32bavxuzm9UKmtfSE2mRcvXsS//du/wefz4V3veheOHDmCj33sYxgcHMx77GxDKTc2NnD33XfD5XJheHgYFy5cQHt7OwghOHPmDC5evAibzYbz58/j+PHjZX22hiZdv9+P6elpSJKEI0eOlBWdZYISW7lqKtrTGgqFMDo6iqGhobLXpkWkS70lVldXMTg4iLGxMU2JoxjS/cHvpvE/vutA39Dt+N/efA0yw4BhCFgQiGDAkc2CWgoGgCGICBbEZCskwiAkNEEkDGwGGQnJgEDKhMVYFxgWCMctYJjNXK2YYkF4FhA5EIHbrNYxABNjYYqw4GUGiTZ5s0OCB0xeY9aeYtoWpe4p1km3elDbZH784x/H4cOH8ZOf/ASf+MQn8OKLLxZUe8g2lPLcuXN485vfjLNnz+LcuXM4d+4cHn30Ufzwhz+Ew+GAw+HA5cuX8cADD+Dy5cvlfYayfrvGYFkWR44cwauvvqr5NATawVDqcZPJJJxOJyKRCMbHx2EymTSzWiynkEZNUpaXlzE8PKxMWdWSNIqNdB/+j18CRmDF04vvXXgD/vBPfwMTK4KAgUg4EDCQCQcOAkysBC/fiVZjEkHeioRohIGTQRgZG0kr/AkLBImDAQSyxIEzbJ4nEjWASbGAzIBhGRATAAKYYgxYgYF53QSyQTbJWNzs9x0bG1PWSHtUI5GI4mdAc5S0T7QWLl+7jXQzQdVoIyMjGBkZKeh3sg2lfPrpp/HMM88AAD74wQ/ijW98Ix599FE8/fTTuPfee8EwDE6fPo1gMJhmdl4KGpp0Ozs7FWIUBEHTglmpbWOZkt2DBzddrEKhkKbFr2KPpe4BVs9Im5ub0zwnWXR6QXqd7AiQEKz47v/7Ztx66gaGxpc387GyCQGhCRyRYTUISIpGyDKLDd6MpGQFKwgg4BFMWrEesYHIHExmGbLAgHv9CmeDHLgUuykFZgG5CSBWwBgD2CQgGAEGDF5PFIONp68/W48q9b6dnZ1FMBiEz+dLmwhBo+JKzkmrZZRdL6SrRUrM5/MpRNrX1wefzwcA8Hq9aekKOpRy15IuRSXsHYslXVEU4XK54PP5MDw8jMnJybSbQcs8bDHpBXX7V7YeYC2LchTFki4nEhABILbXSU8Grj53EFevHED3kA8DE0tYMzQjKXCwGCRwjAQCA5IiAxkGJAQz4pIEjiFIhS0gAAQBIBEDWKMMzkBgiLDgeAbEALAig9TrETDLA+aQDGJgIZuZzZSDQGAKF7Du171vrVYrBgYGYLfb0yZCqAtAarEAlTxrRVi7mXSDwWBZ88qyoZJDb4EdQrqVNjLPB0mSsLi4CK/Xm3eihJakW+ixAoEAZmZm0NTUlLPAWIkpD8WSriFIwHEESdvrNzDLAISASCyWFvdgyb8HTH8EbBsPEyej2ZpELGXB5ilgQcAgxgOdzTGQsBEwAbJIwEY48EYTGIuE5iDAks3PSiwMLGscGFkCIwLmoATCMZAsABiAFQFTsLjvSt2jnG0ihFos4Ha704xlaESsld1itVAPpBsOh3Ho0KGyj9Pb26ukDZaXl5XindZDKYEGJ116odci0lWrtfbs2YM77rgj7wWo5Rj27aLTaDSKmZkZMAyzbVtaPUS65pAINiVCYo0Q+kyv92xt9s4ylk0Tm1TKAhJhwZsIJJGDIHEQeBaEsLDZU+AFA9YjzTDEWJAIILUSGBIshAhAeA6mEIFkB2whgJcIJBtgWZdgWRLAgQExMJCTLMACDE9gCRX+EC/ks2YTC1BjGZonpnaL6tE8dru9pIGV1YC677xWCIfDmpj333nnnXjyySdx9uxZPPnkk3jnO9+pvP7YY4/hnnvuweXLl9Ha2lpWagFocNKlqESkmyuapEq3+fn5bT0cMo+n1Rpz3YDJZBIOhwOJRAITExMFOS+xLKv5A6tY0p3o74Dn5RWYXonB18KBmDkwr6cZXqdeIMUArAGiJCOy2gzGJoHILMAwSBgBg0FCijeAlQEmwYETNn/ZGOQgWwhMcQmCicAYl8BILKQUA9nEwhJMQLaaYNkAJAu3GenyMu55V+FtQaXmVbMZy2SO5lldXUUikUjrTy1WtVUp1EOkW0pON9tQyrNnz+Kuu+7CE088gaGhIVy4cAEA8I53vAMXL17E+Pg4bDYbvvnNb5a95oYmXXWkS7drWiGTyDMlu7fddltRhbtKOpcJgoC5uTn4/X6Mj4+ju7u7YBKohOS5WNL9v/77u/Hhd/0/YAQJff+5go1jneB7LGAlQBYBCADDs4AMEIkBBw4Sz4JhWRCzBClshGw1ACyB1CfB7OJgjLAgLCCZAU5gQAwE5qAE0crAGJVhEADjSgRsNAVWJJDNErgkBxCCD/3lG3DnXbcXvH4ti1m5RvPQ/lSaJ45Go5BlGclkEi6XqyYOX/VCusXaOmYbSgkAP/3pT7e8xjAMvvKVr5S0tlxoaNKlMBqNFcnp0nSA3+/H7OwsmpqacOutt5YkvqgE6dJ88tLSEoaGhrYU7wpBPeR0W1qs+Nw/vBf//YF/gyGWQOeLAQRHrUjtawMXBEgbAQcGTIoFJ3GbRMowkC0EMsNBJpuFOGxaN4CNySBGFqxIYAgBHddiIBYDiIGFgWcgs4AhRQDOAEQiYOIGcAYOHV3N+Men/w/Y24vr965GB0GuMe6XL1+G1Wrd4nurzhNXakZao5JurbEjSJe2jGl9zGg0iitXrsBkMpUtjc021r1U0DlYzz33HPr7+8ua46ZFTleSJLhcLiwtLcFqtcJms4HneSSTyYJdpI7eNoRzT34YZ//0MTCrG2jzsyDTIYSO9oEXjOBMBMTCgREJWJGBZGGA5GabF5MiAAeYfRJanASsgQMYGSBA88wGwLIgAoFsYEFMDIwMgy/+j3fh6NHNCbKEEMgyAceVRky1mp5ACIHBYEBvb2+awxedBqGekUZ7itWtbOX2ttcD6Uaj0ZpPvy4WDU26lSqkRSIROJ1OJBIJnDhxYsuIk1KgRaSrTnHIslxwPjkfyiFdQgiWlpbgcrnQ39+P48ePQxRFhMNh+Hw+TE9PK2oueqPTdqlsRDx+sB/f+OVn8Dd/8j+xNu0GE4mgLZYA2loAUYTMsVj/b32QrQYwMQIYAZIgMK9LaJlLQTYwYDkOMggIS8CtR8AmBDCEwGiTMTzZgwfPvQ9dfekSbIZhwHGlR6q16pXNJYzINg2C9hRHo1H4fD5lsGkhpjK5UGvSbUQvXaDBSRfYvGG0KqTRRnee5zE4OKho77VAuaQbCATgcDhgs9lw66234ne/+50mKrxSSdfv92NmZgbt7e247bbblHSMwWBQ/AoOHz4MhmEgiqISea2vryMej6cVhux2u2Jy3dZlx2O/+Fs8d/Ea/uNL/wuLL7qB9QDQ0Q6D2YS+7zqAjjZILTaQeALgAE5mwYgyYDKAsCzufP8JvO9Dv49Vtx+dfW1FpwuKhSzLNSPdQt+X9hSrPT9ymcpk9hQ3NTVlJbZaky5FPXZ25EPDky5QfvdCpmS3s7MTyWQSKysrmq2xVNKl7V8AcPDgQWUrpcUUX3qcYvKv0WgU09PT4DgOR44cgcVigSzLylqWlpbg8Xiwb9++17ftm8TQ0tICu92OgYEBhYjpHC61yTUd+3L4v43hjj/+rPJg8S2s4z++/P/hZ997EcS3BmaRB2M0grOZYTBysLfZ8LaPHsOf/PnblALn8JS2TfP1BkJIWd9/LlOZXD3FmSPca026tXrYlYuGJ12GYUquwFPTl42NDYyNjSmSXUD7NrRiSTeZTGJ2dhaxWAyTk5NbigX0eOVe9IUW0lKpFGZnZxGNRhWXNDWp+v1+OJ1OdHR04OTJkwpZ0mNTYlb/DvVW7evrU4pviUQCkUgEa2trmJubU7bAdrsddz30R7jv3D05u0auX79e1rkoFbVKL+QzES8HuXqK1SPcXS4XotEoXnrppbQ8cTV7iiORiGY70Wqi4Um3FAiCAJfLhdXVVYyMjGD//v1bLhStSbfQC1EQBMzPz2N9fT1v+5dWoobtjkOLZD6fDyMjI5iamlIIlGEYxGIxOBwOmEwmHDlyZIsZOyWFTHJQEzD9G4DSLtXT06N87lQqhUgkglAoBI/HA57nYTKZlJHi9GavFeotp1sJZBvh/vzzz2P//v1KesLn823pKVanjrRGMBhsOC9dYAeQrvpi3+7iL1Sym3ncaiCz/ev06dN5byitWtByka66SLZ3716cOnVKWSfDMMouIR6PY2JiomhVEP1s6ptRTcD0D7AZeXV0dKCzs1P5XmieWH2zJ5NJzM3Noa2tTRn/Ug1SqiXp1nJ7na+nOHM+mizLsNlsaVFxuT3FWpndVBsNT7oU+fxvZVmGx+NJG7BYDwUAIJ3c9uzZU3D7l5aRbmZqRl0ku/3229OsJGVZxuLiIlZXVzE6OlqUEKOQtQC5iVgdETMMo/StsiwLhmFw/fp1dHR0IJVKYXFxMa1VSh0Va/3d14p0y83pVgoGg2HLJAhZlpXUkbqn2GQybZE8F/qgDIVCmkiAq40dQ7q0bUxNumpC6+3txenTpzX33S0VhBCsr69jdnZWIbdizE60Gk6pzunSkT3ZimQAsLKyolhDnjx5sipRZC4iBjajbkIICCGIRqNIJpOw2+1ob29Hf3+/YoFJb3a1kosazaijrnKwk3K6haDYGgrLskoOXw215Jl2ttB/qxZ4ZLtv9Ui3RshW+FLbGXZ0dBRNaOpja5k3o8cLh8OYmZmB1WoteiglhVbDKVmWhSiKePnll5WiXWaRLBAIYHZ2VpE/19rkRJ0npjnwUCiEQ4cOwWq1KlExJWXq+tXb26sU7Kj9Ii0KiaKY5oNrt9s1Gw9eKewEA3Oz2Qyz2Zy1p5imjrL1FBNC9Ei31jAajeB5Xoke7XZ72fPSso1NLxdXr14FAExNTZVVedUivUA9gMPhMIaGhnDw4MG0IlkikVAi38OHD2s2+UILEELg9XrhdrvzSqBzpSfozd7V1aX8nno6xNLSUlHCjlpgpxqYb9dTHA6H8eijj+LSpUuwWCzwer04duwY/vzP/7yoNQ0PD8Nut4PjOBgMBvz2t7/NOStNSzQ86aoLK6+99hrsdjuOHDmiCUHQ6LncyI72AcdiMYyMjKCvr6/stZVTSKOERVMFTU1N6O7uVopk1EAnGo1iYmKi7rZwdEx8Z2cnbr/99rwpo2IKdjQX2d7erhhZFyLsqNU04Fr2yVb7vTN7ih9//HE88sgjmJiYwNDQEG7cuFFScPTzn/88rQiYa1aalmh40k0kErh+/ToSiQT27NmTNteqXJTbNiaKIubn57G2toaxsTHwPK9ZX2Gpke76+jocDoeSdmFZFl6vF7/97W/R3NysRHsjIyM4cOBA3UR1AJTIGwBuueWWkh+sxRbsaNRFC3aZwo54PI4rV66k5SHtdnvF6wc7Ib1QDkKhEPbt24c3velNeNOb3qTJMXPNStMSDU+6BoMBY2NjiMViNR/ZQ0Er/LQ1jbZ/ra6uVn16BEUkEsH09DSMRiOOHj0Ks9msEMzJkyfh9XrhcrmUYsfCwgI8Ho+iJGtpaamYW9V2oGkQv9+PiYmJtDllWqHQgp1a2GGz2dDX14dIJIJbb701r7CDErGWc/x00i2vkMYwDN72treBYRj8xV/8Be6///6cs9K0RMOTrslkQltbG1KpFBKJhKbHLtZ4XG1w3tfXt6X9qxZz0qiyLR6PY3JyUtkOU/IIBoNKDvzUqVNpBUdBEBCJRBAOhzE/P49YLKY0yVMybm5urtiNT8/nwsICBgcHcfLkyapG3tmEHerWOfowMBgMIISUJewo5XPt1JxuoSjX1vHZZ5/F3r17sbq6ire+9a04cOBA2s8rNSut4UmXolIjewohyULbv7ScHrHd+B9KCKurqxgbG0N3d3dakYxOmSCE4ODBg1ltK6koQR1ZqkUJi4uLiMViYBhGieRaWlo06YUNBoNwOBxoaWmpi44JCtrXvLGxgbm5OfT392NiYgIAsqYnqKR2O2EHNZmhRFyIsEOSJE0j52JQD6Rb7qgeOuusp6cH7373u/H888/nnJWmJRqedCvllVDoMUOhEGZmZmA2m7dt/9LSUzefkowWyQYGBtKUZMDNPHMoFML4+HjRW3WDwbBFly9JklJV9nq9iEQiIISgublZyYcW6t9KI3NBEHI+DGqJWCyG6elpmM1mHD9+fMvDtZCCHcuyW4Qd9BxGIhHFZGY7YcduTy9EIpGSSZeq5Ox2O2KxGP7zP/8Tn/vc53LOStMSDU+6wCbxVirSzXVM6jkgSRIOHDhQUIGs0umFtbU1zM7OKkUytYCCEAKPx4OlpaWsI+LLAcdxW6YayLKcZhkYiUQgy7JCIjQ9QSNYSZKwsLCQFpnXE+jDKhAIYHJysqBcYiEFO3VUTCNcjuMUIqZ54pWVFUSjUUiSpAg7YrFYzQy864F0y3HZ8/l8ePe73w1g87v9wAc+gD/8wz/E7bffnnVWmpbYEaQLVG5kT2aeOJVKwel0IhwOY2JiIq2peztUagx7riIZvZnX1tYwPz+P3t5enDx5sio3C8uySpRLt3F0+m04HFbM2EVRBMdxSCQS6O7uxrFjx8rqrdYahBD4fD7Mz89jcHAQ4+PjZT2siinYAYDVaoXFYkFvb6/yoKV54kQiAZfLBZfLlSbsKNaMvBTUehJwuW16o6OjWV3pOjs7s85K0xI7gnQ3nf+1y5dSqNML6vav0dFRTE1NFX1Raz2Gned5vPTSS0gkElmLZOFwOM34vFb5P/Wa1dNvw+GwslXv7+9HPB7HK6+8Ap7nlao/Je5arJ16B1utVpw4caJsqXAu5HNiU0fG9CFLJ0MEAgH09fWhpaUlp7BDrbDTUthR60iXkm49tTQWih1BukBlTj5NL9D2qcHBwW3dv/JBq0hXFEV4vV6sra3hlltuQVdXV1qRLJVKpaU+6m2GFM/zmJ2dRSKRyJqaoTLdcDiMUCgEt9uNVCoFi8WSlpqoVDQniqKym5mcnKyZ1JRl2axELIoiFhYWEI1GlV0NHVy5nbCDdp+Ua7tYa9KNRqMN6aUL7CDS1Rq0Qu3z+WCz2XDq1Kmym93LJV2al11cXERPT49id0iPSb1vNzY2lAkY9QTav7yysoKRkZG01io1GIZJ80sANj97KpVCOBxGJBKB1+tFMpmEyWRK6yUux0SbEIKVlRW4XC7s27dP07y3VqBjm/r6+hTToWKEHTTXnmtiR6HCjlqTbigUSpMJNxJ2BOkW46lbCKhqy263o7W1VTOVW6mkq25Jo9JXSZJw+fJlvPTSS7Db7UilUvD7/RgaGio776g16PqdTid6e3uVIl8xUHu3qtt4aH4zs/1KHRE3NTVtez5oXry5ubmuWtQoUqkUZmZmIEkSjh49mtYlU2zBjgo79uzZoxBxscKOeiDdRjS7AXYI6VKU65Wgbv86evQoTCYTXnjhBc3WV0reWZ33VBfJDAYD7rjjDqU9zGQygeM4uN1uBAIBhXCqIUfNBzrjzWQyVaRIpjauoRAEQYmI19bWFL8Eej5aWlqUPlhBEOB0OhGNRrF///6627LS3Y3H41EmiRSCfAW7zFwxkD6xg/Yi5xN2xONx8DxfMwOgRp0aAewQ0s0cxV4s6cbjcczMzEAURezfv1/ZtlB7QK1QTKRLxQvJZBKTk5OKnR3N20YiETgcDlgsFpw8eVIhMzrLKhwOY2VlBQ6HA7IsKz2z1SJiSmaRSKTqeVGj0bhlBDnNb4bDYSUfKooiBEFAT08PJiYm6spFDbj5wG1ra9Ok66SQgp36ms83scPn82FxcREOh6MkYUe5aFQvXWCHkC5FsW1j27V/af0EL0Qcoe6SGB8f31Iko0WoVCqldCyooZ5lpW7VykXE6m24FkQsyzK8Xi88Hg+Gh4ezzp+rBdSiDkpmra2t6OnpQTweh8fjQTQaBYAt56Xa22hayItEIpiamqp4ITRXwS5bnpi2AhoMBhw8eFAJJIoVdpQLnXTrBPnEDGqoJbJ02GI1iCFfpEvJanFxEYODg1uUZFQ8sL6+jrGxsTQf2O1QLSL2+/1K3rla/cDFgOd5OJ1OxOPxNDJTP2xpoSkcDmN5eRkzMzOKqEO9U6hEzpea78/NzdW8kJcrPZFMJpXcN3Dz+qStgLRgRwhRjMizCTvKndihk26NkZleyAVZluF2uzVp/yoF2UiXFpkcDge6urrSKtL058vLy3C73RgYGNBsTE4xREwJJxcR0/QMy7JZJwLXGmrD8+0sK9WiDgp6XiKRiDKRRE0g9LyU08cbj8fx2muvwWw2V7QnuFTQc+j1etN2hfkKdlTY0dfXpxTsaJ7Y7/djYWEBgiCUJOwIh8MYHh6u9MeuCHYE6VLk8kqgrUBzc3Po7e0tqv1Ly5E9mReSukh26623wmQypaUS/H5/2sihSudhtyNin8+XRsTNzc2IRqOKg5nWDvtaIBQKYXp6WjEiKuUcqs9Lf38/gM1riqrr/H4/5ufnIQhCWiRXiKhDlmW4XC6sra3V7TmMxWJ49dVX0dLSsqXzpNiCHRV25JrYsby8jGQyua2wQ490awx1pJup+PL7/WluVcUqmyiRaxl5JJNJzMzMKHnZzCJZNBqFw+GA0WiseeSoJhwK2g/sdruVm2F6ejptC07zfrUCz/NwOBxIpVI4dOiQ5sY5NGfZ1NSk+K/SkTKRSATBYHBbUcfGxgZmZmaUNrpamdfkAn0grK+v48CBAwX3xeYr2GXLE+ea2EGJeH19HYlEAgzDwG634+c//zlWV1c1uy9+9KMf4cyZM5AkCR/96Edx9uxZTY6bC8w2GubazCEpEoQQ8DyP1dVVhEIhTExMKMMfjUZjWZXpq1evYv/+/ZpUtkVRxC9/+UtYLBZli0YvQFokoznHiYmJuuxDDAaDmJmZQVtbG0ZGRpTcpnoLTtu1JEmqOhHLsgyPxwOv14vR0dGcAoxqIVPUEQ6HkUgkIAgCOI7D0NAQOjs7yxJ1VALBYBDT09Po6enB0NBQxR4ImU5smXxESVgt7Pj617+O73//+wA2CftP/uRP8PnPf76k95ckCZOTk/jJT36CgYEB3H777Xjqqadw8ODBcj9azi9zR5AusNmJEAgE4Ha7FRLWolXppZdewtDQUFnqF0oEbrcbgiDgD/7gD5TX6d+Li4tYXV3F6Ogouru76+oGBDZH5VBp8eTkZEGRo9rgJpOI1b4KWhExfSB0dHRgZGSk7gp56tzyvn37YDKZFGFHPB6H0WjcMqmj2teBKIqYnZ1FLBbD1NRUTdrockXEavzRH/0Rvv/976O1tRVra2tKOqxYXLp0CV/4whfw4x//GADwyCOPAAA+85nPlP4BNpHzi9sRCW2vXgAAIABJREFU6QVgczvpdruxtraGo0ePpjXLl4NyfHoJIYrdYnd3N06ePIkrV65gZWVFyff5fD5lQKRWRTItQVMJ6ha2QqE2uKG5UDURq4tSuSwfCwH1mhAEoe6mFlNEIhG89tpraG1tTcstq8UOPM8rJEx3PFTUoVbXVeoaodfqvn37atrqly9PnEwm8U//9E9wu90wm80wmUwlEy4AeL1eDA4OKv8/MDCAy5cvl3y8QrAjSJcQgpdffhmdnZ3geV4zwgVKl+5SdZvFYkkrku3fvx/r6+tYXFxEJBKB2WxGT08PrFYrBEGouRMYhdrSUMsHQjYipu1FmURss9nSuiYyiZh2oywvL9elBy+wGTnOzc0hFApt67tMi0zqFjY6MikSiSiiDnWenRrEl/PdpFIpTE9PAwCOHz9eN9egGizL4tq1azhz5gzuvPNOzM/P151Uu1DsCNJlGAYnTpyAKIpYXl7W9NjFRrp0G64WL6g7EoxGIyKRCCwWCw4dOgSO47a4aVmtVoVsWlpaqt4+FAqF4HA40NzcXJX2JTrupxgiZhgGy8vL6O7uLsnLoRqg6x4cHMTExERJkWO2kUmSJClE7Ha700Qd6l7i7c4JIQRLS0tYXFwsSmJcbaRSKfzDP/wDnnnmGTzxxBM4cuSIZsfeu3cv3G638v8ej6esyLkQ7AjSBTZv3FLHkudDoaRLIxq/3684fFEPVFqNpRr/iYmJtHYXtYmL2tYwEAjA5XIprUhqIq7EUz6VSmF2dhbJZLLmPgS5iHhjY0MZ52M0GrG2toZYLJY3Iq42EokEpqenYTAYKvLQ4jgObW1tadeQWhW2tLSEaDSaV+wSj8fx6quvoqmpqSrtiKXi6tWrOHPmDN7znvfgl7/8pebf7e233w6Hw6Hs6L7zne/g3//93zV9j0zU55kuEZXy1M1nPK4uku3btw8nT54EcFOpQ7fAPp8Pw8PDeRvzgdy2hjQPur6+rrhAZRJxqTeOLMtYWFiAz+er20Ke2hZSnVtWR8TqaRSZgo5qELF6jZOTkxUZFZ8LuUYmqXusZ2dnlQBCEAQMDw9jz549dUm4qVQK586dw7PPPovz58/j8OHDFXkfg8GAxx57DG9/+9shSRI+8pGP4NChQxV5L4od070giiIkScJvfvMb/N7v/Z5mx1W3oamRWSQbHh7eEmn7fD64XC7s2bMH+/bt07QAoiYb+kdtbFOIbwD9DHNzc+jr69N8jVqB9lr39vYW1L6kPje0TUv9kKKRn5ZEHAgEMDMzk3Yt1BvC4bAicmhtbVVSFGpRBz0/tczrvvDCC/jrv/5rvO9978OnPvWpunwoFICd3zJGSffSpUs4deqUZhc9NTKfmppSXqMqJ5vNhrGxMaVIBmxGqsFgELOzs7Db7RgdHa1aTlYd2VDCoRNP1VN5OY5TRtFYLBaMj4/XZfEkkUhgZmYGDMNgcnKyLFtItRcAPT/qiLhUIlaLMA4cOFCXnROSJCnGTtkmiVBRh/ohxfM8LBZL2rkxm80V3QElk0k88sgjuHTpEr72ta9VPOKsMHZ+yxgFdRrTiujU3QuUBARBUC5edZGMFtEIITUZH55LxktvJI/Hg0gkgmQyCYZhsHfvXvT09NQ8B5oJ9WTgYod/5oI6R6xWkFEipmkbSsTqB1W286MuQtWDCCMX6C5h7969OYt5DMPAZrPBZrOhr68PwM3aAr126KQOs9mcdm60Gpl05coVPPjgg7j77rvxzDPPNGp0WxB2TKQrSRJEUcS1a9cwMTGhGeHFYjFF4krH4HR1dSmTW2mRjLYFjY+PVzWXVyjUSq2hoSHYbDYl4lO3IbW2tiqN+bXYItO8bK3SHer8eWZETMmGZVk4nU40NzdjfHy8LgmC53nFI/rAgQOamcdnU9dRY/NSRB2JRAIPP/wwrly5gq997WtpO8oGx85PL1DSfeWVV7B3715NzDBkWcb8/Dzm5uYwNTWF/v7+NIUMdfVfWlrC8PCw4qZUb6Cjfmi+MVueV23yHQ6HEYvFwHFcWqGukgop6lTGcRwmJibqbgx7PB5HMBiEx+NBLBaD2WxOy59XqqOklLXSOW/VisCpqIOScaaoI9dD/PLly/jUpz6FD3zgAzhz5kxdPrzKwM4nXVmWIQgCpqenFRejUkF9TZ1OJ7q6uuD3+3Hy5Mm0Itna2hrm5+fR29uLffv21WWfaCwWw8zMDAwGQ0lERhvz1URMpar0T7meAVTxtr6+XrcuW8BNtdbAwAAGBgYAYIvEuVqtfbmQSCQUe8iJiYmaPgTUog567bAsixs3bii7mfn5eXzjG9/A/v37a7bOCmL3kO7c3BysVquStysW6iIZ3To+++yz6OzsREtLCziOg8fjQVNTE8bGxuqyACUIAubn5xEMBjExMaEpkamjmnA4jHg8rkzkLSbPp+6c6O/vx8DAQF1W/KlpN8uymJyczPt9Z6YmshFxub67ud7X7XZjaWmp6q1qxUAURVy4cAHnz5+HIAiKZeq3v/1tTE5O1np5WmPnky41uVlcXAQA7Nu3r6jfj8fjcDgcEEURExMTSpGMphP8fj/m5uYUdyhKNDQHWg8uUZmGKv39/VVZE83z0T+04JJJxBQ0AjeZTHXbOaGWGJdTzFMTMX1YaUnE1NOhvb29Lk1+KOLxOP7+7/8eL774Ih5//HGFZOn05npIzWiM3UO6y8vLSCQSGB0dLej3aHS8sbGh3FyZRTKXy6UU0ejNRyfOhkIhpaCgJprW1taqkkkgEIDD4VBuvlrmx9R2hvQP9ZUVRVFxgKtX2Sm1Nezq6sqZAy8HWhCxJEmYn5/HxsYGpqam6m6KMQUhBJcuXcKnP/1pfPjDH8Zf/dVf1e2DQWPsHtJdX1+H3+/fNk+kHt0zNDSUtUi2tLQEj8dTcNRI5buUjHmeh9VqVaLhSuT4aJuaLMuYnJysyz5Rap7jdDrR1tam+E/QEd71UowSBAEOhwOJRAIHDhyoassfJWJ16kZNxLQoZTKZEAgEMD09rYhuar3DyoVYLIYvfvGLuHHjBh5//HGMj4/XeknVxM4nXWBzmxsMBuH1enM2VquLZGqDZnWRjPZsdnd3Y2hoqOSokTad02iYKqOampoUIi512iyNdNReD/UIKsKwWq0YHx9Pi97ytWdpIW8uFOqKfz11oWQScSgUUtr79uzZg46OjpoYIm0HQgieffZZ/M3f/A0++tGP4oEHHtgt0a0au4N06awlh8OBY8eObfk5NbmmRTKj0ZimJItEInA4HLBYLBgbG6tI25JaNRYKhRCJRABAiWRaW1vzeqaqCWJgYAB79+6tywKUune5GDP5THlz5gSK1tZWTceix2IxvPbaa2nXRD2CBgpDQ0OKhDczIla3aNWKiKPRKD7/+c9jZmYGjz/+OMbGxmqyjjrA7iHdVCqFF198EbfddpvyOu0BVU89UI/Joe5aajvGaoJa9anFCrTPUS1WoCOI7HY7xsbG6pIg1A+FwcFB7N27t+yosRh5c6FQ50T3799fl6ORgJvdExzHYXJyMiuZqmW89PzQ1E21iJgQgl/96lc4e/Ys7r//fvzlX/5lXQYDVcTuIF1BECCKIi5fvow77rgDgiDA6XQiEAhkLZKpe0THxsbSJpTWGrTPMRQKIRAIIBQKgWEYdHd3o6urSynU1ct6gc1KOlXvVTpqpPOy1EQDYAsRZ7vxqViknlvVaCeKx+MpemIH/f1sRFwJr+ZIJILPfe5zmJubw9e//vWGHY2uMXYP6cqyjF//+tfYu3cvvF6vYl+XWSRbXl6G2+2u6y26JElYXFyEz+fD2NgY7HZ7Wn6PdgSoC3W12FbSh1skEsH+/fvLmidXDqinrJpoqLyZtq15PB5NDHQqCTry3G63Y3x8XLNUSi5jm1KJmBCCX/ziF/jMZz6DBx54APfff39d3kc1wu4gXdoy9uKLL2JsbAxDQ0PKFFFgM2/r9/vhdDqV4YX1KD2kxb65ubm8tpDUlERdqBMEYUv+s1KfkT68FhYWMDQ0hD179tRV5A3clDcvLCwgEAjAaDRuMW1pamqqi3WrR55XK+WxHRGrHcbUiEQi+Lu/+zssLi7i8ccfx9DQUMXX2mDYHaR748YNJJNJBAIBnD59WhnnzDCMUmAzGo0YHx+H1Wqt8WqzIxKJYGZmJmu1vxCoC1G0UJeZ/7Tb7WVHJOFwGNPT02hpacHo6Ghd5peBmwpD9YTgbPJmg8FQU7FLKBTCa6+9VvGR54WAErH6HPE8DwD47ne/i66uLly4cAGf+MQncN999+nRbXbsDtLleR6SJOGFF16A0WhEW1sbrFYrfD4fEokEJiYm6rZgwvM8ZmdnEY/HMTk5qekWXW3vqN52q7eUhUZ7giCkrbNem/JpyiMWi2H//v1bPGSz/Xt161qp8uZioR55Xu3e4GJApcYPPfQQnE4n7HY7wuEw/vRP/xSf/exna728esTuIN1Pf/rTyjDFoaEh/OpXv8LQ0BCMRiNMJpMSxbS2ttaFbBe4KdJYWlqqqi8r3XbT1ITazIaeJzXJqCXG9dTLmgn1FONyUx48z6epDrPJm8spZqpHnldLsl0KCCH42c9+hoceeghnzpzBhz/8YbAsC0IIIpGIJgGC2+3GvffeC5/PB4ZhcP/99+PMmTPY2NjA3XffrfRQX7hwAe3t7SCE4MyZM7h48SJsNhvOnz+P48ePa/BpNcPuIN3p6Wn85je/wbe//W387ne/w6FDhzA2NoYTJ07gxIkTGBgYULbe8XgcZrM5jYirXYSibkt0S1nrBnJKMpRokskkLBYLTCYTgsEgOjo6MDExUZd5cGCzNfC1116DxWKpmMuWWnWoljdnEnE+8DyP6elpEEKwf//+uvSeoAiFQvjbv/1brK6u4qtf/SoGBwcr8j7Ly8tYXl7G8ePHEYlEcOLECXzve9/D+fPn0dHRgbNnz+LcuXMIBAJ49NFHcfHiRfzLv/wLLl68iMuXL+PMmTO4fPlyRdZWInYH6QLAf/3Xf+FHP/oRHnroIVitVly7dg3PPfccrly5gldeeQU2mw0nTpzAbbfdhmPHjqV1BPA8r6jFtG7CV4MavtD8cr1W0VOpFKanp5Vpu8lkUun/VHdM1JqEqe8xLUBp4aVcKNTTm9X5z2w+CurC49jYmDIBuh5BCMFPfvITfO5zn8ODD/7/7Z17UFNn+se/JwTwgrWABrkZCAG5ipCAdsalTL1OtdjK6kTbn06tXduV2lmwynbHWd110FpdmQ5Mt91q1e201lm70KkFbbvLCO0kAQpTlcVQEZEkQCFyCWKA5P39wZ6zCRcFScgJvJ8Z/yAcJy/h8Jz3fZ7v830ysW3btknN3W7YsAEZGRnIyMhASUkJ/P39odfrkZqaips3b2LXrl1ITU3Fli1bAACLFi3iruMJ0yfoPgx2hHd5eTkXiO/cuYOgoCAkJSVBJpNx7cNs7pMQwjUpsN1ij3sMZM11urq6ho1h5xOsOXtTU9OwlId16y577LYeiDl37txxNypMBHYcDZ8Gaw7VyLI74oGBAcycOROhoaGcBwUf6ejowO9//3sYDAb89a9/5UY/TRYNDQ1ISUnB9evXsXDhQnR0dAAY/Fy9vb3R0dGB9evXIzs7G8uXLwcArFixAu+8845NU5STmT4z0h4GwzDw9fXF2rVrsXbtWgD/k+moVCqUlJTg+PHj6O7uRlRUFJeWmDdvHnp7e3H79m2u0m2dlnhUXs9isXBCd7FYjIiICN7m79hWaR8fHyQnJw8LngzDYPbs2Zg9eza3q7BuVNBqtTaNCuzn9LDW5sfBZDJxXYbx8fG8UqNYzxwTiURobGyEXq/n7AwNBgMaGhps2pvZHbGz3eEuX76MgwcPYu/evXjppZcm/SFmNBqRnp6O3NzcYblihmF4+3czHqZV0B0JgUAAiUQCiUTCHVX6+/tx7do1qFQqnDt3Dj/99BOEQiESExORmJiIhIQErv9dp9PhwYMHo7qJGQwG1NXVwdfXF0lJSU4/io+GyWRCXV0d+vv7ERMTM64qurUSgoVtbe7s7ERDQ8Ow8T+PW8y03oXz/Yje1dWF2tpa+Pr62kyotn5YsTWG5uZmzi3OegyQo1JcQ7l37x6ys7PR1dWF4uJiBAQEOPw9h9Lf34/09HS8+OKL2LhxIwDAz88Per2eSy+wv+/AwEDcvXuX+79NTU2TviN/XKZVeuFxYau0FRUVUKlUUKvV+PnnnyESibj88OLFi+Hu7m7TpGA2myEUCjkXMD4cfYdiPbAyLCwM8+fPd9huwlqW1dnZOW4PYlYb/OSTT0IikTi98DgaZrMZ9fX16OjoQFRU1CPlataM1t48NH1jr3uJEIKioiIcOnQI+/fvx9atW51ynxJCsH37dvj4+CA3N5d7/a233oKvry9XSDMYDDh27BguXbqEvLw8rpC2Z88eqNXqSV/3Q6A5XXvD+u2qVCouELe1tSEkJAR9fX3w8PBATk4OPDw8bLSxfJKtsbtwR5l1j4WR1ABDTw0Mw3BtxpGRkeMKYpON9cjzoKAgu/x+h7Y3G41GMAwzrKtuvMHSYDBg//796O3tRX5+vlOLUGVlZfjVr36FuLg47ufIycnB0qVLsXnzZjQ2NkIsFuPChQvw8fEBIQQZGRkoLi7GrFmz8PHHH/MpnwvQoDs5FBQUYP/+/Vi2bBk8PT1RXV0Ns9mMxYsXQy6XIzExEQEBAdwfkLNkaw8ePEBdXR3nusYn4/OhHsTt7e3o7e2Fl5cXFixY4FBVyUTo7++HRqNBX18foqKiHK5IGcmZbqwNL4QQXLp0CX/+85/x9ttvQ6FQTIlcKc+gQXcyqKmpQUBAAKdKYANIZWUl1Go1VCoVamtrMXfuXMhkMiQlJSE+Ph6zZs2aFNmaxWJBY2MjmpubuVQCX2En27Jz1KwbFYxGI6cqeZSjmKOxbsaYzOaWkRgYGBjWVcfm0T08PGA0GuHn54fs7GwMDAwgPz8ffn5+TlnrNIAGXb5ACEFbW5tNWoJ1Q5PL5ZDJZIiOjobFYrGrbI099vJ5ZDww+GC4c+cOWltbHzqSnT1yszti652etQexIwOg9YMhIiKClxIwNo9+8+ZNHDhwgJPXPfvss1i3bh2efvppZy9xqkKDLp+xWCz4+eefuSBcWVmJ+/fvIyYmhgvEYrGY08eOR7bGmmADQEREBK+kVUMxGAzQaDTw8/N7LNMXdqfHBuKh/gn28iB2lZHnLG1tbcjKygLDMMjLy4NAIEBlZSWEQiFWrFhhl/fYsWMHvvrqK4hEIly/fh0AcPDgQfztb3/jTlQ5OTl49tlnAQBHjhzBqVOn4Obmhvfeew9r1qyxyzp4BA26rkZfXx+qq6u5QHz9+nXMmDEDCQkJkMvlSEhIgLe3N5eWGCpbmzNnDrRaLVpaWiY0Qnwy6Ovrg0ajQX9/PyIjI+36YLCeSmwPD2Kj0Yj//Oc/vFdQAIMPh4KCAhw9ehQHDhzApk2bHLbzv3r1Kry8vLBt2zaboOvl5YW9e/faXFtTU4MtW7ZArVZDp9Nh5cqV0Gg0vP4sHwPaHOFqeHh4IDk5GcnJyQAG/4A6OjpQXl4OlUqFgoIC1NfXIzAwEImJiUhKSkJwcDDc3NxQVVUFgUAAoVAIHx8f3L9/H0Kh0C6WjvbE2kTHUXI1T09PzJ8/n9ttWbftsk0KY/EgtlgsqK+v5/3Ic5bW1lZkZWXB3d0d//rXvxyev09JSUFDQ8OYri0sLIRCoYCnpydCQ0MhlUqhVqvx1FNPOXSNfIEGXReBYRh4e3tj9erVWL16NYD/OZQplUp8//33OHr0KNfWvGnTJsjlcohEIphMJjQ1NdlYOrL5YWfJ1rq7u1FbW4snnnhiUptGGIbBzJkzMXPmTK6IZO1B3NLSwjUpsIU6hmFw9+5dBAQEQC6X8+rBNRRCCL744gscO3YMBw8exMaNG52qTMjLy8O5c+cgl8tx4sQJeHt7Q6vVYtmyZdw1QUFB0Gq1TlvjZOOSQbe4uBhvvvkmzGYzdu7ciezsbGcvySkIBAKIxWKIxWLEx8ejtLQUn332GXx9faFUKnH+/HlUV1eDYRgsWbIEMpkMiYmJmDdvHrq7u9Ha2jrpsjXrKcGRkZG82DEyDAMvLy94eXlxnVgWiwX37t1DfX09ent74e7ujpaWFty/f9+mtZlPUquWlhZkZWVh5syZ+Pe//z3uuWr25vXXX8eBAwfAMAwOHDiArKwsnD592qlr4gMuF3TNZjN2796Nb775hjOqSUtLQ3R0tLOX5lQWLVqEH374gdsxxsfHY9euXSCEwGg0orKyEiqVCseOHYNGo4Gvry/nLZGQkABPT090dHSgsbHRYbI1dox4cHAwwsPDeRWwhtLW1oZbt27ZeAdbexDX19fbeBCzDyxHGJ0/CovFgosXL+L48eP405/+hOeff54Xn621HO3VV1/F+vXrAbh2C689cLmgq1arIZVKIZFIAAAKhQKFhYXTPugyDDPiEZ3tXEpNTUVqaiqA/41JV6vVUCqVOHXqFJqbmyGVSrm2ZolEgoGBAej1emg0mgnJ1np7e3Hz5k3Ov4LP/rEmkwm1tbUQCASQyWQ2u36hUAhvb28bGZu1B7Fer+eMzq0LdY78eZubm5GZmYk5c+agpKSEVwVT1jMBGBzzExsbCwBIS0vD1q1bkZmZCZ1Oh7q6Oq52MR1wuaCr1WptjJSDgoL4Zl7MexiGgb+/PzZs2IANGzYAGDxBaDQaKJVKfPnllzh06BD6+voQFxfHBWKRSISenp4xu61ZN2PwXVplXdQLDw8f89Hcw8MD8+bN464nhMBkMqGzs9Pm5MD667Inh4lqei0WCy5cuICTJ0/i8OHDSEtLc+rudsuWLSgpKUFbWxuCgoJw6NAhlJSUcOmtkJAQfPDBBwCAmJgYbN68GdHR0RAKhcjPz59qyoWH4nKSsX/84x8oLi7GRx99BAD4+9//DpVKhby8PCevbOrx4MEDVFVV2ZjAs+OQWNmatQm8tWzNzc0NOp0OIpEIISEhvC4+WY88DwsLs3tRb6gHcXd3N8xm82O7iTU3N+PNN9+Ej48PTp48yeuH2TRm6kjGpns+aDKZMWMGnnrqKU7KQwhBe3s7ZwJ//vx5NDY2YuHChVwTxxNPPIGioiLExcXB3d2dK9ZZ64f5EoCtu98iIyMdNrR0NA/inp4edHZ2QqfTjcmD2GKx4Pz583jvvfeQk5ODdevW8SJ3SxkfLrfTHRgYQEREBL777jsEBgYiKSkJn376KTfxgTK5sKNylEolzpw5g4qKCsTExCA4OJgr1IWFhXGTFPgiW+PTyHMWaxObzs5OzoP48uXLmD17Nr799luIxWKcPHly1PZoCm+YOjtdoVCIvLw8rFmzBmazGTt27HB4wA0JCeGOf0KhEBUVFaNOKZ1uCAQChIWFQavVIjo6GhcvXsSMGTM4E/gzZ87g2rVrcHd3R0JCgs00jqGyNetA7CjZ2sDAAG7dugWj0YjY2FhejTx3c3PDk08+aTPGyWQyobi4GIWFhVzji0KhwBdffGG3tY/UwuvCU3h5j8vtdJ1BSEgIKioqbIor+/btG3FKKWU4hBB0dXXZmMDfunULfn5+XH44Pj7exgTeWrbG5j0nWmxpa2tDXV0dgoODERgYyPujuU6nw549e+Dv748TJ05wwViv13MyNnswUgvvaPe3C0zh5QvUe2EijBR0raePWk8ppYwNVi2gUqm4Ql17ezsiIiI47+HIyEhOkjURtzV25LnFYkFkZCSvJWvAYMrmk08+wfvvv4933nkHa9ascfgDoqGhAevXr+eC7mj3twtM4eULUye94AwYhsHq1avBMAx27dqF3/zmN2hpaeFutAULFqClpcXJq3QtGIZBUFAQgoKCkJ6eDmAwp1lTUwOVSoWLFy+iqqoKhBDOBF4mk8HPzw9GoxG3b9+G0WiEu7v7qLI1Vxp5ztLU1IQ9e/YgODgYV69edVhx71GMdn+PJNnUarU06I4DGnTHQFlZGQIDA9Ha2opVq1YhMjLS5vtTZUqps3Fzc0NcXBzi4uKwc+dOTmrFmsAfP34cN2/ehLe3t0033ezZs9HV1WUzJHTWrFkwGAyYM2cO5HI5L71urbFYLDh37hw++OADvPvuu1i1ahVv7il6f9sXGnTHACtJE4lEeOGFF6BWq0edUkqxH6zUKiUlBSkpKQAGd6+//PILZwJ/9uxZ6HQ6hIaGQi6XY8mSJfjuu+8QGRmJ8PBwLmh7eXnxUrYGAHfv3sUbb7wBiUSC0tLSYaPHncFUnMLLF/hz5/GUnp4eTkPZ09ODK1euIDY2FmlpaTh79iwA4OzZs1xnlz3YsWMHRCIR1zYJDFaTV61ahfDwcKxatQr37t0DMBiE9uzZA6lUisWLF+PHH3+02zr4CMMwEIlEeO6553D48GFcuXIFP/30E06cOAGBQIDXXnsNV65cQW5uLvLz81FVVQV3d3fu+NvU1AS1Wg21Wo3a2lro9Xr09PTgEbUNh2CxWHD69Gls3rwZ+/btw/vvv8+LgAtg1Ps7LS0N586dAyEESqUSc+fOpamFcUILaY+gvr4eL7zwAoBBudHWrVvxhz/8Ae3t7SNOKbUHtJr8ePzud7/Dzp07ERMTA5PJxJnAl5eXcybwiYmJXKHO2gR+MmVrANDY2IiMjAxERETg2LFjTp1wbN3C6+fnh0OHDuH555931Sm8fIGqF1wNWk22L6wJPDsgtLy8HLdv30ZgYCDkcjnkcjni4uLg5ubmUNmaxWLBqVOn8PHHH+PEiRN45plnaL50akLVC64OrSZPDNYEfs2aNdw8LtaQR6lUorS0FH/5y184n19WPxwYGAiTyYTm5mZoNBoAtq26Xl5eYw6aDQ0NyMjIQHR0NMrKypy6u6U4Dxp0XRBaTbYPAoEAISEhCAkJgUKhADA4PffGjRtQKpX49NOQFS4YAAAE8ElEQVRPUV1dDYFAYNNNt2DBAhiNRjQ0NHCyNeu0xFC3NbPZjFOnTuHMmTPIzc3F008/TX9/0xgadF0EWk2eHNzd3bFkyRIsWbIEr732mo0JvFKpxJEjR6DRaDB//nwbtzVPT08b2dqMGTNQWFgIsViMzz//HAkJCfj+++951XZMcQ406LoIbDU5Ozt7WDU5Ly8PCoUCKpWKVpPtzGgm8Hq9njOB//DDD9Ha2sqZwMtkMoSEhODevXsoKioCwzAoLS1FZmYm5ynrKKhPiAtACHnYP4oTUCgUZMGCBUQoFJLAwEDy0Ucfkba2NvLMM88QqVRKVqxYQdrb2wkhhFgsFvLb3/6WSCQSEhsbS8rLyyf8/i+//DKZP38+iYmJ4V774x//SAICAkh8fDyJj48nly5d4r6Xk5NDwsLCSEREBCkuLp7w+7siAwMD5MaNG+T06dNk165dRCwWk02bNpGenh5CCCF9fX2ktrbW4esQi8Xkl19+sXntrbfeIkeOHCGEEHLkyBGyb98+h6+DMnpcpeoFyjBGkqwdPHgQXl5e2Lt3r821NTU12LJlC9RqNXQ6HVauXAmNRjOtJgGMBCHEKXlb6hPCG0b95dPmCMowUlJSxqw5LiwshEKhgKenJ0JDQyGVSqFWqx28Qv7jrEIZ6xMik8nw4YcfAhhd+UJxDjToUsZMXl4eFi9ejB07dnAdcaNJ1ijOoaysDD/++COKioqQn5+Pq1ev2nyfKl+cDw26lDHx+uuv49atW6iuroa/vz+ysrKcvSTKCDzMJwQA9QnhATToUsaEn58f3NzcIBAI8Oqrr3IpBCpZ4w/O8AmhjB8adCljgt0pAcA///lPzownLS0N58+fh8lkwu3bt1FXV4fk5GRnLXNa09LSguXLlyM+Ph7JyclYt24d1q5di+zsbHzzzTcIDw/Ht99+i+zsbGcvdXrzMGmDE2QWFB4wkmTtpZdeIrGxsSQuLo4899xzRKfTcdcfPnyYSCQSEhERQb7++usJv39jYyNJTU0lUVFRJDo6muTm5hJCCGlvbycrV64kUqmUrFy5khgMBkLIoGzujTfeIGFhYSQuLo5UVlZOeA0UygShkjGK66DX66HX65GYmIju7m7IZDIUFBTgzJkz1GmN4ipQyRjFdfD39+cmzM6ZMwdRUVHQarUoLCzE9u3bAQDbt29HQUEBgEHZ2rZt28AwDJYtW4aOjg6bdAiFwido0KXwmoaGBlRVVWHp0qXjdlqjUPgIDboU3mI0GpGeno7c3NxhExWmst60uLgYixYtglQqxdGjR529HIqdoUGXwkv6+/uRnp6OF198ERs3bgSAUfWmU0m2ZjabsXv3bhQVFaGmpgafffYZampqnL0sih2hQZfCOwgheOWVVxAVFYXMzEzu9ekwt0utVkMqlUIikcDDwwMKhQKFhYXOXhbFjjxKvUChTDoMwywHUArgGgDLf19+G4AKwAUACwHcAbCZEGJgBvMMeQDWArgP4GVCSMWkL9wOMAzzawBrCSE7//v1/wFYSgjJcO7KKPaC+ulSeAchpAyjS25WjHA9AbDboYuiUOwETS9QKPxCCyDY6uug/75GmSLQoEuh8ItyAOEMw4QyDOMBQAHgSyeviWJHaHqBQuERhJABhmEyAFwG4AbgNCHkhpOXRbEjtJBGoVAokwhNL1AoFMok8v9+eeU2U0qYYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Chh969QU-u"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEBaWTtLN_A_"
      },
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=10, shuffle=True)\n",
        "validate_dataloader = DataLoader(validation_data, batch_size=10, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=10, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4hpRnHALqS"
      },
      "source": [
        "# Define CNN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSj3U3DL5NGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf7a277-27ed-4ce0-a301-f619c3695063"
      },
      "source": [
        "# class CNN(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(CNN, self).__init__()\n",
        "#     out1 = 4\n",
        "#     out2 = 4\n",
        "#     out3 = 2\n",
        "#     self.cnn_layers = nn.Sequential(\n",
        "#       # Layer 1\n",
        "#       nn.Conv3d(1,out1,4,1,1),\n",
        "#       nn.BatchNorm3d(out1),\n",
        "#       #nn.ReLU(inplace=True),\n",
        "#       nn.LeakyReLU(inplace=True),\n",
        "#       nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "#       # Layer 2\n",
        "#       nn.Conv3d(out1, out2, 4, 1, 1),\n",
        "#       nn.BatchNorm3d(out2),\n",
        "#       #nn.ReLU(inplace=True),\n",
        "#       nn.LeakyReLU(inplace=True),\n",
        "#       nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "#       # Layer 3\n",
        "#       nn.Conv3d(out2, out3, 4, 1, 1),\n",
        "#       nn.BatchNorm3d(out3),\n",
        "#       #nn.ReLU(inplace=True),\n",
        "#       nn.LeakyReLU(inplace=True),\n",
        "#       nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "#     )\n",
        "    # self.linear_layers = nn.Sequential(\n",
        "    #   nn.Linear(48778, 2)\n",
        "    # )\n",
        "#   def forward(self, x):\n",
        "#     x = self.cnn_layers(x)\n",
        "#     x = x.view(x.size(0), -1)\n",
        "#     x = self.linear_layers(x)\n",
        "#     return x\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    out1 = 32\n",
        "    out2 = 64\n",
        "    out3 = 128\n",
        "    out4 = 64\n",
        "    out5 = 16\n",
        "    out6 = 2\n",
        "    self.cnn_layers = nn.Sequential(\n",
        "      # Layer 1\n",
        "      nn.Conv3d(1,out1,2,2),\n",
        "      nn.BatchNorm3d(out1),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 2\n",
        "      nn.Conv3d(out1, out2, 2, 2),\n",
        "      nn.BatchNorm3d(out2),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 3\n",
        "      nn.Conv3d(out2, out3, 2, 2),\n",
        "      nn.BatchNorm3d(out3),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "      # Layer 4\n",
        "      nn.Conv3d(out3, out4, 1, 1),\n",
        "      nn.BatchNorm3d(out4),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      # Layer 5\n",
        "      nn.Conv3d(out4, out5, 1, 1),\n",
        "      nn.BatchNorm3d(out5),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      # Layer 6\n",
        "      nn.Conv3d(out5, out6, 1, 1),\n",
        "      nn.BatchNorm3d(out6),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.AvgPool3d(2)\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cnn_layers(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv3d(1, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (7): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (11): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (13): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (15): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (16): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (18): Conv3d(16, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (19): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (21): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imIsJYkHAVEe"
      },
      "source": [
        "# Define Train and Test Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RhWjamUGtE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b07e4ec-0afb-459d-ffd5-ec3aa42aa9b1"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "        X = X.float()\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        #y = reshape(y, (y.shape[0],1))\n",
        "        hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "        for index in range(len(y)):\n",
        "          if y[index] == 0:\n",
        "            hot_y[index,0] = 1\n",
        "            hot_y[index,1] = 0\n",
        "          elif y[index] == 1:\n",
        "            hot_y[index,0] = 0\n",
        "            hot_y[index,1] = 1\n",
        "      \n",
        "        print(hot_y)\n",
        "        pred = model(X)\n",
        "        torch.squeeze(pred)\n",
        "        loss = loss_fn(pred, hot_y.float())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print results after each batch        \n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss\n",
        "\n",
        "def validate_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    validate_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "            \n",
        "            pred = model(X)\n",
        "            # print(f'pred: {pred}')\n",
        "            # print(f'hot_y: {hot_y}')\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            # print(f'predictions: {predictions}')\n",
        "            # print(f'targets: {targets}')\n",
        "            print(f'Correct this batch = {(predictions == targets).sum().item()}')\n",
        "\n",
        "            torch.squeeze(pred)\n",
        "            validate_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            # correct += (pred.argmax(1) == hot_y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    validate_loss /= num_batches\n",
        "    correct /= size\n",
        "    accuracy = 100*correct\n",
        "    print(f\"Validate Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validate_loss:>8f} \\n\")\n",
        "    return validate_loss, accuracy\n",
        "\n",
        "learning_rate = 0.00101\n",
        "# defining the model\n",
        "model = CNN()\n",
        "# defining the optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# defining the loss function\n",
        "pos_weights = torch.tensor([(1/pos_weights), pos_weights])\n",
        "# print(pos_weights.size())\n",
        "# loss_fn = nn.BCEWithLogitsLoss()\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weights)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.to(device)\n",
        "loss_fn.to(device)\n",
        "\n",
        "summary(model=model, input_size=(1, 246, 246, 246), batch_size=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1     [2, 32, 123, 123, 123]             288\n",
            "       BatchNorm3d-2     [2, 32, 123, 123, 123]              64\n",
            "         LeakyReLU-3     [2, 32, 123, 123, 123]               0\n",
            "         MaxPool3d-4        [2, 32, 61, 61, 61]               0\n",
            "            Conv3d-5        [2, 64, 30, 30, 30]          16,448\n",
            "       BatchNorm3d-6        [2, 64, 30, 30, 30]             128\n",
            "         LeakyReLU-7        [2, 64, 30, 30, 30]               0\n",
            "         MaxPool3d-8        [2, 64, 15, 15, 15]               0\n",
            "            Conv3d-9          [2, 128, 7, 7, 7]          65,664\n",
            "      BatchNorm3d-10          [2, 128, 7, 7, 7]             256\n",
            "        LeakyReLU-11          [2, 128, 7, 7, 7]               0\n",
            "        MaxPool3d-12          [2, 128, 3, 3, 3]               0\n",
            "           Conv3d-13           [2, 64, 3, 3, 3]           8,256\n",
            "      BatchNorm3d-14           [2, 64, 3, 3, 3]             128\n",
            "        LeakyReLU-15           [2, 64, 3, 3, 3]               0\n",
            "           Conv3d-16           [2, 16, 3, 3, 3]           1,040\n",
            "      BatchNorm3d-17           [2, 16, 3, 3, 3]              32\n",
            "        LeakyReLU-18           [2, 16, 3, 3, 3]               0\n",
            "           Conv3d-19            [2, 2, 3, 3, 3]              34\n",
            "      BatchNorm3d-20            [2, 2, 3, 3, 3]               4\n",
            "        LeakyReLU-21            [2, 2, 3, 3, 3]               0\n",
            "        AvgPool3d-22            [2, 2, 1, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 92,342\n",
            "Trainable params: 92,342\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 113.58\n",
            "Forward/backward pass size (MB): 2921.27\n",
            "Params size (MB): 0.35\n",
            "Estimated Total Size (MB): 3035.20\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w-_C54rIh_Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=content/drive/logsdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfKkG2-Gh_p1",
        "outputId": "e6fa0b36-bb83-4469-df88-f7c1694453ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.8.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSqQYmcaAe-Q"
      },
      "source": [
        "# Run Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23uXlNlG9ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d9af8e-24f4-4ec2-d3db-4bb4308bc021"
      },
      "source": [
        "epochs = 5\n",
        "train_losses = [[],[]]\n",
        "validate_losses = [[],[]]\n",
        "validate_accuracies = [[],[]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Custom tensorboard writer class\n",
        "\"\"\"\n",
        "\n",
        "class customWriter(SummaryWriter):\n",
        "    def __init__(self, log_dir, batch_size, epoch, num_classes):\n",
        "        super(customWriter, self).__init__()\n",
        "        self.log_dir = log_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch = epoch\n",
        "        self.num_classes = num_classes\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.class_loss = {n: [] for n in range(num_classes+1)}\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        return 1/(1+torch.exp(-x))\n",
        "\n",
        "    def reset_losses(self):\n",
        "        self.train_loss, self.val_loss, self.class_loss = [], [], {\n",
        "            n: [] for n in range(self.num_classes+1)}\n",
        "\n",
        "    def plot_batch(self, tag, images):\n",
        "        \"\"\"\n",
        "        Plot batches in grid\n",
        "\n",
        "        Args: tag = identifier for plot (string)\n",
        "              images = input batch (torch.tensor)\n",
        "        \"\"\"\n",
        "        img_grid = torchvision.utils.make_grid(images, nrow=self.batch_size // 2)\n",
        "        self.add_image(tag, img_grid)\n",
        "\n",
        "    # def plot_prediction(self, tag, prediction, target, plot_target=True):\n",
        "    #     \"\"\"\n",
        "    #     Plot predictions vs target segmentation.\n",
        "    #     Args: tag = identifier for plot (string)\n",
        "    #           prediction = batch output of trained model (torch.tensor)\n",
        "    #           target = batch ground-truth segmentations (torch.tensor)\n",
        "    #     \"\"\"\n",
        "    #     fig = plt.figure(figsize=(24, 24, 24))#changed from (24,24)\n",
        "    #     prediction = self.sigmoid(prediction)\n",
        "    #     for idx in np.arange(self.batch_size):\n",
        "    #         ax = fig.add_subplot(self.batch_size // 2, self.batch_size // 2, self.batch_size // 2,\n",
        "    #                             idx+1, label='segmentations')\n",
        "    #         ax.imshow(prediction[idx, 0].cpu().numpy(\n",
        "    #         ), cmap='viridis')\n",
        "    #         if plot_target:\n",
        "    #             ax.imshow(target[idx, 0].cpu().numpy(), cmap='gray', alpha=0.25)\n",
        "    #         ax.set_title('prediction @ epoch: {} - idx: {}'.format(self.epoch, idx))\n",
        "    #     self.add_figure(tag, fig)\n",
        "    def plot_tumour(self, tag, image):\n",
        "        \"\"\"\n",
        "        Plot predictions vs target segmentation.\n",
        "        Args: tag = identifier for plot (string)\n",
        "              prediction = batch output of trained model (torch.tensor)\n",
        "              target = batch ground-truth segmentations (torch.tensor)\n",
        "        \"\"\"\n",
        "        fig = plt.figure(figsize=(24, 24, 24))#changed from (24,24)\n",
        "        for idx in np.arange(self.batch_size):\n",
        "            ax = fig.add_subplot(self.batch_size // 2, self.batch_size // 2, self.batch_size // 2,\n",
        "                                idx+1, label='images')\n",
        "            ax.imshow(image[idx, 0].cpu().numpy(\n",
        "            ), cmap='viridis')\n",
        "            \n",
        "            ax.set_title('prediction @ epoch: {} - idx: {}'.format(self.epoch, idx))\n",
        "        self.add_figure(tag, fig)\n",
        "\n",
        "    def plot_histogram(self, tag, prediction):\n",
        "        print('Plotting histogram')\n",
        "        fig = plt.figure(figsize=(24, 24))\n",
        "        for idx in np.arange(self.batch_size):\n",
        "            ax = fig.add_subplot(self.batch_size // 2, self.batch_size // 2,\n",
        "                                 idx+1, yticks=[], label='histogram')\n",
        "            pred_norm = (prediction[idx, 0]-prediction[idx, 0].min())/(\n",
        "                prediction[idx, 0].max()-prediction[idx, 0].min())\n",
        "            ax.hist(pred_norm.cpu().flatten(), bins=100)\n",
        "            ax.set_title(\n",
        "                f'Prediction histogram @ epoch: {self.epoch} - idx: {idx}')\n",
        "        self.add_figure(tag, fig)\n",
        "\n",
        "    def per_class_loss(self, prediction, target, criterion, alpha=None):\n",
        "        # Predict shape: (4, 1, 512, 512)\n",
        "        # Target shape: (4, 1, 512, 512)\n",
        "        #pred, target = prediction.cpu().numpy(), target.cpu().numpy()\n",
        "        pred, target = prediction, target\n",
        "        for class_ in range(self.num_classes + 1):\n",
        "            class_pred, class_tgt = torch.where(\n",
        "                target == class_, pred, torch.tensor([0], dtype=torch.float32).cuda()),  torch.where(target == class_, target, torch.tensor([0], dtype=torch.float32).cuda())\n",
        "\n",
        "            #class_pred, class_tgt = pred[target == class_], target[target == class_] \n",
        "            if alpha is not None:\n",
        "                loss = criterion(class_pred, class_tgt, alpha)\n",
        "                #bce_loss, dice_loss = criterion(class_pred, class_tgt, alpha)\n",
        "            else:\n",
        "                loss = criterion(class_pred, class_tgt)\n",
        "                #bce_loss, dice_loss = criterion(class_pred, class_tgt)\n",
        "            #loss = bce_loss + dice_loss\n",
        "            self.class_loss[class_].append(loss.item())\n",
        "\n",
        "    def write_class_loss(self):\n",
        "        for class_ in range(self.num_classes+1):\n",
        "            self.add_scalar(f'Per Class loss for class {class_}', np.mean(self.class_loss[class_]), self.epoch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "writer = customWriter(project_folder, 2, 0, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    validate_loss = validate_loop(validate_dataloader, model, loss_fn)\n",
        "\n",
        "    train_losses[0].append(t)\n",
        "    train_losses[1].append(train_loss)\n",
        "    validate_losses[0].append(t)\n",
        "    validate_losses[1].append(validate_loss[0])\n",
        "    validate_accuracies[0].append(t)\n",
        "    validate_accuracies[1].append(validate_loss[1])\n",
        "\n",
        "    writer.add_scalar('Train Loss', train_loss, t)\n",
        "    writer.add_scalar('Validate Loss', validate_loss[0], t)\n",
        "    # plot 3d plots here\n",
        "    writer.plot_tumour()\n",
        "writer.close()\n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.536289  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 2.333449  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.264387  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.333626  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.232699  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.266872  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.227999  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.232579  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.256392  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.223888  [   63/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 8\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 9\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.226275 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 2.225927  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 2.228411  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.227648  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.240123  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.222598  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.226172  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.230924  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.225806  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 2.228843  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 2.231336  [   63/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 9\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 8\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.223773 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.220834  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.218694  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.230012  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.232958  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.223865  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.218630  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.227411  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.234524  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.235183  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.218570  [   63/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 8\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 9\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.222901 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.223584  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.217164  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n",
            "loss: 2.229833  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.217459  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.235821  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.221503  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.220717  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.225109  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.233536  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.227180  [   63/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 8\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 10\n",
            "(246, 246, 246)\n",
            "Correct this batch = 0\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.238643 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.221172  [    0/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.227234  [   10/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.223460  [   20/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.229937  [   30/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.227416  [   40/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.218371  [   50/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.231257  [   60/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.218165  [   70/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.227815  [   80/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], device='cuda:0')\n",
            "loss: 2.216097  [   63/   97]\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 7\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "(246, 246, 246)\n",
            "Correct this batch = 10\n",
            "(246, 246, 246)\n",
            "Correct this batch = 1\n",
            "Validate Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.222640 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "NUCtjrHb6JAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = reshape(X, (X.shape[0],1,246,246,246))\n",
        "            X = X.float()\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #y = reshape(y, (y.shape[0],1))\n",
        "            hot_y = torch.empty((X.shape[0],2)).to(device)\n",
        "            for index in range(len(y)):\n",
        "              if y[index] == 0:\n",
        "                hot_y[index,0] = 1\n",
        "                hot_y[index,1] = 0\n",
        "              elif y[index] == 1:\n",
        "                hot_y[index,0] = 0\n",
        "                hot_y[index,1] = 1\n",
        "                \n",
        "            pred = model(X)\n",
        "            _,predictions = torch.max(pred , 1)\n",
        "            _,targets = torch.max(hot_y, 1)\n",
        "            torch.squeeze(pred)\n",
        "            #test_loss += loss_fn(pred, y.float()).item()\n",
        "            test_loss += loss_fn(pred, hot_y.float()).item()\n",
        "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n",
        "\n",
        "test_loop(test_dataloader, model)"
      ],
      "metadata": {
        "id": "MEuNq5Z-6IV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZBw098GbFou"
      },
      "source": [
        "# Plot Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmncBB6bEip"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(train_losses[0], train_losses[1], label=\"Train Loss\")\n",
        "ax.plot(validate_losses[0], validate_losses[1], label=\"Validate Loss\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Accuracies"
      ],
      "metadata": {
        "id": "fFAdAFAECQ-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(validate_accuracies[0], validate_accuracies[1], label=\"Validate Accuracies\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy / %')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "2Q8g4JowCPkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}